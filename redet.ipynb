{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9fe266",
   "metadata": {
    "_cell_guid": "d7ec313e-e6fb-48b4-8b93-5d4e62203414",
    "_uuid": "73fbc1ab-fe28-4694-a9eb-7d6ae648d2f4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:30:17.608150Z",
     "iopub.status.busy": "2025-09-15T06:30:17.607879Z",
     "iopub.status.idle": "2025-09-15T06:30:24.250252Z",
     "shell.execute_reply": "2025-09-15T06:30:24.249626Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.647445,
     "end_time": "2025-09-15T06:30:24.251363",
     "exception": false,
     "start_time": "2025-09-15T06:30:17.603918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanish-jain140301\u001b[0m (\u001b[33mtanish1403\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb -q\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_tanish\")\n",
    "\n",
    "wandb.login(key = secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85ff8ce",
   "metadata": {
    "_cell_guid": "9047be76-4ae7-4deb-ac03-788fb5ffd435",
    "_uuid": "252a48bd-42ad-4bc6-a66e-893c4d3cbb41",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:30:24.258197Z",
     "iopub.status.busy": "2025-09-15T06:30:24.257959Z",
     "iopub.status.idle": "2025-09-15T06:30:24.379050Z",
     "shell.execute_reply": "2025-09-15T06:30:24.378342Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.12599,
     "end_time": "2025-09-15T06:30:24.380500",
     "exception": false,
     "start_time": "2025-09-15T06:30:24.254510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0907134",
   "metadata": {
    "_cell_guid": "15dec884-9976-4a83-9674-af59b5f318b1",
    "_uuid": "95036aad-d3ea-4eae-b78c-bf037f9fa83e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:30:24.387338Z",
     "iopub.status.busy": "2025-09-15T06:30:24.387102Z",
     "iopub.status.idle": "2025-09-15T06:33:02.294112Z",
     "shell.execute_reply": "2025-09-15T06:33:02.293007Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 157.912218,
     "end_time": "2025-09-15T06:33:02.295739",
     "exception": false,
     "start_time": "2025-09-15T06:30:24.383521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m386.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\r\n",
      "datasets 3.6.0 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 3.6.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "pytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\r\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "pymc 5.23.0 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "yfinance 0.2.63 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "dataproc-spark-connect 0.7.5 requires tqdm>=4.67, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\r\n",
      "pytensor 2.31.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "# !pip install mmcv-full==1.7.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html -q\n",
    "!pip install mmdet==2.28.2 -q\n",
    "!pip install -U openmim -q\n",
    "!mim install \"mmengine>=0.7.0\" -q\n",
    "!pip install xmltodict -q  # For dataset conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18010ee7",
   "metadata": {
    "_cell_guid": "20ffea5b-704c-4157-b73d-b9c7948e00e0",
    "_uuid": "67f36fdf-5423-4eb9-a55a-702f74ab582f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:02.369527Z",
     "iopub.status.busy": "2025-09-15T06:33:02.369234Z",
     "iopub.status.idle": "2025-09-15T06:33:17.689196Z",
     "shell.execute_reply": "2025-09-15T06:33:17.688151Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.358336,
     "end_time": "2025-09-15T06:33:17.690613",
     "exception": false,
     "start_time": "2025-09-15T06:33:02.332277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\r\n",
      "Collecting mmcv==2.0.1\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.1-cp311-cp311-manylinux1_x86_64.whl (74.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (0.10.7)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (4.11.0.86)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.0.1) (3.7.2)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.0.1) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.0.1) (3.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv==2.0.1) (4.3.8)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv==2.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv==2.0.1) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mmcv==2.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mmcv==2.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.0.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.0.1) (2.19.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mmcv==2.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.0.1) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (1.17.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!mim install 'mmcv==2.0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac8c0c7",
   "metadata": {
    "_cell_guid": "4d023f3b-eb29-4cf0-b41e-daaa5ddeffdc",
    "_uuid": "8caa7187-d6fc-481a-92d1-4fd179f4d5c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:17.820690Z",
     "iopub.status.busy": "2025-09-15T06:33:17.820395Z",
     "iopub.status.idle": "2025-09-15T06:33:33.031796Z",
     "shell.execute_reply": "2025-09-15T06:33:33.030999Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.254496,
     "end_time": "2025-09-15T06:33:33.033212",
     "exception": false,
     "start_time": "2025-09-15T06:33:17.778716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\r\n",
      "Collecting mmcv-full\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv_full-1.7.2-cp311-cp311-manylinux1_x86_64.whl (70.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (2.4.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (4.11.0.86)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-full) (4.3.8)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv-full) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv-full) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mmcv-full) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mmcv-full) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mmcv-full) (2024.2.0)\r\n",
      "Installing collected packages: mmcv-full\r\n",
      "Successfully installed mmcv-full-1.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!mim install 'mmcv-full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38b5d8b",
   "metadata": {
    "_cell_guid": "9bfec733-226e-4430-b879-3fb59243d26e",
    "_uuid": "0df7e8ae-7340-4248-a53c-f290b7a259d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:33.128355Z",
     "iopub.status.busy": "2025-09-15T06:33:33.127809Z",
     "iopub.status.idle": "2025-09-15T06:33:33.142048Z",
     "shell.execute_reply": "2025-09-15T06:33:33.141369Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.062136,
     "end_time": "2025-09-15T06:33:33.143183",
     "exception": false,
     "start_time": "2025-09-15T06:33:33.081047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Prepare Dataset (SCCOS to DOTA format)\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import xmltodict\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "dataset_path = \"/kaggle/input/sccos-dataset/\"\n",
    "working_dir = \"/kaggle/working/sccos_dota\"\n",
    "train_images_dir = os.path.join(working_dir, \"train/images\")\n",
    "train_labels_dir = os.path.join(working_dir, \"train/labels\")\n",
    "val_images_dir = os.path.join(working_dir, \"val/images\")\n",
    "val_labels_dir = os.path.join(working_dir, \"val/labels\")\n",
    "test_images_dir = os.path.join(working_dir, \"test/images\")\n",
    "test_labels_dir = os.path.join(working_dir, \"test/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e489eb5f",
   "metadata": {
    "_cell_guid": "800663ff-8219-45b7-8b59-08a7ec6b5e1d",
    "_uuid": "325fa1c5-399d-40b0-8dd6-48916ea9638b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:33.235427Z",
     "iopub.status.busy": "2025-09-15T06:33:33.235207Z",
     "iopub.status.idle": "2025-09-15T06:33:43.528688Z",
     "shell.execute_reply": "2025-09-15T06:33:43.527945Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 10.341202,
     "end_time": "2025-09-15T06:33:43.530175",
     "exception": false,
     "start_time": "2025-09-15T06:33:33.188973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/mmrotate'...\r\n",
      "remote: Enumerating objects: 482, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (482/482), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (333/333), done.\u001b[K\r\n",
      "remote: Total 482 (delta 143), reused 474 (delta 135), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (482/482), 11.52 MiB | 33.42 MiB/s, done.\r\n",
      "Resolving deltas: 100% (143/143), done.\r\n",
      "/kaggle/working/mmrotate\n",
      "Obtaining file:///kaggle/working/mmrotate\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting e2cnn (from mmrotate==0.3.4)\r\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (3.7.2)\r\n",
      "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (1.7.2)\r\n",
      "Requirement already satisfied: mmdet<3.0.0,>=2.25.1 in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (2.28.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (1.26.4)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (2.0.10)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (1.17.0)\r\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (3.1.10)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (2.0.1+cu118)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmdet<3.0.0,>=2.25.1->mmrotate==0.3.4) (1.15.3)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from e2cnn->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (11.2.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (2.4.1)\r\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (2.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (4.11.0.86)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (3.14.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (3.1.6)\r\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (2.0.0)\r\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->mmrotate==0.3.4) (3.31.6)\r\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->mmrotate==0.3.4) (15.0.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mmrotate==0.3.4) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mmrotate==0.3.4) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->e2cnn->mmrotate==0.3.4) (1.3.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (4.3.8)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: e2cnn, mmrotate\r\n",
      "  Running setup.py develop for mmrotate\r\n",
      "Successfully installed e2cnn-0.2.3 mmrotate-0.3.4\r\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Clone and Install MMRotate 0.3.4\n",
    "!git clone https://github.com/zhangpeng2001/nirnet.git /kaggle/working/mmrotate\n",
    "%cd /kaggle/working/mmrotate\n",
    "# !git checkout v0.3.4  # Ensure exact version\n",
    "!pip install -r requirements/build.txt -q\n",
    "!pip install -v -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4851fc6",
   "metadata": {
    "_cell_guid": "a8ec2e24-041c-422f-9ab6-f526906b8dbe",
    "_uuid": "83a9a167-e1cb-495d-a467-de044dd44164",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:43.625584Z",
     "iopub.status.busy": "2025-09-15T06:33:43.625318Z",
     "iopub.status.idle": "2025-09-15T06:33:45.423498Z",
     "shell.execute_reply": "2025-09-15T06:33:45.422541Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.846566,
     "end_time": "2025-09-15T06:33:45.424908",
     "exception": false,
     "start_time": "2025-09-15T06:33:43.578342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcv                                  2.0.1\r\n",
      "mmcv-full                             1.7.2\r\n",
      "mmdet                                 2.28.2\r\n",
      "mmengine                              0.10.7\r\n",
      "mmrotate                              0.3.4               /kaggle/working/mmrotate\r\n",
      "pytorch-ignite                        0.5.2\r\n",
      "pytorch-lightning                     2.5.2\r\n",
      "torch                                 2.0.1+cu118\r\n",
      "torchao                               0.10.0\r\n",
      "torchaudio                            2.0.2+cu118\r\n",
      "torchdata                             0.11.0\r\n",
      "torchinfo                             1.8.0\r\n",
      "torchmetrics                          1.7.3\r\n",
      "torchsummary                          1.5.1\r\n",
      "torchtune                             0.6.1\r\n",
      "torchvision                           0.15.2+cu118\r\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify Installations\n",
    "!pip list | grep -E 'torch|mmcv|mmdet|mmengine|mmrotate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2820545b",
   "metadata": {
    "_cell_guid": "a119f71a-1a0f-4f02-91aa-6e61dfc47121",
    "_uuid": "ab25a3e3-e802-4e60-ab31-c7e68938e482",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:45.522088Z",
     "iopub.status.busy": "2025-09-15T06:33:45.521835Z",
     "iopub.status.idle": "2025-09-15T06:33:45.530327Z",
     "shell.execute_reply": "2025-09-15T06:33:45.529699Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.058354,
     "end_time": "2025-09-15T06:33:45.531422",
     "exception": false,
     "start_time": "2025-09-15T06:33:45.473068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs/redet/redet_r50_fpn_1x_sccos.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/redet/redet_r50_fpn_1x_sccos.py\n",
    "_base_ = [\n",
    "    '../_base_/datasets/dotav1.py', '../_base_/schedules/schedule_1x.py',\n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "angle_version = 'le135'\n",
    "model = dict(\n",
    "    type='ReDet',\n",
    "    backbone=dict(\n",
    "        type='ReResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        frozen_stages=1,\n",
    "        style='pytorch',\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
    "    neck=dict(\n",
    "        type='ReFPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    rpn_head=dict(\n",
    "        type='RotatedRPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        version='le90',\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(\n",
    "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
    "    roi_head=dict(\n",
    "        type='RoITransRoIHead',\n",
    "        version='le90',\n",
    "        num_stages=2,\n",
    "        stage_loss_weights=[1, 1],\n",
    "        bbox_roi_extractor=[\n",
    "            dict(\n",
    "                type='SingleRoIExtractor',\n",
    "                roi_layer=dict(\n",
    "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
    "                out_channels=256,\n",
    "                featmap_strides=[4, 8, 16, 32]),\n",
    "            dict(\n",
    "                type='RotatedSingleRoIExtractor',\n",
    "                roi_layer=dict(\n",
    "                    type='RiRoIAlignRotated',\n",
    "                    out_size=7,\n",
    "                    num_samples=2,\n",
    "                    num_orientations=8,\n",
    "                    clockwise=True),\n",
    "                out_channels=256,\n",
    "                featmap_strides=[4, 8, 16, 32])\n",
    "        ],\n",
    "        bbox_head=[\n",
    "            dict(\n",
    "                type='RotatedShared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=1,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHAHBBoxCoder',\n",
    "                    angle_range='le90',\n",
    "                    norm_factor=2,\n",
    "                    edge_swap=True,\n",
    "                    target_means=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    target_stds=[0.1, 0.1, 0.2, 0.2, 1.0]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='RotatedShared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=1,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHAOBBoxCoder',\n",
    "                    angle_range='le90',\n",
    "                    norm_factor=None,\n",
    "                    edge_swap=True,\n",
    "                    proj_xy=True,\n",
    "                    target_means=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    target_stds=[0.05, 0.05, 0.1, 0.1, 0.5]),\n",
    "                reg_class_agnostic=False,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
    "        ]),\n",
    "    train_cfg=dict(\n",
    "        rpn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.3,\n",
    "                min_pos_iou=0.3,\n",
    "                match_low_quality=True,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=256,\n",
    "                pos_fraction=0.5,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=False),\n",
    "            allowed_border=0,\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        rpn_proposal=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=[\n",
    "            dict(\n",
    "                assigner=dict(\n",
    "                    type='MaxIoUAssigner',\n",
    "                    pos_iou_thr=0.5,\n",
    "                    neg_iou_thr=0.5,\n",
    "                    min_pos_iou=0.5,\n",
    "                    match_low_quality=False,\n",
    "                    ignore_iof_thr=-1,\n",
    "                    iou_calculator=dict(type='BboxOverlaps2D')),\n",
    "                sampler=dict(\n",
    "                    type='RandomSampler',\n",
    "                    num=512,\n",
    "                    pos_fraction=0.25,\n",
    "                    neg_pos_ub=-1,\n",
    "                    add_gt_as_proposals=True),\n",
    "                pos_weight=-1,\n",
    "                debug=False),\n",
    "            dict(\n",
    "                assigner=dict(\n",
    "                    type='MaxIoUAssigner',\n",
    "                    pos_iou_thr=0.5,\n",
    "                    neg_iou_thr=0.5,\n",
    "                    min_pos_iou=0.5,\n",
    "                    match_low_quality=False,\n",
    "                    ignore_iof_thr=-1,\n",
    "                    iou_calculator=dict(type='RBboxOverlaps2D')),\n",
    "                sampler=dict(\n",
    "                    type='RRandomSampler',\n",
    "                    num=512,\n",
    "                    pos_fraction=0.25,\n",
    "                    neg_pos_ub=-1,\n",
    "                    add_gt_as_proposals=True),\n",
    "                pos_weight=-1,\n",
    "                debug=False)\n",
    "        ]),\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            nms_pre=2000,\n",
    "            min_bbox_size=0,\n",
    "            score_thr=0.05,\n",
    "            nms=dict(iou_thr=0.1),\n",
    "            max_per_img=2000)))\n",
    "\n",
    "dataset_type = 'DOTADataset'\n",
    "# data_root = '/kaggle/working/sccos_dota/'\n",
    "data_root = '/kaggle/input/sccos-dota/sccos_dota/'\n",
    "classes = ('ship',)  # Explicitly define classes\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53],\n",
    "    std=[58.395, 57.12, 57.375],\n",
    "    to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RResize', img_scale=(1024, 1024)),\n",
    "    dict(\n",
    "        type='RRandomFlip',\n",
    "        flip_ratio=[0.25, 0.25, 0.25],\n",
    "        direction=['horizontal', 'vertical', 'diagonal'],\n",
    "        version='le135'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='RResize'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=4,\n",
    "    workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'train/labels/',\n",
    "        img_prefix=data_root + 'train/images/',\n",
    "        pipeline=train_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'val/labels/',\n",
    "        img_prefix=data_root + 'val/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'test/labels/',\n",
    "        img_prefix=data_root + 'test/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)))\n",
    "evaluation = dict(interval=1, metric='mAP', save_best='mAP') # Add save_best here\n",
    "lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=1000,\n",
    "    warmup_ratio=0.3333333333333333,\n",
    "    step=[8, 11])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=25)\n",
    "checkpoint_config = dict(interval=1) # Keep interval for saving\n",
    "log_config = dict(\n",
    "    interval=100,\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        dict(type='WandbLoggerHook',\n",
    "             init_kwargs=dict(\n",
    "                 project='SOTA',\n",
    "                 name='redet_train'),\n",
    "             interval=100)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c04a58c",
   "metadata": {
    "_cell_guid": "fbf3bcdc-5cef-4854-bcb6-aa319536c46b",
    "_uuid": "c1883d32-4124-48b1-9072-2e111c10049a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:33:45.626199Z",
     "iopub.status.busy": "2025-09-15T06:33:45.625726Z",
     "iopub.status.idle": "2025-09-15T06:34:21.117665Z",
     "shell.execute_reply": "2025-09-15T06:34:21.116898Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 35.540315,
     "end_time": "2025-09-15T06:34:21.119069",
     "exception": false,
     "start_time": "2025-09-15T06:33:45.578754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\r\n",
      "  full_mask[mask] = norms.to(torch.uint8)\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "ReDet(\r\n",
      "  28.406 M, 90.064% Params, 80.118 GFLOPs, 100.000% FLOPs, \r\n",
      "  (backbone): ReResNet(\r\n",
      "    0.006 M, 0.020% Params, 0.465 GFLOPs, 0.580% FLOPs, \r\n",
      "    (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {irrep_0, irrep_0, irrep_0}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=7, stride=2, padding=3, bias=False)\r\n",
      "    (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.034 GFLOPs, 0.042% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "    (maxpool): PointwiseMaxPool(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "    (layer1): ResLayer(\r\n",
      "      0.0 M, 0.000% Params, 0.185 GFLOPs, 0.230% FLOPs, \r\n",
      "      (0): Bottleneck(\r\n",
      "        0.0 M, 0.000% Params, 0.084 GFLOPs, 0.105% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.034 GFLOPs, 0.042% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (downsample): SequentialModule(\r\n",
      "          0.0 M, 0.000% Params, 0.034 GFLOPs, 0.042% FLOPs, \r\n",
      "          (0): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "          (1): InnerBatchNorm(0.0 M, 0.000% Params, 0.034 GFLOPs, 0.042% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Bottleneck(\r\n",
      "        0.0 M, 0.000% Params, 0.05 GFLOPs, 0.063% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.034 GFLOPs, 0.042% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (2): Bottleneck(\r\n",
      "        0.0 M, 0.000% Params, 0.05 GFLOPs, 0.063% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.034 GFLOPs, 0.042% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (layer2): ResLayer(\r\n",
      "      0.001 M, 0.003% Params, 0.13 GFLOPs, 0.162% FLOPs, \r\n",
      "      (0): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.055 GFLOPs, 0.068% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=2, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (downsample): SequentialModule(\r\n",
      "          0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, \r\n",
      "          (0): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=2, bias=False)\r\n",
      "          (1): InnerBatchNorm(0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.025 GFLOPs, 0.031% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (2): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.025 GFLOPs, 0.031% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (3): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.025 GFLOPs, 0.031% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.000% Params, 0.017 GFLOPs, 0.021% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (layer3): ResLayer(\r\n",
      "      0.003 M, 0.008% Params, 0.09 GFLOPs, 0.113% FLOPs, \r\n",
      "      (0): Bottleneck(\r\n",
      "        0.001 M, 0.002% Params, 0.027 GFLOPs, 0.034% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=2, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (downsample): SequentialModule(\r\n",
      "          0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, \r\n",
      "          (0): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=2, bias=False)\r\n",
      "          (1): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.013 GFLOPs, 0.016% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (2): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.013 GFLOPs, 0.016% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (3): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.013 GFLOPs, 0.016% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (4): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.013 GFLOPs, 0.016% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (5): Bottleneck(\r\n",
      "        0.0 M, 0.001% Params, 0.013 GFLOPs, 0.016% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.0 M, 0.001% Params, 0.008 GFLOPs, 0.010% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (layer4): ResLayer(\r\n",
      "      0.003 M, 0.009% Params, 0.026 GFLOPs, 0.033% FLOPs, \r\n",
      "      (0): Bottleneck(\r\n",
      "        0.001 M, 0.004% Params, 0.014 GFLOPs, 0.017% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=2, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.001 M, 0.002% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (downsample): SequentialModule(\r\n",
      "          0.001 M, 0.002% Params, 0.004 GFLOPs, 0.005% FLOPs, \r\n",
      "          (0): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=2, bias=False)\r\n",
      "          (1): InnerBatchNorm(0.001 M, 0.002% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Bottleneck(\r\n",
      "        0.001 M, 0.002% Params, 0.006 GFLOPs, 0.008% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.001 M, 0.002% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "      (2): Bottleneck(\r\n",
      "        0.001 M, 0.002% Params, 0.006 GFLOPs, 0.008% FLOPs, \r\n",
      "        (conv1): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn1): InnerBatchNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu1): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv2): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1, bias=False)\r\n",
      "        (bn2): InnerBatchNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu2): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "        (conv3): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1, bias=False)\r\n",
      "        (bn3): InnerBatchNorm(0.001 M, 0.002% Params, 0.004 GFLOPs, 0.005% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (relu3): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=False, type=[8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}])\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (neck): ReFPN(\r\n",
      "    0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "    (lateral_convs): ModuleList(\r\n",
      "      (0): ConvModule(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (conv): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\r\n",
      "      )\r\n",
      "      (1): ConvModule(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (conv): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\r\n",
      "      )\r\n",
      "      (2): ConvModule(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (conv): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\r\n",
      "      )\r\n",
      "      (3): ConvModule(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (conv): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (up_samples): ModuleList(\r\n",
      "      (0-3): 4 x R2Upsampling(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "    )\r\n",
      "    (fpn_convs): ModuleList(\r\n",
      "      (0-3): 4 x ConvModule(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (conv): R2Conv(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], [8-Rotations: {regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (max_pools): ModuleList(\r\n",
      "      (0): PointwiseMaxPool(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "    )\r\n",
      "    (relus): ModuleList()\r\n",
      "  )\r\n",
      "  (rpn_head): RotatedRPNHead(\r\n",
      "    0.594 M, 1.883% Params, 51.848 GFLOPs, 64.714% FLOPs, \r\n",
      "    (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\r\n",
      "    (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "    (rpn_conv): Conv2d(0.59 M, 1.871% Params, 51.512 GFLOPs, 64.294% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (rpn_cls): Conv2d(0.001 M, 0.002% Params, 0.067 GFLOPs, 0.084% FLOPs, 256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    (rpn_reg): Conv2d(0.003 M, 0.010% Params, 0.269 GFLOPs, 0.336% FLOPs, 256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "  )\r\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\r\n",
      "  (roi_head): RoITransRoIHead(\r\n",
      "    27.806 M, 88.161% Params, 27.806 GFLOPs, 34.706% FLOPs, \r\n",
      "    (bbox_roi_extractor): ModuleList(\r\n",
      "      (0): SingleRoIExtractor(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (roi_layers): ModuleList(\r\n",
      "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\r\n",
      "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\r\n",
      "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\r\n",
      "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): RotatedSingleRoIExtractor(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (roi_layers): ModuleList(\r\n",
      "          (0-3): 4 x RiRoIAlignRotated(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (bbox_head): ModuleList(\r\n",
      "      (0-1): 2 x RotatedShared2FCBBoxHead(\r\n",
      "        13.903 M, 44.081% Params, 13.903 GFLOPs, 17.353% FLOPs, \r\n",
      "        (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\r\n",
      "        (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "        (fc_cls): Linear(0.002 M, 0.006% Params, 0.002 GFLOPs, 0.003% FLOPs, in_features=1024, out_features=2, bias=True)\r\n",
      "        (fc_reg): Linear(0.005 M, 0.016% Params, 0.005 GFLOPs, 0.006% FLOPs, in_features=1024, out_features=5, bias=True)\r\n",
      "        (shared_convs): ModuleList()\r\n",
      "        (shared_fcs): ModuleList(\r\n",
      "          (0): Linear(12.846 M, 40.730% Params, 12.845 GFLOPs, 16.033% FLOPs, in_features=12544, out_features=1024, bias=True)\r\n",
      "          (1): Linear(1.05 M, 3.328% Params, 1.049 GFLOPs, 1.309% FLOPs, in_features=1024, out_features=1024, bias=True)\r\n",
      "        )\r\n",
      "        (cls_convs): ModuleList()\r\n",
      "        (cls_fcs): ModuleList()\r\n",
      "        (reg_convs): ModuleList()\r\n",
      "        (reg_fcs): ModuleList()\r\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.003% FLOPs, inplace=True)\r\n",
      "      )\r\n",
      "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "==============================\r\n",
      "Input shape: (3, 1024, 1024)\r\n",
      "Flops: 80.12 GFLOPs\r\n",
      "Params: 31.54 M\r\n",
      "==============================\r\n",
      "!!!Please be cautious if you use the results in papers. You may need to check if all ops are supported and verify that the flops computation is correct.\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mmrotate\n",
    "!python tools/analysis_tools/get_flops.py configs/redet/redet_r50_fpn_1x_sccos.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8728855",
   "metadata": {
    "_cell_guid": "c2f05ec9-546b-49b3-8817-be0ef72ab45c",
    "_uuid": "15dd70a9-5c19-4862-9e08-b20bb897f60d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T06:34:21.219524Z",
     "iopub.status.busy": "2025-09-15T06:34:21.218831Z",
     "iopub.status.idle": "2025-09-15T14:56:22.259374Z",
     "shell.execute_reply": "2025-09-15T14:56:22.258451Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 30121.633199,
     "end_time": "2025-09-15T14:56:22.802154",
     "exception": false,
     "start_time": "2025-09-15T06:34:21.168955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 06:34:26,251 - mmrotate - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Tesla P100-PCIE-16GB\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Cuda compilation tools, release 12.5, V12.5.82\r\n",
      "GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n",
      "PyTorch: 2.0.1+cu118\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.2-Product Build 20250620 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.8\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.7\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.15.2+cu118\r\n",
      "OpenCV: 4.11.0\r\n",
      "MMCV: 1.7.2\r\n",
      "MMCV Compiler: GCC 9.3\r\n",
      "MMCV CUDA Compiler: 11.8\r\n",
      "MMRotate: 0.3.4+7250f04\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2025-09-15 06:34:26,569 - mmrotate - INFO - Distributed training: False\r\n",
      "2025-09-15 06:34:26,726 - mmrotate - INFO - Config:\r\n",
      "dataset_type = 'DOTADataset'\r\n",
      "data_root = '/kaggle/input/sccos-dota/sccos_dota/'\r\n",
      "img_norm_cfg = dict(\r\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "    dict(\r\n",
      "        type='RRandomFlip',\r\n",
      "        flip_ratio=[0.25, 0.25, 0.25],\r\n",
      "        direction=['horizontal', 'vertical', 'diagonal'],\r\n",
      "        version='le135'),\r\n",
      "    dict(\r\n",
      "        type='Normalize',\r\n",
      "        mean=[123.675, 116.28, 103.53],\r\n",
      "        std=[58.395, 57.12, 57.375],\r\n",
      "        to_rgb=True),\r\n",
      "    dict(type='Pad', size_divisor=32),\r\n",
      "    dict(type='DefaultFormatBundle'),\r\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='MultiScaleFlipAug',\r\n",
      "        img_scale=(1024, 1024),\r\n",
      "        flip=False,\r\n",
      "        transforms=[\r\n",
      "            dict(type='RResize'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img'])\r\n",
      "        ])\r\n",
      "]\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=4,\r\n",
      "    workers_per_gpu=2,\r\n",
      "    train=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/input/sccos-dota/sccos_dota/train/labels/',\r\n",
      "        img_prefix='/kaggle/input/sccos-dota/sccos_dota/train/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "            dict(\r\n",
      "                type='RRandomFlip',\r\n",
      "                flip_ratio=[0.25, 0.25, 0.25],\r\n",
      "                direction=['horizontal', 'vertical', 'diagonal'],\r\n",
      "                version='le135'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    val=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/input/sccos-dota/sccos_dota/val/labels/',\r\n",
      "        img_prefix='/kaggle/input/sccos-dota/sccos_dota/val/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    test=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/input/sccos-dota/sccos_dota/test/labels/',\r\n",
      "        img_prefix='/kaggle/input/sccos-dota/sccos_dota/test/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )))\r\n",
      "evaluation = dict(interval=1, metric='mAP', save_best='mAP')\r\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\r\n",
      "lr_config = dict(\r\n",
      "    policy='step',\r\n",
      "    warmup='linear',\r\n",
      "    warmup_iters=1000,\r\n",
      "    warmup_ratio=0.3333333333333333,\r\n",
      "    step=[8, 11])\r\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=25)\r\n",
      "checkpoint_config = dict(interval=1)\r\n",
      "log_config = dict(\r\n",
      "    interval=100,\r\n",
      "    hooks=[\r\n",
      "        dict(type='TextLoggerHook'),\r\n",
      "        dict(\r\n",
      "            type='WandbLoggerHook',\r\n",
      "            init_kwargs=dict(project='SOTA', name='redet_train'),\r\n",
      "            interval=100)\r\n",
      "    ])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = None\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "angle_version = 'le135'\r\n",
      "model = dict(\r\n",
      "    type='ReDet',\r\n",
      "    backbone=dict(\r\n",
      "        type='ReResNet',\r\n",
      "        depth=50,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(0, 1, 2, 3),\r\n",
      "        frozen_stages=1,\r\n",
      "        style='pytorch',\r\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\r\n",
      "    neck=dict(\r\n",
      "        type='ReFPN',\r\n",
      "        in_channels=[256, 512, 1024, 2048],\r\n",
      "        out_channels=256,\r\n",
      "        num_outs=5),\r\n",
      "    rpn_head=dict(\r\n",
      "        type='RotatedRPNHead',\r\n",
      "        in_channels=256,\r\n",
      "        feat_channels=256,\r\n",
      "        version='le90',\r\n",
      "        anchor_generator=dict(\r\n",
      "            type='AnchorGenerator',\r\n",
      "            scales=[8],\r\n",
      "            ratios=[0.5, 1.0, 2.0],\r\n",
      "            strides=[4, 8, 16, 32, 64]),\r\n",
      "        bbox_coder=dict(\r\n",
      "            type='DeltaXYWHBBoxCoder',\r\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\r\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\r\n",
      "        loss_cls=dict(\r\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\r\n",
      "        loss_bbox=dict(\r\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\r\n",
      "    roi_head=dict(\r\n",
      "        type='RoITransRoIHead',\r\n",
      "        version='le90',\r\n",
      "        num_stages=2,\r\n",
      "        stage_loss_weights=[1, 1],\r\n",
      "        bbox_roi_extractor=[\r\n",
      "            dict(\r\n",
      "                type='SingleRoIExtractor',\r\n",
      "                roi_layer=dict(\r\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\r\n",
      "                out_channels=256,\r\n",
      "                featmap_strides=[4, 8, 16, 32]),\r\n",
      "            dict(\r\n",
      "                type='RotatedSingleRoIExtractor',\r\n",
      "                roi_layer=dict(\r\n",
      "                    type='RiRoIAlignRotated',\r\n",
      "                    out_size=7,\r\n",
      "                    num_samples=2,\r\n",
      "                    num_orientations=8,\r\n",
      "                    clockwise=True),\r\n",
      "                out_channels=256,\r\n",
      "                featmap_strides=[4, 8, 16, 32])\r\n",
      "        ],\r\n",
      "        bbox_head=[\r\n",
      "            dict(\r\n",
      "                type='RotatedShared2FCBBoxHead',\r\n",
      "                in_channels=256,\r\n",
      "                fc_out_channels=1024,\r\n",
      "                roi_feat_size=7,\r\n",
      "                num_classes=1,\r\n",
      "                bbox_coder=dict(\r\n",
      "                    type='DeltaXYWHAHBBoxCoder',\r\n",
      "                    angle_range='le90',\r\n",
      "                    norm_factor=2,\r\n",
      "                    edge_swap=True,\r\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0, 0.0],\r\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2, 1.0]),\r\n",
      "                reg_class_agnostic=True,\r\n",
      "                loss_cls=dict(\r\n",
      "                    type='CrossEntropyLoss',\r\n",
      "                    use_sigmoid=False,\r\n",
      "                    loss_weight=1.0),\r\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\r\n",
      "                               loss_weight=1.0)),\r\n",
      "            dict(\r\n",
      "                type='RotatedShared2FCBBoxHead',\r\n",
      "                in_channels=256,\r\n",
      "                fc_out_channels=1024,\r\n",
      "                roi_feat_size=7,\r\n",
      "                num_classes=1,\r\n",
      "                bbox_coder=dict(\r\n",
      "                    type='DeltaXYWHAOBBoxCoder',\r\n",
      "                    angle_range='le90',\r\n",
      "                    norm_factor=None,\r\n",
      "                    edge_swap=True,\r\n",
      "                    proj_xy=True,\r\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0, 0.0],\r\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1, 0.5]),\r\n",
      "                reg_class_agnostic=False,\r\n",
      "                loss_cls=dict(\r\n",
      "                    type='CrossEntropyLoss',\r\n",
      "                    use_sigmoid=False,\r\n",
      "                    loss_weight=1.0),\r\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\r\n",
      "        ]),\r\n",
      "    train_cfg=dict(\r\n",
      "        rpn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                match_low_quality=True,\r\n",
      "                ignore_iof_thr=-1),\r\n",
      "            sampler=dict(\r\n",
      "                type='RandomSampler',\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                add_gt_as_proposals=False),\r\n",
      "            allowed_border=0,\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            max_per_img=2000,\r\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\r\n",
      "            min_bbox_size=0),\r\n",
      "        rcnn=[\r\n",
      "            dict(\r\n",
      "                assigner=dict(\r\n",
      "                    type='MaxIoUAssigner',\r\n",
      "                    pos_iou_thr=0.5,\r\n",
      "                    neg_iou_thr=0.5,\r\n",
      "                    min_pos_iou=0.5,\r\n",
      "                    match_low_quality=False,\r\n",
      "                    ignore_iof_thr=-1,\r\n",
      "                    iou_calculator=dict(type='BboxOverlaps2D')),\r\n",
      "                sampler=dict(\r\n",
      "                    type='RandomSampler',\r\n",
      "                    num=512,\r\n",
      "                    pos_fraction=0.25,\r\n",
      "                    neg_pos_ub=-1,\r\n",
      "                    add_gt_as_proposals=True),\r\n",
      "                pos_weight=-1,\r\n",
      "                debug=False),\r\n",
      "            dict(\r\n",
      "                assigner=dict(\r\n",
      "                    type='MaxIoUAssigner',\r\n",
      "                    pos_iou_thr=0.5,\r\n",
      "                    neg_iou_thr=0.5,\r\n",
      "                    min_pos_iou=0.5,\r\n",
      "                    match_low_quality=False,\r\n",
      "                    ignore_iof_thr=-1,\r\n",
      "                    iou_calculator=dict(type='RBboxOverlaps2D')),\r\n",
      "                sampler=dict(\r\n",
      "                    type='RRandomSampler',\r\n",
      "                    num=512,\r\n",
      "                    pos_fraction=0.25,\r\n",
      "                    neg_pos_ub=-1,\r\n",
      "                    add_gt_as_proposals=True),\r\n",
      "                pos_weight=-1,\r\n",
      "                debug=False)\r\n",
      "        ]),\r\n",
      "    test_cfg=dict(\r\n",
      "        rpn=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            max_per_img=2000,\r\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\r\n",
      "            min_bbox_size=0),\r\n",
      "        rcnn=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            score_thr=0.05,\r\n",
      "            nms=dict(iou_thr=0.1),\r\n",
      "            max_per_img=2000)))\r\n",
      "classes = ('ship', )\r\n",
      "work_dir = '/kaggle/working/runs/redet_train'\r\n",
      "auto_resume = False\r\n",
      "gpu_ids = range(0, 1)\r\n",
      "\r\n",
      "2025-09-15 06:34:26,727 - mmrotate - INFO - Set random seed to 1651075027, deterministic: False\r\n",
      "/usr/local/lib/python3.11/dist-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\r\n",
      "  full_mask[mask] = norms.to(torch.uint8)\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "2025-09-15 06:34:52,452 - mmcv - INFO - initialize RotatedRPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\r\n",
      "2025-09-15 06:34:52,457 - mmcv - INFO - initialize RotatedShared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\r\n",
      "2025-09-15 06:34:52,663 - mmcv - INFO - initialize RotatedShared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\r\n",
      "2025-09-15 06:34:52,878 - mmcv - INFO - \r\n",
      "backbone.conv1.weights - torch.Size([960]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,879 - mmcv - INFO - \r\n",
      "backbone.bn1.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,879 - mmcv - INFO - \r\n",
      "backbone.bn1.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,879 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv1.weights - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,879 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn1.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,879 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn1.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,880 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv2.weights - torch.Size([4096]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,880 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn2.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,880 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn2.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,881 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv3.weights - torch.Size([2048]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,881 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn3.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,881 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn3.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,881 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.0.weights - torch.Size([2048]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,883 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,883 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,883 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv1.weights - torch.Size([2048]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,883 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn1.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,883 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn1.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,883 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv2.weights - torch.Size([4096]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,887 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn2.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,887 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn2.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,887 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv3.weights - torch.Size([2048]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,889 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn3.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,889 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn3.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,889 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv1.weights - torch.Size([2048]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,890 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn1.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,890 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn1.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,890 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv2.weights - torch.Size([4096]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,894 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn2.batch_norm_[8].weight - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,894 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn2.batch_norm_[8].bias - torch.Size([8]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,894 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv3.weights - torch.Size([2048]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,895 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn3.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,896 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn3.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,896 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv1.weights - torch.Size([4096]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,896 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn1.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,896 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn1.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,896 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv2.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,897 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn2.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,897 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn2.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,897 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv3.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,898 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn3.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,898 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn3.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,898 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.0.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,898 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.1.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,898 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.1.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,898 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv1.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,899 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn1.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,899 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn1.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,899 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv2.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,903 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn2.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,903 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn2.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,903 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv3.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,904 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn3.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,904 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn3.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,904 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv1.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,906 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn1.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,906 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn1.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,906 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv2.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,910 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn2.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,910 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn2.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,910 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv3.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,911 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn3.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,911 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn3.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,912 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv1.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,913 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn1.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,913 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn1.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,913 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv2.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,917 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn2.batch_norm_[8].weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,917 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn2.batch_norm_[8].bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,917 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv3.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,919 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn3.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,919 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn3.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,919 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv1.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,919 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,919 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,920 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv2.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,920 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn2.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,920 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn2.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,920 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv3.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,921 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn3.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,921 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn3.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,921 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.0.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,921 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.1.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,922 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.1.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,922 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv1.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,922 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,922 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,922 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv2.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,926 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn2.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,926 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn2.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,927 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv3.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,928 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn3.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,928 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn3.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,928 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv1.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,930 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,930 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,930 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv2.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,934 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn2.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,934 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn2.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,934 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv3.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,936 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn3.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,936 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn3.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,936 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv1.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,937 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,937 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,937 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv2.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,941 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn2.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,941 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn2.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,942 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv3.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,943 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn3.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,943 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn3.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,943 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv1.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,944 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,944 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,945 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv2.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,948 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn2.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,948 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn2.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,948 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv3.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,950 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn3.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,950 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn3.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,950 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv1.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,951 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn1.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,951 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn1.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,951 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv2.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,955 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn2.batch_norm_[8].weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,955 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn2.batch_norm_[8].bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,955 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv3.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,956 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn3.batch_norm_[8].weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,956 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn3.batch_norm_[8].bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,957 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv1.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,957 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn1.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,957 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn1.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,957 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv2.weights - torch.Size([262144]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,958 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn2.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,958 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn2.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,958 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv3.weights - torch.Size([131072]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,958 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn3.batch_norm_[8].weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,959 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn3.batch_norm_[8].bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,959 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.0.weights - torch.Size([262144]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,959 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.1.batch_norm_[8].weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,959 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.1.batch_norm_[8].bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,959 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv1.weights - torch.Size([131072]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,960 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn1.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,960 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn1.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,960 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv2.weights - torch.Size([262144]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,964 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn2.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,964 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn2.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,964 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv3.weights - torch.Size([131072]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,965 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn3.batch_norm_[8].weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,965 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn3.batch_norm_[8].bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,966 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv1.weights - torch.Size([131072]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,967 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn1.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,967 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn1.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,967 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv2.weights - torch.Size([262144]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,971 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn2.batch_norm_[8].weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,971 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn2.batch_norm_[8].bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,971 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv3.weights - torch.Size([131072]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,972 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn3.batch_norm_[8].weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,973 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn3.batch_norm_[8].bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,973 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,973 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.weights - torch.Size([8192]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,973 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,973 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.weights - torch.Size([16384]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,975 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,975 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.weights - torch.Size([32768]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,976 - mmcv - INFO - \r\n",
      "neck.lateral_convs.3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,976 - mmcv - INFO - \r\n",
      "neck.lateral_convs.3.conv.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,977 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,977 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,982 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,983 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,986 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,986 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,990 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,990 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.weights - torch.Size([65536]): \r\n",
      "The value is the same before and after calling `init_weights` of ReDet  \r\n",
      " \r\n",
      "2025-09-15 06:34:52,994 - mmcv - INFO - \r\n",
      "rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,994 - mmcv - INFO - \r\n",
      "rpn_head.rpn_conv.bias - torch.Size([256]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,994 - mmcv - INFO - \r\n",
      "rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,994 - mmcv - INFO - \r\n",
      "rpn_head.rpn_cls.bias - torch.Size([3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,994 - mmcv - INFO - \r\n",
      "rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,994 - mmcv - INFO - \r\n",
      "rpn_head.rpn_reg.bias - torch.Size([12]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.fc_cls.weight - torch.Size([2, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.fc_cls.bias - torch.Size([2]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.fc_reg.weight - torch.Size([5, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.fc_reg.bias - torch.Size([5]): \r\n",
      "NormalInit: mean=0, std=0.001, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.fc_cls.weight - torch.Size([2, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.fc_cls.bias - torch.Size([2]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.fc_reg.weight - torch.Size([5, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,995 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.fc_reg.bias - torch.Size([5]): \r\n",
      "NormalInit: mean=0, std=0.001, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,996 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,996 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,996 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:34:52,996 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-15 06:35:10,984 - mmrotate - INFO - Start running, host: root@24d5f4e7b9d7, work_dir: /kaggle/working/runs/redet_train\r\n",
      "2025-09-15 06:35:10,984 - mmrotate - INFO - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(ABOVE_NORMAL) OptimizerHook                      \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "2025-09-15 06:35:10,984 - mmrotate - INFO - workflow: [('train', 1)], max: 25 epochs\r\n",
      "2025-09-15 06:35:10,984 - mmrotate - INFO - Checkpoints will be saved to /kaggle/working/runs/redet_train by HardDiskBackend.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanish-jain140301\u001b[0m (\u001b[33mtanish1403\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/mmrotate/wandb/run-20250915_063511-tuun175x\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mredet_train\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/SOTA\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/SOTA/runs/tuun175x\u001b[0m\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "2025-09-15 06:37:14,126 - mmrotate - INFO - Epoch [1][100/928]\tlr: 9.983e-04, eta: 7:48:01, time: 1.216, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.2584, loss_rpn_bbox: 0.0456, s0.loss_cls: 0.1583, s0.acc: 97.3677, s0.loss_bbox: 0.1405, s1.loss_cls: 0.0528, s1.acc: 99.0361, s1.loss_bbox: 0.0549, loss: 0.7105, grad_norm: 9.7573\r\n",
      "2025-09-15 06:39:11,557 - mmrotate - INFO - Epoch [1][200/928]\tlr: 1.165e-03, eta: 7:38:04, time: 1.174, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.1749, loss_rpn_bbox: 0.0434, s0.loss_cls: 0.1120, s0.acc: 97.5640, s0.loss_bbox: 0.1586, s1.loss_cls: 0.0465, s1.acc: 99.0601, s1.loss_bbox: 0.0274, loss: 0.5629, grad_norm: 6.2291\r\n",
      "2025-09-15 06:41:10,744 - mmrotate - INFO - Epoch [1][300/928]\tlr: 1.332e-03, eta: 7:35:41, time: 1.192, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.1444, loss_rpn_bbox: 0.0393, s0.loss_cls: 0.1283, s0.acc: 96.9932, s0.loss_bbox: 0.1824, s1.loss_cls: 0.0422, s1.acc: 99.1240, s1.loss_bbox: 0.0235, loss: 0.5601, grad_norm: 5.9967\r\n",
      "2025-09-15 06:43:07,503 - mmrotate - INFO - Epoch [1][400/928]\tlr: 1.498e-03, eta: 7:31:11, time: 1.168, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.1278, loss_rpn_bbox: 0.0347, s0.loss_cls: 0.1306, s0.acc: 96.9238, s0.loss_bbox: 0.1923, s1.loss_cls: 0.0422, s1.acc: 99.1670, s1.loss_bbox: 0.0205, loss: 0.5481, grad_norm: 5.5223\r\n",
      "2025-09-15 06:45:04,727 - mmrotate - INFO - Epoch [1][500/928]\tlr: 1.665e-03, eta: 7:28:04, time: 1.172, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.1268, loss_rpn_bbox: 0.0350, s0.loss_cls: 0.1230, s0.acc: 97.0454, s0.loss_bbox: 0.1745, s1.loss_cls: 0.0389, s1.acc: 99.1602, s1.loss_bbox: 0.0193, loss: 0.5175, grad_norm: 5.2372\r\n",
      "2025-09-15 06:47:01,274 - mmrotate - INFO - Epoch [1][600/928]\tlr: 1.832e-03, eta: 7:24:54, time: 1.165, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.1360, loss_rpn_bbox: 0.0410, s0.loss_cls: 0.1388, s0.acc: 96.6538, s0.loss_bbox: 0.1784, s1.loss_cls: 0.0515, s1.acc: 98.9551, s1.loss_bbox: 0.0218, loss: 0.5675, grad_norm: 5.2297\r\n",
      "2025-09-15 06:48:59,594 - mmrotate - INFO - Epoch [1][700/928]\tlr: 1.998e-03, eta: 7:23:03, time: 1.183, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.1293, loss_rpn_bbox: 0.0340, s0.loss_cls: 0.1247, s0.acc: 96.8584, s0.loss_bbox: 0.1698, s1.loss_cls: 0.0396, s1.acc: 99.1338, s1.loss_bbox: 0.0150, loss: 0.5124, grad_norm: 4.1938\r\n",
      "2025-09-15 06:50:57,540 - mmrotate - INFO - Epoch [1][800/928]\tlr: 2.165e-03, eta: 7:20:59, time: 1.179, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.1282, loss_rpn_bbox: 0.0352, s0.loss_cls: 0.1223, s0.acc: 96.8501, s0.loss_bbox: 0.1629, s1.loss_cls: 0.0425, s1.acc: 99.1084, s1.loss_bbox: 0.0168, loss: 0.5078, grad_norm: 4.0311\r\n",
      "2025-09-15 06:52:56,103 - mmrotate - INFO - Epoch [1][900/928]\tlr: 2.332e-03, eta: 7:19:12, time: 1.186, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.1080, loss_rpn_bbox: 0.0337, s0.loss_cls: 0.1358, s0.acc: 96.2402, s0.loss_bbox: 0.1919, s1.loss_cls: 0.0371, s1.acc: 99.1025, s1.loss_bbox: 0.0167, loss: 0.5231, grad_norm: 3.7937\r\n",
      "2025-09-15 06:53:29,088 - mmrotate - INFO - Saving checkpoint at 1 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.2 task/s, elapsed: 147s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 06:56:04,867 - mmrotate - INFO - \r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| class | gts  | dets  | recall | ap    |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| ship  | 1744 | 11459 | 0.030  | 0.091 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| mAP   |      |       |        | 0.091 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "2025-09-15 06:56:06,053 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_1.pth.\r\n",
      "2025-09-15 06:56:06,054 - mmrotate - INFO - Best mAP is 0.0909 at 1 epoch.\r\n",
      "2025-09-15 06:56:06,054 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 06:56:06,055 - mmrotate - INFO - Epoch(val) [1][464]\tmAP: 0.0909\r\n",
      "2025-09-15 06:58:05,080 - mmrotate - INFO - Epoch [2][100/928]\tlr: 2.500e-03, eta: 7:05:04, time: 1.190, data_time: 0.045, memory: 6886, loss_rpn_cls: 0.0950, loss_rpn_bbox: 0.0310, s0.loss_cls: 0.1291, s0.acc: 96.4058, s0.loss_bbox: 0.1720, s1.loss_cls: 0.0375, s1.acc: 99.1362, s1.loss_bbox: 0.0168, loss: 0.4815, grad_norm: 3.6097\r\n",
      "2025-09-15 07:00:00,905 - mmrotate - INFO - Epoch [2][200/928]\tlr: 2.500e-03, eta: 7:03:24, time: 1.158, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0947, loss_rpn_bbox: 0.0315, s0.loss_cls: 0.1326, s0.acc: 96.3354, s0.loss_bbox: 0.1704, s1.loss_cls: 0.0347, s1.acc: 99.1602, s1.loss_bbox: 0.0151, loss: 0.4789, grad_norm: 3.5236\r\n",
      "2025-09-15 07:01:56,258 - mmrotate - INFO - Epoch [2][300/928]\tlr: 2.500e-03, eta: 7:01:34, time: 1.154, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0983, loss_rpn_bbox: 0.0357, s0.loss_cls: 0.1385, s0.acc: 95.9688, s0.loss_bbox: 0.1759, s1.loss_cls: 0.0391, s1.acc: 99.0693, s1.loss_bbox: 0.0203, loss: 0.5079, grad_norm: 3.5032\r\n",
      "2025-09-15 07:03:50,925 - mmrotate - INFO - Epoch [2][400/928]\tlr: 2.500e-03, eta: 6:59:31, time: 1.147, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0859, loss_rpn_bbox: 0.0300, s0.loss_cls: 0.1448, s0.acc: 95.7910, s0.loss_bbox: 0.1810, s1.loss_cls: 0.0390, s1.acc: 99.0557, s1.loss_bbox: 0.0202, loss: 0.5009, grad_norm: 3.4265\r\n",
      "2025-09-15 07:05:45,859 - mmrotate - INFO - Epoch [2][500/928]\tlr: 2.500e-03, eta: 6:57:34, time: 1.149, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0874, loss_rpn_bbox: 0.0374, s0.loss_cls: 0.1506, s0.acc: 95.4521, s0.loss_bbox: 0.1862, s1.loss_cls: 0.0382, s1.acc: 99.0352, s1.loss_bbox: 0.0220, loss: 0.5219, grad_norm: 3.4854\r\n",
      "2025-09-15 07:07:39,891 - mmrotate - INFO - Epoch [2][600/928]\tlr: 2.500e-03, eta: 6:55:24, time: 1.140, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0877, loss_rpn_bbox: 0.0361, s0.loss_cls: 0.1511, s0.acc: 95.6211, s0.loss_bbox: 0.1742, s1.loss_cls: 0.0414, s1.acc: 98.9893, s1.loss_bbox: 0.0234, loss: 0.5138, grad_norm: 3.4342\r\n",
      "2025-09-15 07:09:34,503 - mmrotate - INFO - Epoch [2][700/928]\tlr: 2.500e-03, eta: 6:53:24, time: 1.146, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0852, loss_rpn_bbox: 0.0347, s0.loss_cls: 0.1488, s0.acc: 95.4775, s0.loss_bbox: 0.1890, s1.loss_cls: 0.0351, s1.acc: 99.0928, s1.loss_bbox: 0.0205, loss: 0.5133, grad_norm: 3.3684\r\n",
      "2025-09-15 07:11:28,800 - mmrotate - INFO - Epoch [2][800/928]\tlr: 2.500e-03, eta: 6:51:20, time: 1.143, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0752, loss_rpn_bbox: 0.0352, s0.loss_cls: 0.1413, s0.acc: 95.6704, s0.loss_bbox: 0.1672, s1.loss_cls: 0.0358, s1.acc: 99.1074, s1.loss_bbox: 0.0215, loss: 0.4762, grad_norm: 3.1310\r\n",
      "2025-09-15 07:13:23,059 - mmrotate - INFO - Epoch [2][900/928]\tlr: 2.500e-03, eta: 6:49:17, time: 1.143, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0807, loss_rpn_bbox: 0.0359, s0.loss_cls: 0.1496, s0.acc: 95.3237, s0.loss_bbox: 0.1838, s1.loss_cls: 0.0378, s1.acc: 99.0098, s1.loss_bbox: 0.0243, loss: 0.5120, grad_norm: 3.3440\r\n",
      "2025-09-15 07:13:54,778 - mmrotate - INFO - Saving checkpoint at 2 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.2 task/s, elapsed: 144s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 07:16:27,253 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 9850 | 0.135  | 0.098 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.098 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 07:16:27,418 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_1.pth was removed\r\n",
      "2025-09-15 07:16:28,560 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_2.pth.\r\n",
      "2025-09-15 07:16:28,561 - mmrotate - INFO - Best mAP is 0.0977 at 2 epoch.\r\n",
      "2025-09-15 07:16:28,561 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 07:16:28,562 - mmrotate - INFO - Epoch(val) [2][464]\tmAP: 0.0977\r\n",
      "2025-09-15 07:18:25,596 - mmrotate - INFO - Epoch [3][100/928]\tlr: 2.500e-03, eta: 6:41:23, time: 1.170, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0717, loss_rpn_bbox: 0.0354, s0.loss_cls: 0.1432, s0.acc: 95.4629, s0.loss_bbox: 0.1726, s1.loss_cls: 0.0344, s1.acc: 99.0972, s1.loss_bbox: 0.0256, loss: 0.4829, grad_norm: 3.1682\r\n",
      "2025-09-15 07:20:19,725 - mmrotate - INFO - Epoch [3][200/928]\tlr: 2.500e-03, eta: 6:39:38, time: 1.141, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0707, loss_rpn_bbox: 0.0313, s0.loss_cls: 0.1402, s0.acc: 95.6338, s0.loss_bbox: 0.1536, s1.loss_cls: 0.0340, s1.acc: 99.1123, s1.loss_bbox: 0.0244, loss: 0.4542, grad_norm: 3.0535\r\n",
      "2025-09-15 07:22:13,443 - mmrotate - INFO - Epoch [3][300/928]\tlr: 2.500e-03, eta: 6:37:47, time: 1.137, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0652, loss_rpn_bbox: 0.0302, s0.loss_cls: 0.1337, s0.acc: 95.6948, s0.loss_bbox: 0.1483, s1.loss_cls: 0.0319, s1.acc: 99.1621, s1.loss_bbox: 0.0237, loss: 0.4330, grad_norm: 2.9817\r\n",
      "2025-09-15 07:24:07,478 - mmrotate - INFO - Epoch [3][400/928]\tlr: 2.500e-03, eta: 6:36:00, time: 1.140, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0604, loss_rpn_bbox: 0.0322, s0.loss_cls: 0.1499, s0.acc: 94.9858, s0.loss_bbox: 0.1802, s1.loss_cls: 0.0330, s1.acc: 99.0669, s1.loss_bbox: 0.0274, loss: 0.4831, grad_norm: 3.2567\r\n",
      "2025-09-15 07:26:02,346 - mmrotate - INFO - Epoch [3][500/928]\tlr: 2.500e-03, eta: 6:34:19, time: 1.149, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0653, loss_rpn_bbox: 0.0309, s0.loss_cls: 0.1462, s0.acc: 95.2759, s0.loss_bbox: 0.1709, s1.loss_cls: 0.0338, s1.acc: 99.0591, s1.loss_bbox: 0.0276, loss: 0.4746, grad_norm: 3.1601\r\n",
      "2025-09-15 07:27:57,085 - mmrotate - INFO - Epoch [3][600/928]\tlr: 2.500e-03, eta: 6:32:36, time: 1.147, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0653, loss_rpn_bbox: 0.0348, s0.loss_cls: 0.1493, s0.acc: 95.0474, s0.loss_bbox: 0.1665, s1.loss_cls: 0.0349, s1.acc: 99.0288, s1.loss_bbox: 0.0306, loss: 0.4815, grad_norm: 3.1279\r\n",
      "2025-09-15 07:29:51,937 - mmrotate - INFO - Epoch [3][700/928]\tlr: 2.500e-03, eta: 6:30:52, time: 1.149, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0682, loss_rpn_bbox: 0.0294, s0.loss_cls: 0.1490, s0.acc: 95.0508, s0.loss_bbox: 0.1743, s1.loss_cls: 0.0374, s1.acc: 98.9756, s1.loss_bbox: 0.0300, loss: 0.4882, grad_norm: 3.3344\r\n",
      "2025-09-15 07:31:45,745 - mmrotate - INFO - Epoch [3][800/928]\tlr: 2.500e-03, eta: 6:29:00, time: 1.138, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0612, loss_rpn_bbox: 0.0276, s0.loss_cls: 0.1465, s0.acc: 94.9995, s0.loss_bbox: 0.1682, s1.loss_cls: 0.0344, s1.acc: 99.0098, s1.loss_bbox: 0.0330, loss: 0.4709, grad_norm: 3.2248\r\n",
      "2025-09-15 07:33:39,086 - mmrotate - INFO - Epoch [3][900/928]\tlr: 2.500e-03, eta: 6:27:05, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0604, loss_rpn_bbox: 0.0298, s0.loss_cls: 0.1466, s0.acc: 95.1665, s0.loss_bbox: 0.1708, s1.loss_cls: 0.0333, s1.acc: 99.0435, s1.loss_bbox: 0.0309, loss: 0.4718, grad_norm: 3.1404\r\n",
      "2025-09-15 07:34:10,954 - mmrotate - INFO - Saving checkpoint at 3 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 142s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 07:36:42,206 - mmrotate - INFO - \r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| class | gts  | dets  | recall | ap    |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| ship  | 1744 | 10178 | 0.257  | 0.149 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| mAP   |      |       |        | 0.149 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "2025-09-15 07:36:42,364 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_2.pth was removed\r\n",
      "2025-09-15 07:36:43,857 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_3.pth.\r\n",
      "2025-09-15 07:36:43,858 - mmrotate - INFO - Best mAP is 0.1489 at 3 epoch.\r\n",
      "2025-09-15 07:36:43,858 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 07:36:43,858 - mmrotate - INFO - Epoch(val) [3][464]\tmAP: 0.1489\r\n",
      "2025-09-15 07:38:39,747 - mmrotate - INFO - Epoch [4][100/928]\tlr: 2.500e-03, eta: 6:21:11, time: 1.158, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0500, loss_rpn_bbox: 0.0263, s0.loss_cls: 0.1412, s0.acc: 95.1792, s0.loss_bbox: 0.1624, s1.loss_cls: 0.0320, s1.acc: 99.0845, s1.loss_bbox: 0.0344, loss: 0.4462, grad_norm: 3.0688\r\n",
      "2025-09-15 07:40:32,932 - mmrotate - INFO - Epoch [4][200/928]\tlr: 2.500e-03, eta: 6:19:22, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0592, loss_rpn_bbox: 0.0321, s0.loss_cls: 0.1480, s0.acc: 94.9062, s0.loss_bbox: 0.1652, s1.loss_cls: 0.0341, s1.acc: 99.0054, s1.loss_bbox: 0.0351, loss: 0.4737, grad_norm: 3.1356\r\n",
      "2025-09-15 07:42:26,183 - mmrotate - INFO - Epoch [4][300/928]\tlr: 2.500e-03, eta: 6:17:34, time: 1.133, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0572, loss_rpn_bbox: 0.0293, s0.loss_cls: 0.1442, s0.acc: 94.9312, s0.loss_bbox: 0.1653, s1.loss_cls: 0.0342, s1.acc: 98.9492, s1.loss_bbox: 0.0388, loss: 0.4691, grad_norm: 3.0258\r\n",
      "2025-09-15 07:44:19,595 - mmrotate - INFO - Epoch [4][400/928]\tlr: 2.500e-03, eta: 6:15:46, time: 1.134, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0499, loss_rpn_bbox: 0.0257, s0.loss_cls: 0.1328, s0.acc: 95.3320, s0.loss_bbox: 0.1480, s1.loss_cls: 0.0332, s1.acc: 99.0337, s1.loss_bbox: 0.0327, loss: 0.4222, grad_norm: 2.9813\r\n",
      "2025-09-15 07:46:12,832 - mmrotate - INFO - Epoch [4][500/928]\tlr: 2.500e-03, eta: 6:13:57, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0572, loss_rpn_bbox: 0.0295, s0.loss_cls: 0.1314, s0.acc: 95.5039, s0.loss_bbox: 0.1527, s1.loss_cls: 0.0344, s1.acc: 98.9902, s1.loss_bbox: 0.0336, loss: 0.4388, grad_norm: 2.8890\r\n",
      "2025-09-15 07:48:06,551 - mmrotate - INFO - Epoch [4][600/928]\tlr: 2.500e-03, eta: 6:12:11, time: 1.137, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0461, loss_rpn_bbox: 0.0251, s0.loss_cls: 0.1427, s0.acc: 94.9048, s0.loss_bbox: 0.1593, s1.loss_cls: 0.0312, s1.acc: 99.0239, s1.loss_bbox: 0.0352, loss: 0.4395, grad_norm: 2.9470\r\n",
      "2025-09-15 07:50:00,527 - mmrotate - INFO - Epoch [4][700/928]\tlr: 2.500e-03, eta: 6:10:25, time: 1.140, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0533, loss_rpn_bbox: 0.0308, s0.loss_cls: 0.1417, s0.acc: 95.0444, s0.loss_bbox: 0.1496, s1.loss_cls: 0.0321, s1.acc: 99.0352, s1.loss_bbox: 0.0385, loss: 0.4459, grad_norm: 2.9330\r\n",
      "2025-09-15 07:51:54,367 - mmrotate - INFO - Epoch [4][800/928]\tlr: 2.500e-03, eta: 6:08:39, time: 1.138, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0520, loss_rpn_bbox: 0.0286, s0.loss_cls: 0.1334, s0.acc: 95.2998, s0.loss_bbox: 0.1561, s1.loss_cls: 0.0295, s1.acc: 99.0815, s1.loss_bbox: 0.0354, loss: 0.4349, grad_norm: 2.9560\r\n",
      "2025-09-15 07:53:47,974 - mmrotate - INFO - Epoch [4][900/928]\tlr: 2.500e-03, eta: 6:06:51, time: 1.136, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0457, loss_rpn_bbox: 0.0270, s0.loss_cls: 0.1295, s0.acc: 95.4873, s0.loss_bbox: 0.1523, s1.loss_cls: 0.0323, s1.acc: 99.0171, s1.loss_bbox: 0.0352, loss: 0.4219, grad_norm: 3.0229\r\n",
      "2025-09-15 07:54:19,598 - mmrotate - INFO - Saving checkpoint at 4 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 142s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 07:56:50,033 - mmrotate - INFO - \r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| class | gts  | dets  | recall | ap    |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| ship  | 1744 | 10342 | 0.365  | 0.243 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| mAP   |      |       |        | 0.243 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "2025-09-15 07:56:50,187 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_3.pth was removed\r\n",
      "2025-09-15 07:56:51,268 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_4.pth.\r\n",
      "2025-09-15 07:56:51,269 - mmrotate - INFO - Best mAP is 0.2431 at 4 epoch.\r\n",
      "2025-09-15 07:56:51,270 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 07:56:51,270 - mmrotate - INFO - Epoch(val) [4][464]\tmAP: 0.2431\r\n",
      "2025-09-15 07:58:47,688 - mmrotate - INFO - Epoch [5][100/928]\tlr: 2.500e-03, eta: 6:02:04, time: 1.163, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0487, loss_rpn_bbox: 0.0272, s0.loss_cls: 0.1397, s0.acc: 94.9819, s0.loss_bbox: 0.1699, s1.loss_cls: 0.0333, s1.acc: 98.9937, s1.loss_bbox: 0.0393, loss: 0.4582, grad_norm: 3.1117\r\n",
      "2025-09-15 08:00:40,987 - mmrotate - INFO - Epoch [5][200/928]\tlr: 2.500e-03, eta: 6:00:18, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0465, loss_rpn_bbox: 0.0258, s0.loss_cls: 0.1324, s0.acc: 95.2407, s0.loss_bbox: 0.1441, s1.loss_cls: 0.0352, s1.acc: 98.9062, s1.loss_bbox: 0.0443, loss: 0.4283, grad_norm: 2.7728\r\n",
      "2025-09-15 08:02:34,231 - mmrotate - INFO - Epoch [5][300/928]\tlr: 2.500e-03, eta: 5:58:31, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0484, loss_rpn_bbox: 0.0280, s0.loss_cls: 0.1373, s0.acc: 95.0337, s0.loss_bbox: 0.1605, s1.loss_cls: 0.0348, s1.acc: 98.8794, s1.loss_bbox: 0.0432, loss: 0.4523, grad_norm: 3.1416\r\n",
      "2025-09-15 08:04:27,613 - mmrotate - INFO - Epoch [5][400/928]\tlr: 2.500e-03, eta: 5:56:45, time: 1.134, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0482, loss_rpn_bbox: 0.0286, s0.loss_cls: 0.1374, s0.acc: 95.1265, s0.loss_bbox: 0.1484, s1.loss_cls: 0.0350, s1.acc: 98.8950, s1.loss_bbox: 0.0416, loss: 0.4392, grad_norm: 2.8982\r\n",
      "2025-09-15 08:06:21,076 - mmrotate - INFO - Epoch [5][500/928]\tlr: 2.500e-03, eta: 5:54:59, time: 1.135, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0458, loss_rpn_bbox: 0.0221, s0.loss_cls: 0.1278, s0.acc: 95.4067, s0.loss_bbox: 0.1398, s1.loss_cls: 0.0315, s1.acc: 98.9795, s1.loss_bbox: 0.0408, loss: 0.4079, grad_norm: 2.8901\r\n",
      "2025-09-15 08:08:14,806 - mmrotate - INFO - Epoch [5][600/928]\tlr: 2.500e-03, eta: 5:53:14, time: 1.137, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0422, loss_rpn_bbox: 0.0224, s0.loss_cls: 0.1272, s0.acc: 95.3613, s0.loss_bbox: 0.1427, s1.loss_cls: 0.0321, s1.acc: 98.9897, s1.loss_bbox: 0.0431, loss: 0.4097, grad_norm: 2.8797\r\n",
      "2025-09-15 08:10:08,727 - mmrotate - INFO - Epoch [5][700/928]\tlr: 2.500e-03, eta: 5:51:29, time: 1.139, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0263, s0.loss_cls: 0.1282, s0.acc: 95.3096, s0.loss_bbox: 0.1403, s1.loss_cls: 0.0348, s1.acc: 98.8359, s1.loss_bbox: 0.0481, loss: 0.4209, grad_norm: 2.8984\r\n",
      "2025-09-15 08:12:01,960 - mmrotate - INFO - Epoch [5][800/928]\tlr: 2.500e-03, eta: 5:49:40, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0479, loss_rpn_bbox: 0.0284, s0.loss_cls: 0.1438, s0.acc: 94.7354, s0.loss_bbox: 0.1627, s1.loss_cls: 0.0366, s1.acc: 98.7671, s1.loss_bbox: 0.0495, loss: 0.4689, grad_norm: 2.9840\r\n",
      "2025-09-15 08:13:54,862 - mmrotate - INFO - Epoch [5][900/928]\tlr: 2.500e-03, eta: 5:47:51, time: 1.129, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0406, loss_rpn_bbox: 0.0267, s0.loss_cls: 0.1342, s0.acc: 95.1514, s0.loss_bbox: 0.1592, s1.loss_cls: 0.0348, s1.acc: 98.8291, s1.loss_bbox: 0.0483, loss: 0.4437, grad_norm: 2.9169\r\n",
      "2025-09-15 08:14:26,547 - mmrotate - INFO - Saving checkpoint at 5 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 140s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 08:16:55,412 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 6802 | 0.490  | 0.336 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.336 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 08:16:55,564 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_4.pth was removed\r\n",
      "2025-09-15 08:16:56,692 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_5.pth.\r\n",
      "2025-09-15 08:16:56,693 - mmrotate - INFO - Best mAP is 0.3356 at 5 epoch.\r\n",
      "2025-09-15 08:16:56,694 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 08:16:56,694 - mmrotate - INFO - Epoch(val) [5][464]\tmAP: 0.3356\r\n",
      "2025-09-15 08:18:53,337 - mmrotate - INFO - Epoch [6][100/928]\tlr: 2.500e-03, eta: 5:43:41, time: 1.166, data_time: 0.045, memory: 6886, loss_rpn_cls: 0.0415, loss_rpn_bbox: 0.0248, s0.loss_cls: 0.1383, s0.acc: 94.8599, s0.loss_bbox: 0.1509, s1.loss_cls: 0.0374, s1.acc: 98.7314, s1.loss_bbox: 0.0519, loss: 0.4447, grad_norm: 2.9398\r\n",
      "2025-09-15 08:20:46,265 - mmrotate - INFO - Epoch [6][200/928]\tlr: 2.500e-03, eta: 5:41:54, time: 1.129, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0371, loss_rpn_bbox: 0.0225, s0.loss_cls: 0.1255, s0.acc: 95.4487, s0.loss_bbox: 0.1662, s1.loss_cls: 0.0346, s1.acc: 98.8550, s1.loss_bbox: 0.0482, loss: 0.4341, grad_norm: 2.8972\r\n",
      "2025-09-15 08:22:40,169 - mmrotate - INFO - Epoch [6][300/928]\tlr: 2.500e-03, eta: 5:40:10, time: 1.139, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0403, loss_rpn_bbox: 0.0248, s0.loss_cls: 0.1267, s0.acc: 95.3926, s0.loss_bbox: 0.1347, s1.loss_cls: 0.0365, s1.acc: 98.7856, s1.loss_bbox: 0.0512, loss: 0.4142, grad_norm: 2.7605\r\n",
      "2025-09-15 08:24:32,805 - mmrotate - INFO - Epoch [6][400/928]\tlr: 2.500e-03, eta: 5:38:22, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0377, loss_rpn_bbox: 0.0234, s0.loss_cls: 0.1212, s0.acc: 95.5068, s0.loss_bbox: 0.1388, s1.loss_cls: 0.0332, s1.acc: 98.8447, s1.loss_bbox: 0.0515, loss: 0.4059, grad_norm: 2.7292\r\n",
      "2025-09-15 08:26:24,851 - mmrotate - INFO - Epoch [6][500/928]\tlr: 2.500e-03, eta: 5:36:31, time: 1.120, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0355, loss_rpn_bbox: 0.0218, s0.loss_cls: 0.1261, s0.acc: 95.4390, s0.loss_bbox: 0.1463, s1.loss_cls: 0.0348, s1.acc: 98.8291, s1.loss_bbox: 0.0503, loss: 0.4148, grad_norm: 2.9381\r\n",
      "2025-09-15 08:28:16,917 - mmrotate - INFO - Epoch [6][600/928]\tlr: 2.500e-03, eta: 5:34:40, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0421, loss_rpn_bbox: 0.0273, s0.loss_cls: 0.1327, s0.acc: 95.0654, s0.loss_bbox: 0.1480, s1.loss_cls: 0.0383, s1.acc: 98.7036, s1.loss_bbox: 0.0545, loss: 0.4429, grad_norm: 2.9001\r\n",
      "2025-09-15 08:30:08,935 - mmrotate - INFO - Epoch [6][700/928]\tlr: 2.500e-03, eta: 5:32:49, time: 1.120, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0416, loss_rpn_bbox: 0.0263, s0.loss_cls: 0.1312, s0.acc: 95.1318, s0.loss_bbox: 0.1543, s1.loss_cls: 0.0388, s1.acc: 98.6582, s1.loss_bbox: 0.0545, loss: 0.4467, grad_norm: 3.0682\r\n",
      "2025-09-15 08:32:01,302 - mmrotate - INFO - Epoch [6][800/928]\tlr: 2.500e-03, eta: 5:30:59, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0369, loss_rpn_bbox: 0.0236, s0.loss_cls: 0.1229, s0.acc: 95.4683, s0.loss_bbox: 0.1397, s1.loss_cls: 0.0347, s1.acc: 98.7681, s1.loss_bbox: 0.0526, loss: 0.4105, grad_norm: 2.8390\r\n",
      "2025-09-15 08:33:53,391 - mmrotate - INFO - Epoch [6][900/928]\tlr: 2.500e-03, eta: 5:29:08, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0473, loss_rpn_bbox: 0.0258, s0.loss_cls: 0.1273, s0.acc: 95.3330, s0.loss_bbox: 0.1520, s1.loss_cls: 0.0388, s1.acc: 98.6577, s1.loss_bbox: 0.0579, loss: 0.4490, grad_norm: 2.9880\r\n",
      "2025-09-15 08:34:24,971 - mmrotate - INFO - Saving checkpoint at 6 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.4 task/s, elapsed: 138s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 08:36:52,087 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 6962 | 0.529  | 0.374 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.374 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 08:36:52,242 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_5.pth was removed\r\n",
      "2025-09-15 08:36:53,323 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_6.pth.\r\n",
      "2025-09-15 08:36:53,324 - mmrotate - INFO - Best mAP is 0.3743 at 6 epoch.\r\n",
      "2025-09-15 08:36:53,324 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 08:36:53,324 - mmrotate - INFO - Epoch(val) [6][464]\tmAP: 0.3743\r\n",
      "2025-09-15 08:38:47,909 - mmrotate - INFO - Epoch [7][100/928]\tlr: 2.500e-03, eta: 5:25:16, time: 1.145, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0346, loss_rpn_bbox: 0.0217, s0.loss_cls: 0.1263, s0.acc: 95.2959, s0.loss_bbox: 0.1422, s1.loss_cls: 0.0371, s1.acc: 98.6865, s1.loss_bbox: 0.0595, loss: 0.4214, grad_norm: 2.7387\r\n",
      "2025-09-15 08:40:40,486 - mmrotate - INFO - Epoch [7][200/928]\tlr: 2.500e-03, eta: 5:23:29, time: 1.126, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0257, s0.loss_cls: 0.1381, s0.acc: 94.9487, s0.loss_bbox: 0.1681, s1.loss_cls: 0.0423, s1.acc: 98.5278, s1.loss_bbox: 0.0576, loss: 0.4749, grad_norm: 3.1596\r\n",
      "2025-09-15 08:42:33,493 - mmrotate - INFO - Epoch [7][300/928]\tlr: 2.500e-03, eta: 5:21:42, time: 1.130, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0382, loss_rpn_bbox: 0.0255, s0.loss_cls: 0.1361, s0.acc: 94.9907, s0.loss_bbox: 0.1538, s1.loss_cls: 0.0390, s1.acc: 98.6377, s1.loss_bbox: 0.0624, loss: 0.4550, grad_norm: 2.9780\r\n",
      "2025-09-15 08:44:26,048 - mmrotate - INFO - Epoch [7][400/928]\tlr: 2.500e-03, eta: 5:19:54, time: 1.126, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0333, loss_rpn_bbox: 0.0216, s0.loss_cls: 0.1255, s0.acc: 95.3154, s0.loss_bbox: 0.1442, s1.loss_cls: 0.0411, s1.acc: 98.5356, s1.loss_bbox: 0.0662, loss: 0.4318, grad_norm: 2.7405\r\n",
      "2025-09-15 08:46:19,210 - mmrotate - INFO - Epoch [7][500/928]\tlr: 2.500e-03, eta: 5:18:08, time: 1.132, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0371, loss_rpn_bbox: 0.0262, s0.loss_cls: 0.1180, s0.acc: 95.6455, s0.loss_bbox: 0.1484, s1.loss_cls: 0.0364, s1.acc: 98.7510, s1.loss_bbox: 0.0559, loss: 0.4220, grad_norm: 2.9571\r\n",
      "2025-09-15 08:48:11,898 - mmrotate - INFO - Epoch [7][600/928]\tlr: 2.500e-03, eta: 5:16:20, time: 1.127, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0371, loss_rpn_bbox: 0.0237, s0.loss_cls: 0.1256, s0.acc: 95.3696, s0.loss_bbox: 0.1453, s1.loss_cls: 0.0399, s1.acc: 98.5542, s1.loss_bbox: 0.0648, loss: 0.4364, grad_norm: 2.9077\r\n",
      "2025-09-15 08:50:04,402 - mmrotate - INFO - Epoch [7][700/928]\tlr: 2.500e-03, eta: 5:14:31, time: 1.125, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0288, loss_rpn_bbox: 0.0194, s0.loss_cls: 0.1088, s0.acc: 95.9883, s0.loss_bbox: 0.1204, s1.loss_cls: 0.0346, s1.acc: 98.7852, s1.loss_bbox: 0.0572, loss: 0.3692, grad_norm: 2.5996\r\n",
      "2025-09-15 08:51:56,601 - mmrotate - INFO - Epoch [7][800/928]\tlr: 2.500e-03, eta: 5:12:42, time: 1.122, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0315, loss_rpn_bbox: 0.0209, s0.loss_cls: 0.1105, s0.acc: 95.8628, s0.loss_bbox: 0.1336, s1.loss_cls: 0.0382, s1.acc: 98.6147, s1.loss_bbox: 0.0621, loss: 0.3969, grad_norm: 2.8031\r\n",
      "2025-09-15 08:53:48,695 - mmrotate - INFO - Epoch [7][900/928]\tlr: 2.500e-03, eta: 5:10:52, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.0242, s0.loss_cls: 0.1186, s0.acc: 95.6523, s0.loss_bbox: 0.1406, s1.loss_cls: 0.0414, s1.acc: 98.5024, s1.loss_bbox: 0.0655, loss: 0.4254, grad_norm: 2.8226\r\n",
      "2025-09-15 08:54:19,996 - mmrotate - INFO - Saving checkpoint at 7 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 139s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 08:56:47,684 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4032 | 0.601  | 0.503 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.503 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 08:56:47,845 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_6.pth was removed\r\n",
      "2025-09-15 08:56:48,930 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_7.pth.\r\n",
      "2025-09-15 08:56:48,931 - mmrotate - INFO - Best mAP is 0.5025 at 7 epoch.\r\n",
      "2025-09-15 08:56:48,932 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 08:56:48,932 - mmrotate - INFO - Epoch(val) [7][464]\tmAP: 0.5025\r\n",
      "2025-09-15 08:58:43,797 - mmrotate - INFO - Epoch [8][100/928]\tlr: 2.500e-03, eta: 5:07:19, time: 1.148, data_time: 0.045, memory: 6886, loss_rpn_cls: 0.0311, loss_rpn_bbox: 0.0232, s0.loss_cls: 0.1262, s0.acc: 95.1733, s0.loss_bbox: 0.1533, s1.loss_cls: 0.0454, s1.acc: 98.3628, s1.loss_bbox: 0.0771, loss: 0.4562, grad_norm: 2.8849\r\n",
      "2025-09-15 09:00:35,958 - mmrotate - INFO - Epoch [8][200/928]\tlr: 2.500e-03, eta: 5:05:31, time: 1.122, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0343, loss_rpn_bbox: 0.0243, s0.loss_cls: 0.1235, s0.acc: 95.3789, s0.loss_bbox: 0.1483, s1.loss_cls: 0.0430, s1.acc: 98.4751, s1.loss_bbox: 0.0703, loss: 0.4437, grad_norm: 2.8637\r\n",
      "2025-09-15 09:02:28,142 - mmrotate - INFO - Epoch [8][300/928]\tlr: 2.500e-03, eta: 5:03:42, time: 1.122, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0284, loss_rpn_bbox: 0.0225, s0.loss_cls: 0.1230, s0.acc: 95.4629, s0.loss_bbox: 0.1439, s1.loss_cls: 0.0416, s1.acc: 98.4819, s1.loss_bbox: 0.0697, loss: 0.4292, grad_norm: 2.9364\r\n",
      "2025-09-15 09:04:20,919 - mmrotate - INFO - Epoch [8][400/928]\tlr: 2.500e-03, eta: 5:01:55, time: 1.128, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0334, loss_rpn_bbox: 0.0205, s0.loss_cls: 0.1197, s0.acc: 95.5884, s0.loss_bbox: 0.1287, s1.loss_cls: 0.0407, s1.acc: 98.5034, s1.loss_bbox: 0.0690, loss: 0.4121, grad_norm: 2.7586\r\n",
      "2025-09-15 09:06:14,053 - mmrotate - INFO - Epoch [8][500/928]\tlr: 2.500e-03, eta: 5:00:09, time: 1.131, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0282, loss_rpn_bbox: 0.0198, s0.loss_cls: 0.1156, s0.acc: 95.7075, s0.loss_bbox: 0.1336, s1.loss_cls: 0.0383, s1.acc: 98.6260, s1.loss_bbox: 0.0670, loss: 0.4026, grad_norm: 2.9271\r\n",
      "2025-09-15 09:08:06,913 - mmrotate - INFO - Epoch [8][600/928]\tlr: 2.500e-03, eta: 4:58:22, time: 1.129, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0307, loss_rpn_bbox: 0.0219, s0.loss_cls: 0.1181, s0.acc: 95.5840, s0.loss_bbox: 0.1411, s1.loss_cls: 0.0425, s1.acc: 98.4707, s1.loss_bbox: 0.0711, loss: 0.4255, grad_norm: 2.8261\r\n",
      "2025-09-15 09:09:59,311 - mmrotate - INFO - Epoch [8][700/928]\tlr: 2.500e-03, eta: 4:56:33, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0351, loss_rpn_bbox: 0.0205, s0.loss_cls: 0.1173, s0.acc: 95.6416, s0.loss_bbox: 0.1328, s1.loss_cls: 0.0425, s1.acc: 98.5098, s1.loss_bbox: 0.0686, loss: 0.4168, grad_norm: 2.9219\r\n",
      "2025-09-15 09:11:51,985 - mmrotate - INFO - Epoch [8][800/928]\tlr: 2.500e-03, eta: 4:54:45, time: 1.127, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0332, loss_rpn_bbox: 0.0223, s0.loss_cls: 0.1265, s0.acc: 95.2109, s0.loss_bbox: 0.1524, s1.loss_cls: 0.0464, s1.acc: 98.3032, s1.loss_bbox: 0.0761, loss: 0.4569, grad_norm: 3.0827\r\n",
      "2025-09-15 09:13:46,581 - mmrotate - INFO - Epoch [8][900/928]\tlr: 2.500e-03, eta: 4:53:01, time: 1.146, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0192, s0.loss_cls: 0.1138, s0.acc: 95.7339, s0.loss_bbox: 0.1316, s1.loss_cls: 0.0423, s1.acc: 98.5103, s1.loss_bbox: 0.0720, loss: 0.4059, grad_norm: 2.7873\r\n",
      "2025-09-15 09:14:18,798 - mmrotate - INFO - Saving checkpoint at 8 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.2 task/s, elapsed: 143s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 09:16:50,452 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 6602 | 0.667  | 0.532 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.532 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 09:16:50,612 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_7.pth was removed\r\n",
      "2025-09-15 09:16:51,763 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_8.pth.\r\n",
      "2025-09-15 09:16:51,764 - mmrotate - INFO - Best mAP is 0.5318 at 8 epoch.\r\n",
      "2025-09-15 09:16:51,765 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 09:16:51,765 - mmrotate - INFO - Epoch(val) [8][464]\tmAP: 0.5318\r\n",
      "2025-09-15 09:18:47,089 - mmrotate - INFO - Epoch [9][100/928]\tlr: 2.500e-04, eta: 4:49:42, time: 1.153, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0300, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1182, s0.acc: 95.6123, s0.loss_bbox: 0.1252, s1.loss_cls: 0.0451, s1.acc: 98.4263, s1.loss_bbox: 0.0746, loss: 0.4107, grad_norm: 2.8323\r\n",
      "2025-09-15 09:20:39,216 - mmrotate - INFO - Epoch [9][200/928]\tlr: 2.500e-04, eta: 4:47:54, time: 1.121, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0268, loss_rpn_bbox: 0.0173, s0.loss_cls: 0.1074, s0.acc: 95.9360, s0.loss_bbox: 0.1164, s1.loss_cls: 0.0413, s1.acc: 98.4990, s1.loss_bbox: 0.0759, loss: 0.3852, grad_norm: 2.5863\r\n",
      "2025-09-15 09:22:31,811 - mmrotate - INFO - Epoch [9][300/928]\tlr: 2.500e-04, eta: 4:46:07, time: 1.126, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0278, loss_rpn_bbox: 0.0185, s0.loss_cls: 0.1142, s0.acc: 95.6523, s0.loss_bbox: 0.1219, s1.loss_cls: 0.0450, s1.acc: 98.3174, s1.loss_bbox: 0.0809, loss: 0.4082, grad_norm: 2.6485\r\n",
      "2025-09-15 09:24:23,964 - mmrotate - INFO - Epoch [9][400/928]\tlr: 2.500e-04, eta: 4:44:18, time: 1.122, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0280, loss_rpn_bbox: 0.0202, s0.loss_cls: 0.1080, s0.acc: 95.9453, s0.loss_bbox: 0.1142, s1.loss_cls: 0.0436, s1.acc: 98.3970, s1.loss_bbox: 0.0761, loss: 0.3901, grad_norm: 2.6138\r\n",
      "2025-09-15 09:26:16,531 - mmrotate - INFO - Epoch [9][500/928]\tlr: 2.500e-04, eta: 4:42:30, time: 1.126, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0264, loss_rpn_bbox: 0.0179, s0.loss_cls: 0.1159, s0.acc: 95.6826, s0.loss_bbox: 0.1300, s1.loss_cls: 0.0453, s1.acc: 98.3286, s1.loss_bbox: 0.0797, loss: 0.4151, grad_norm: 2.7085\r\n",
      "2025-09-15 09:28:09,251 - mmrotate - INFO - Epoch [9][600/928]\tlr: 2.500e-04, eta: 4:40:43, time: 1.127, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0181, s0.loss_cls: 0.1117, s0.acc: 95.7017, s0.loss_bbox: 0.1195, s1.loss_cls: 0.0438, s1.acc: 98.3491, s1.loss_bbox: 0.0806, loss: 0.4005, grad_norm: 2.5833\r\n",
      "2025-09-15 09:30:02,071 - mmrotate - INFO - Epoch [9][700/928]\tlr: 2.500e-04, eta: 4:38:55, time: 1.128, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0227, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.1044, s0.acc: 96.0259, s0.loss_bbox: 0.1157, s1.loss_cls: 0.0398, s1.acc: 98.5132, s1.loss_bbox: 0.0717, loss: 0.3713, grad_norm: 2.5158\r\n",
      "2025-09-15 09:31:54,420 - mmrotate - INFO - Epoch [9][800/928]\tlr: 2.500e-04, eta: 4:37:06, time: 1.123, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.1047, s0.acc: 96.0449, s0.loss_bbox: 0.1058, s1.loss_cls: 0.0409, s1.acc: 98.4473, s1.loss_bbox: 0.0757, loss: 0.3691, grad_norm: 2.6173\r\n",
      "2025-09-15 09:33:46,841 - mmrotate - INFO - Epoch [9][900/928]\tlr: 2.500e-04, eta: 4:35:18, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.0198, s0.loss_cls: 0.1101, s0.acc: 95.7432, s0.loss_bbox: 0.1250, s1.loss_cls: 0.0423, s1.acc: 98.3643, s1.loss_bbox: 0.0829, loss: 0.4053, grad_norm: 2.6097\r\n",
      "2025-09-15 09:34:18,325 - mmrotate - INFO - Saving checkpoint at 9 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 139s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 09:36:46,557 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4684 | 0.684  | 0.568 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.568 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 09:36:46,716 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_8.pth was removed\r\n",
      "2025-09-15 09:36:47,860 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_9.pth.\r\n",
      "2025-09-15 09:36:47,861 - mmrotate - INFO - Best mAP is 0.5677 at 9 epoch.\r\n",
      "2025-09-15 09:36:47,861 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 09:36:47,862 - mmrotate - INFO - Epoch(val) [9][464]\tmAP: 0.5677\r\n",
      "2025-09-15 09:38:42,609 - mmrotate - INFO - Epoch [10][100/928]\tlr: 2.500e-04, eta: 4:32:08, time: 1.147, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1055, s0.acc: 96.0337, s0.loss_bbox: 0.1117, s1.loss_cls: 0.0418, s1.acc: 98.4604, s1.loss_bbox: 0.0736, loss: 0.3731, grad_norm: 2.5270\r\n",
      "2025-09-15 09:40:34,903 - mmrotate - INFO - Epoch [10][200/928]\tlr: 2.500e-04, eta: 4:30:20, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0286, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.1193, s0.acc: 95.4648, s0.loss_bbox: 0.1270, s1.loss_cls: 0.0468, s1.acc: 98.2476, s1.loss_bbox: 0.0834, loss: 0.4240, grad_norm: 2.7470\r\n",
      "2025-09-15 09:42:26,873 - mmrotate - INFO - Epoch [10][300/928]\tlr: 2.500e-04, eta: 4:28:31, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0275, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.1039, s0.acc: 96.1221, s0.loss_bbox: 0.1146, s1.loss_cls: 0.0436, s1.acc: 98.3867, s1.loss_bbox: 0.0788, loss: 0.3855, grad_norm: 2.6621\r\n",
      "2025-09-15 09:44:18,910 - mmrotate - INFO - Epoch [10][400/928]\tlr: 2.500e-04, eta: 4:26:43, time: 1.120, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.0285, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.1089, s0.acc: 95.9233, s0.loss_bbox: 0.1199, s1.loss_cls: 0.0432, s1.acc: 98.4072, s1.loss_bbox: 0.0801, loss: 0.3991, grad_norm: 2.8502\r\n",
      "2025-09-15 09:46:11,238 - mmrotate - INFO - Epoch [10][500/928]\tlr: 2.500e-04, eta: 4:24:54, time: 1.123, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.0169, s0.loss_cls: 0.1040, s0.acc: 96.1035, s0.loss_bbox: 0.1027, s1.loss_cls: 0.0398, s1.acc: 98.5283, s1.loss_bbox: 0.0721, loss: 0.3604, grad_norm: 2.4800\r\n",
      "2025-09-15 09:48:03,846 - mmrotate - INFO - Epoch [10][600/928]\tlr: 2.500e-04, eta: 4:23:07, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.1024, s0.acc: 96.0674, s0.loss_bbox: 0.1089, s1.loss_cls: 0.0410, s1.acc: 98.4258, s1.loss_bbox: 0.0781, loss: 0.3699, grad_norm: 2.5306\r\n",
      "2025-09-15 09:49:56,244 - mmrotate - INFO - Epoch [10][700/928]\tlr: 2.500e-04, eta: 4:21:18, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0264, loss_rpn_bbox: 0.0188, s0.loss_cls: 0.1082, s0.acc: 95.9023, s0.loss_bbox: 0.1262, s1.loss_cls: 0.0448, s1.acc: 98.3545, s1.loss_bbox: 0.0799, loss: 0.4042, grad_norm: 2.8619\r\n",
      "2025-09-15 09:51:48,248 - mmrotate - INFO - Epoch [10][800/928]\tlr: 2.500e-04, eta: 4:19:29, time: 1.120, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.1040, s0.acc: 96.0366, s0.loss_bbox: 0.1121, s1.loss_cls: 0.0419, s1.acc: 98.4346, s1.loss_bbox: 0.0766, loss: 0.3729, grad_norm: 2.6218\r\n",
      "2025-09-15 09:53:40,853 - mmrotate - INFO - Epoch [10][900/928]\tlr: 2.500e-04, eta: 4:17:41, time: 1.126, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0258, loss_rpn_bbox: 0.0192, s0.loss_cls: 0.1101, s0.acc: 95.8608, s0.loss_bbox: 0.1221, s1.loss_cls: 0.0438, s1.acc: 98.3999, s1.loss_bbox: 0.0790, loss: 0.4000, grad_norm: 2.6841\r\n",
      "2025-09-15 09:54:12,464 - mmrotate - INFO - Saving checkpoint at 10 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 140s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 09:56:41,391 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5056 | 0.705  | 0.597 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.597 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 09:56:41,563 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_9.pth was removed\r\n",
      "2025-09-15 09:56:42,657 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_10.pth.\r\n",
      "2025-09-15 09:56:42,658 - mmrotate - INFO - Best mAP is 0.5965 at 10 epoch.\r\n",
      "2025-09-15 09:56:42,659 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 09:56:42,659 - mmrotate - INFO - Epoch(val) [10][464]\tmAP: 0.5965\r\n",
      "2025-09-15 09:58:37,849 - mmrotate - INFO - Epoch [11][100/928]\tlr: 2.500e-04, eta: 4:14:40, time: 1.151, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.0182, s0.loss_cls: 0.1071, s0.acc: 95.9712, s0.loss_bbox: 0.1125, s1.loss_cls: 0.0444, s1.acc: 98.3589, s1.loss_bbox: 0.0824, loss: 0.3916, grad_norm: 2.5863\r\n",
      "2025-09-15 10:00:30,122 - mmrotate - INFO - Epoch [11][200/928]\tlr: 2.500e-04, eta: 4:12:52, time: 1.123, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0258, loss_rpn_bbox: 0.0181, s0.loss_cls: 0.1097, s0.acc: 95.8477, s0.loss_bbox: 0.1088, s1.loss_cls: 0.0440, s1.acc: 98.3691, s1.loss_bbox: 0.0766, loss: 0.3830, grad_norm: 2.6291\r\n",
      "2025-09-15 10:02:22,252 - mmrotate - INFO - Epoch [11][300/928]\tlr: 2.500e-04, eta: 4:11:03, time: 1.121, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0289, loss_rpn_bbox: 0.0176, s0.loss_cls: 0.1096, s0.acc: 95.8896, s0.loss_bbox: 0.1159, s1.loss_cls: 0.0446, s1.acc: 98.3667, s1.loss_bbox: 0.0766, loss: 0.3932, grad_norm: 2.7775\r\n",
      "2025-09-15 10:04:14,529 - mmrotate - INFO - Epoch [11][400/928]\tlr: 2.500e-04, eta: 4:09:15, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0176, s0.loss_cls: 0.1053, s0.acc: 95.9927, s0.loss_bbox: 0.1184, s1.loss_cls: 0.0429, s1.acc: 98.3784, s1.loss_bbox: 0.0783, loss: 0.3887, grad_norm: 2.5778\r\n",
      "2025-09-15 10:06:06,552 - mmrotate - INFO - Epoch [11][500/928]\tlr: 2.500e-04, eta: 4:07:26, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0176, s0.loss_cls: 0.1097, s0.acc: 95.7847, s0.loss_bbox: 0.1146, s1.loss_cls: 0.0431, s1.acc: 98.3701, s1.loss_bbox: 0.0818, loss: 0.3910, grad_norm: 2.6726\r\n",
      "2025-09-15 10:07:58,892 - mmrotate - INFO - Epoch [11][600/928]\tlr: 2.500e-04, eta: 4:05:38, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.0185, s0.loss_cls: 0.1092, s0.acc: 95.8901, s0.loss_bbox: 0.1120, s1.loss_cls: 0.0446, s1.acc: 98.3340, s1.loss_bbox: 0.0799, loss: 0.3898, grad_norm: 2.7266\r\n",
      "2025-09-15 10:09:50,958 - mmrotate - INFO - Epoch [11][700/928]\tlr: 2.500e-04, eta: 4:03:49, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.1007, s0.acc: 96.2715, s0.loss_bbox: 0.1095, s1.loss_cls: 0.0382, s1.acc: 98.5742, s1.loss_bbox: 0.0702, loss: 0.3576, grad_norm: 2.6881\r\n",
      "2025-09-15 10:11:42,966 - mmrotate - INFO - Epoch [11][800/928]\tlr: 2.500e-04, eta: 4:02:00, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1000, s0.acc: 96.1519, s0.loss_bbox: 0.1096, s1.loss_cls: 0.0413, s1.acc: 98.4351, s1.loss_bbox: 0.0754, loss: 0.3674, grad_norm: 2.5579\r\n",
      "2025-09-15 10:13:34,891 - mmrotate - INFO - Epoch [11][900/928]\tlr: 2.500e-04, eta: 4:00:11, time: 1.119, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1111, s0.acc: 95.7603, s0.loss_bbox: 0.1228, s1.loss_cls: 0.0455, s1.acc: 98.2651, s1.loss_bbox: 0.0815, loss: 0.4055, grad_norm: 2.7267\r\n",
      "2025-09-15 10:14:06,537 - mmrotate - INFO - Saving checkpoint at 11 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.4 task/s, elapsed: 138s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 10:16:33,494 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 6057 | 0.714  | 0.604 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.604 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 10:16:33,648 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_10.pth was removed\r\n",
      "2025-09-15 10:16:34,770 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_11.pth.\r\n",
      "2025-09-15 10:16:34,771 - mmrotate - INFO - Best mAP is 0.6039 at 11 epoch.\r\n",
      "2025-09-15 10:16:34,772 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 10:16:34,772 - mmrotate - INFO - Epoch(val) [11][464]\tmAP: 0.6039\r\n",
      "2025-09-15 10:18:29,247 - mmrotate - INFO - Epoch [12][100/928]\tlr: 2.500e-05, eta: 3:57:15, time: 1.144, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0177, s0.loss_cls: 0.1053, s0.acc: 95.9521, s0.loss_bbox: 0.1069, s1.loss_cls: 0.0429, s1.acc: 98.3965, s1.loss_bbox: 0.0793, loss: 0.3769, grad_norm: 2.5848\r\n",
      "2025-09-15 10:20:22,496 - mmrotate - INFO - Epoch [12][200/928]\tlr: 2.500e-05, eta: 3:55:28, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0271, loss_rpn_bbox: 0.0197, s0.loss_cls: 0.1078, s0.acc: 95.8794, s0.loss_bbox: 0.1143, s1.loss_cls: 0.0445, s1.acc: 98.3452, s1.loss_bbox: 0.0791, loss: 0.3924, grad_norm: 2.5386\r\n",
      "2025-09-15 10:22:14,773 - mmrotate - INFO - Epoch [12][300/928]\tlr: 2.500e-05, eta: 3:53:40, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.1006, s0.acc: 96.1401, s0.loss_bbox: 0.1032, s1.loss_cls: 0.0418, s1.acc: 98.4365, s1.loss_bbox: 0.0783, loss: 0.3632, grad_norm: 2.5521\r\n",
      "2025-09-15 10:24:06,527 - mmrotate - INFO - Epoch [12][400/928]\tlr: 2.500e-05, eta: 3:51:51, time: 1.118, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.1006, s0.acc: 96.1807, s0.loss_bbox: 0.1077, s1.loss_cls: 0.0430, s1.acc: 98.4033, s1.loss_bbox: 0.0782, loss: 0.3676, grad_norm: 2.5901\r\n",
      "2025-09-15 10:25:58,573 - mmrotate - INFO - Epoch [12][500/928]\tlr: 2.500e-05, eta: 3:50:03, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.1079, s0.acc: 95.9614, s0.loss_bbox: 0.1221, s1.loss_cls: 0.0439, s1.acc: 98.3774, s1.loss_bbox: 0.0803, loss: 0.4001, grad_norm: 2.8245\r\n",
      "2025-09-15 10:27:50,858 - mmrotate - INFO - Epoch [12][600/928]\tlr: 2.500e-05, eta: 3:48:14, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0253, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.1109, s0.acc: 95.7524, s0.loss_bbox: 0.1197, s1.loss_cls: 0.0460, s1.acc: 98.2378, s1.loss_bbox: 0.0847, loss: 0.4050, grad_norm: 2.6601\r\n",
      "2025-09-15 10:29:43,529 - mmrotate - INFO - Epoch [12][700/928]\tlr: 2.500e-05, eta: 3:46:26, time: 1.127, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0253, loss_rpn_bbox: 0.0173, s0.loss_cls: 0.1105, s0.acc: 95.8213, s0.loss_bbox: 0.1236, s1.loss_cls: 0.0438, s1.acc: 98.3735, s1.loss_bbox: 0.0818, loss: 0.4024, grad_norm: 2.7395\r\n",
      "2025-09-15 10:31:36,394 - mmrotate - INFO - Epoch [12][800/928]\tlr: 2.500e-05, eta: 3:44:38, time: 1.129, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.0951, s0.acc: 96.4746, s0.loss_bbox: 0.0954, s1.loss_cls: 0.0372, s1.acc: 98.6177, s1.loss_bbox: 0.0649, loss: 0.3330, grad_norm: 2.3882\r\n",
      "2025-09-15 10:33:28,670 - mmrotate - INFO - Epoch [12][900/928]\tlr: 2.500e-05, eta: 3:42:49, time: 1.123, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.1036, s0.acc: 96.1094, s0.loss_bbox: 0.1103, s1.loss_cls: 0.0416, s1.acc: 98.4531, s1.loss_bbox: 0.0738, loss: 0.3699, grad_norm: 2.6240\r\n",
      "2025-09-15 10:34:00,062 - mmrotate - INFO - Saving checkpoint at 12 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 140s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 10:36:28,583 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5335 | 0.716  | 0.612 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.612 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 10:36:28,738 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_11.pth was removed\r\n",
      "2025-09-15 10:36:29,867 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_12.pth.\r\n",
      "2025-09-15 10:36:29,868 - mmrotate - INFO - Best mAP is 0.6123 at 12 epoch.\r\n",
      "2025-09-15 10:36:29,869 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 10:36:29,869 - mmrotate - INFO - Epoch(val) [12][464]\tmAP: 0.6123\r\n",
      "2025-09-15 10:38:26,108 - mmrotate - INFO - Epoch [13][100/928]\tlr: 2.500e-05, eta: 3:40:01, time: 1.162, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.0194, s0.loss_cls: 0.1098, s0.acc: 95.8057, s0.loss_bbox: 0.1172, s1.loss_cls: 0.0427, s1.acc: 98.3740, s1.loss_bbox: 0.0800, loss: 0.3931, grad_norm: 2.6457\r\n",
      "2025-09-15 10:40:19,243 - mmrotate - INFO - Epoch [13][200/928]\tlr: 2.500e-05, eta: 3:38:14, time: 1.131, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0180, s0.loss_cls: 0.1072, s0.acc: 95.8750, s0.loss_bbox: 0.1136, s1.loss_cls: 0.0434, s1.acc: 98.3706, s1.loss_bbox: 0.0753, loss: 0.3825, grad_norm: 2.7071\r\n",
      "2025-09-15 10:42:12,644 - mmrotate - INFO - Epoch [13][300/928]\tlr: 2.500e-05, eta: 3:36:26, time: 1.134, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0253, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.1033, s0.acc: 96.1328, s0.loss_bbox: 0.1082, s1.loss_cls: 0.0410, s1.acc: 98.5166, s1.loss_bbox: 0.0735, loss: 0.3676, grad_norm: 2.6715\r\n",
      "2025-09-15 10:44:05,545 - mmrotate - INFO - Epoch [13][400/928]\tlr: 2.500e-05, eta: 3:34:38, time: 1.129, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.1014, s0.acc: 96.1768, s0.loss_bbox: 0.0996, s1.loss_cls: 0.0415, s1.acc: 98.4341, s1.loss_bbox: 0.0754, loss: 0.3541, grad_norm: 2.4530\r\n",
      "2025-09-15 10:46:00,010 - mmrotate - INFO - Epoch [13][500/928]\tlr: 2.500e-05, eta: 3:32:52, time: 1.145, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.1097, s0.acc: 95.7954, s0.loss_bbox: 0.1177, s1.loss_cls: 0.0448, s1.acc: 98.3096, s1.loss_bbox: 0.0826, loss: 0.3989, grad_norm: 2.7612\r\n",
      "2025-09-15 10:47:53,478 - mmrotate - INFO - Epoch [13][600/928]\tlr: 2.500e-05, eta: 3:31:05, time: 1.135, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.1021, s0.acc: 96.1543, s0.loss_bbox: 0.1222, s1.loss_cls: 0.0393, s1.acc: 98.5596, s1.loss_bbox: 0.0739, loss: 0.3789, grad_norm: 2.8625\r\n",
      "2025-09-15 10:49:47,418 - mmrotate - INFO - Epoch [13][700/928]\tlr: 2.500e-05, eta: 3:29:17, time: 1.139, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.1004, s0.acc: 96.1353, s0.loss_bbox: 0.1078, s1.loss_cls: 0.0415, s1.acc: 98.4438, s1.loss_bbox: 0.0797, loss: 0.3662, grad_norm: 2.5480\r\n",
      "2025-09-15 10:51:39,824 - mmrotate - INFO - Epoch [13][800/928]\tlr: 2.500e-05, eta: 3:27:29, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0274, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1038, s0.acc: 96.0996, s0.loss_bbox: 0.1098, s1.loss_cls: 0.0441, s1.acc: 98.3794, s1.loss_bbox: 0.0800, loss: 0.3818, grad_norm: 2.6114\r\n",
      "2025-09-15 10:53:31,970 - mmrotate - INFO - Epoch [13][900/928]\tlr: 2.500e-05, eta: 3:25:40, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1047, s0.acc: 96.0562, s0.loss_bbox: 0.1117, s1.loss_cls: 0.0429, s1.acc: 98.4106, s1.loss_bbox: 0.0756, loss: 0.3784, grad_norm: 2.5928\r\n",
      "2025-09-15 10:54:03,709 - mmrotate - INFO - Saving checkpoint at 13 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 139s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 10:56:31,810 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5847 | 0.722  | 0.611 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.611 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 10:56:31,894 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 10:56:31,895 - mmrotate - INFO - Epoch(val) [13][464]\tmAP: 0.6110\r\n",
      "2025-09-15 10:58:26,482 - mmrotate - INFO - Epoch [14][100/928]\tlr: 2.500e-05, eta: 3:22:54, time: 1.145, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0229, loss_rpn_bbox: 0.0173, s0.loss_cls: 0.1002, s0.acc: 96.2500, s0.loss_bbox: 0.1060, s1.loss_cls: 0.0407, s1.acc: 98.4600, s1.loss_bbox: 0.0768, loss: 0.3638, grad_norm: 2.5726\r\n",
      "2025-09-15 11:00:18,596 - mmrotate - INFO - Epoch [14][200/928]\tlr: 2.500e-05, eta: 3:21:05, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0261, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.1046, s0.acc: 95.9297, s0.loss_bbox: 0.1159, s1.loss_cls: 0.0439, s1.acc: 98.3057, s1.loss_bbox: 0.0853, loss: 0.3948, grad_norm: 2.6508\r\n",
      "2025-09-15 11:02:10,905 - mmrotate - INFO - Epoch [14][300/928]\tlr: 2.500e-05, eta: 3:19:16, time: 1.123, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0264, loss_rpn_bbox: 0.0178, s0.loss_cls: 0.1092, s0.acc: 95.7681, s0.loss_bbox: 0.1159, s1.loss_cls: 0.0442, s1.acc: 98.3506, s1.loss_bbox: 0.0776, loss: 0.3911, grad_norm: 2.6149\r\n",
      "2025-09-15 11:04:03,111 - mmrotate - INFO - Epoch [14][400/928]\tlr: 2.500e-05, eta: 3:17:28, time: 1.122, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.1091, s0.acc: 95.8911, s0.loss_bbox: 0.1177, s1.loss_cls: 0.0436, s1.acc: 98.4019, s1.loss_bbox: 0.0764, loss: 0.3884, grad_norm: 2.6560\r\n",
      "2025-09-15 11:05:55,137 - mmrotate - INFO - Epoch [14][500/928]\tlr: 2.500e-05, eta: 3:15:39, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0999, s0.acc: 96.2285, s0.loss_bbox: 0.1098, s1.loss_cls: 0.0405, s1.acc: 98.4351, s1.loss_bbox: 0.0742, loss: 0.3616, grad_norm: 2.5867\r\n",
      "2025-09-15 11:07:47,846 - mmrotate - INFO - Epoch [14][600/928]\tlr: 2.500e-05, eta: 3:13:50, time: 1.127, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.1020, s0.acc: 96.1099, s0.loss_bbox: 0.1083, s1.loss_cls: 0.0415, s1.acc: 98.4487, s1.loss_bbox: 0.0759, loss: 0.3686, grad_norm: 2.5606\r\n",
      "2025-09-15 11:09:40,785 - mmrotate - INFO - Epoch [14][700/928]\tlr: 2.500e-05, eta: 3:12:02, time: 1.129, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.1044, s0.acc: 96.0508, s0.loss_bbox: 0.1065, s1.loss_cls: 0.0428, s1.acc: 98.3877, s1.loss_bbox: 0.0804, loss: 0.3726, grad_norm: 2.6101\r\n",
      "2025-09-15 11:11:33,155 - mmrotate - INFO - Epoch [14][800/928]\tlr: 2.500e-05, eta: 3:10:13, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0273, loss_rpn_bbox: 0.0196, s0.loss_cls: 0.1179, s0.acc: 95.5605, s0.loss_bbox: 0.1252, s1.loss_cls: 0.0481, s1.acc: 98.1748, s1.loss_bbox: 0.0901, loss: 0.4282, grad_norm: 2.8280\r\n",
      "2025-09-15 11:13:25,174 - mmrotate - INFO - Epoch [14][900/928]\tlr: 2.500e-05, eta: 3:08:24, time: 1.120, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0282, loss_rpn_bbox: 0.0152, s0.loss_cls: 0.0984, s0.acc: 96.3560, s0.loss_bbox: 0.0944, s1.loss_cls: 0.0398, s1.acc: 98.5771, s1.loss_bbox: 0.0696, loss: 0.3456, grad_norm: 2.5635\r\n",
      "2025-09-15 11:13:56,620 - mmrotate - INFO - Saving checkpoint at 14 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 139s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 11:16:24,455 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5406 | 0.723  | 0.613 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.613 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 11:16:24,614 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_12.pth was removed\r\n",
      "2025-09-15 11:16:25,729 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_14.pth.\r\n",
      "2025-09-15 11:16:25,730 - mmrotate - INFO - Best mAP is 0.6129 at 14 epoch.\r\n",
      "2025-09-15 11:16:25,731 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 11:16:25,731 - mmrotate - INFO - Epoch(val) [14][464]\tmAP: 0.6129\r\n",
      "2025-09-15 11:18:20,446 - mmrotate - INFO - Epoch [15][100/928]\tlr: 2.500e-05, eta: 3:05:42, time: 1.147, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0264, loss_rpn_bbox: 0.0177, s0.loss_cls: 0.1020, s0.acc: 96.1841, s0.loss_bbox: 0.1103, s1.loss_cls: 0.0425, s1.acc: 98.4253, s1.loss_bbox: 0.0766, loss: 0.3755, grad_norm: 2.6422\r\n",
      "2025-09-15 11:20:12,460 - mmrotate - INFO - Epoch [15][200/928]\tlr: 2.500e-05, eta: 3:03:53, time: 1.120, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0164, s0.loss_cls: 0.1039, s0.acc: 96.0151, s0.loss_bbox: 0.1152, s1.loss_cls: 0.0403, s1.acc: 98.5063, s1.loss_bbox: 0.0748, loss: 0.3760, grad_norm: 2.6215\r\n",
      "2025-09-15 11:22:04,508 - mmrotate - INFO - Epoch [15][300/928]\tlr: 2.500e-05, eta: 3:02:04, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.1004, s0.acc: 96.1470, s0.loss_bbox: 0.1034, s1.loss_cls: 0.0418, s1.acc: 98.3979, s1.loss_bbox: 0.0816, loss: 0.3653, grad_norm: 2.4793\r\n",
      "2025-09-15 11:23:56,187 - mmrotate - INFO - Epoch [15][400/928]\tlr: 2.500e-05, eta: 3:00:15, time: 1.117, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.0294, loss_rpn_bbox: 0.0202, s0.loss_cls: 0.1055, s0.acc: 95.9844, s0.loss_bbox: 0.1138, s1.loss_cls: 0.0432, s1.acc: 98.3848, s1.loss_bbox: 0.0833, loss: 0.3954, grad_norm: 2.6955\r\n",
      "2025-09-15 11:25:49,373 - mmrotate - INFO - Epoch [15][500/928]\tlr: 2.500e-05, eta: 2:58:27, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.1026, s0.acc: 96.0757, s0.loss_bbox: 0.1162, s1.loss_cls: 0.0438, s1.acc: 98.3726, s1.loss_bbox: 0.0800, loss: 0.3800, grad_norm: 2.6876\r\n",
      "2025-09-15 11:27:41,934 - mmrotate - INFO - Epoch [15][600/928]\tlr: 2.500e-05, eta: 2:56:38, time: 1.126, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1041, s0.acc: 96.1357, s0.loss_bbox: 0.1052, s1.loss_cls: 0.0409, s1.acc: 98.5083, s1.loss_bbox: 0.0699, loss: 0.3624, grad_norm: 2.5744\r\n",
      "2025-09-15 11:29:33,672 - mmrotate - INFO - Epoch [15][700/928]\tlr: 2.500e-05, eta: 2:54:49, time: 1.117, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0282, loss_rpn_bbox: 0.0176, s0.loss_cls: 0.1107, s0.acc: 95.8247, s0.loss_bbox: 0.1055, s1.loss_cls: 0.0444, s1.acc: 98.3516, s1.loss_bbox: 0.0753, loss: 0.3816, grad_norm: 2.7137\r\n",
      "2025-09-15 11:31:25,988 - mmrotate - INFO - Epoch [15][800/928]\tlr: 2.500e-05, eta: 2:53:00, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.1103, s0.acc: 95.7271, s0.loss_bbox: 0.1242, s1.loss_cls: 0.0453, s1.acc: 98.2939, s1.loss_bbox: 0.0788, loss: 0.3988, grad_norm: 2.6515\r\n",
      "2025-09-15 11:33:19,480 - mmrotate - INFO - Epoch [15][900/928]\tlr: 2.500e-05, eta: 2:51:12, time: 1.135, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0264, loss_rpn_bbox: 0.0167, s0.loss_cls: 0.1036, s0.acc: 96.0601, s0.loss_bbox: 0.1178, s1.loss_cls: 0.0437, s1.acc: 98.3813, s1.loss_bbox: 0.0761, loss: 0.3843, grad_norm: 2.7513\r\n",
      "2025-09-15 11:33:51,210 - mmrotate - INFO - Saving checkpoint at 15 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 141s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 11:36:21,271 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5231 | 0.714  | 0.609 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.609 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 11:36:21,361 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 11:36:21,362 - mmrotate - INFO - Epoch(val) [15][464]\tmAP: 0.6094\r\n",
      "2025-09-15 11:38:16,649 - mmrotate - INFO - Epoch [16][100/928]\tlr: 2.500e-05, eta: 2:48:33, time: 1.152, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.1046, s0.acc: 96.0347, s0.loss_bbox: 0.1154, s1.loss_cls: 0.0427, s1.acc: 98.4473, s1.loss_bbox: 0.0789, loss: 0.3804, grad_norm: 2.6753\r\n",
      "2025-09-15 11:40:10,124 - mmrotate - INFO - Epoch [16][200/928]\tlr: 2.500e-05, eta: 2:46:45, time: 1.135, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.1021, s0.acc: 96.1855, s0.loss_bbox: 0.1029, s1.loss_cls: 0.0420, s1.acc: 98.4614, s1.loss_bbox: 0.0759, loss: 0.3609, grad_norm: 2.5872\r\n",
      "2025-09-15 11:42:03,471 - mmrotate - INFO - Epoch [16][300/928]\tlr: 2.500e-05, eta: 2:44:57, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0177, s0.loss_cls: 0.1067, s0.acc: 95.9604, s0.loss_bbox: 0.1040, s1.loss_cls: 0.0451, s1.acc: 98.3340, s1.loss_bbox: 0.0834, loss: 0.3832, grad_norm: 2.5021\r\n",
      "2025-09-15 11:43:56,901 - mmrotate - INFO - Epoch [16][400/928]\tlr: 2.500e-05, eta: 2:43:09, time: 1.134, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1012, s0.acc: 96.1431, s0.loss_bbox: 0.1123, s1.loss_cls: 0.0410, s1.acc: 98.4580, s1.loss_bbox: 0.0746, loss: 0.3705, grad_norm: 2.6628\r\n",
      "2025-09-15 11:45:50,002 - mmrotate - INFO - Epoch [16][500/928]\tlr: 2.500e-05, eta: 2:41:20, time: 1.131, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.0189, s0.loss_cls: 0.1133, s0.acc: 95.6533, s0.loss_bbox: 0.1242, s1.loss_cls: 0.0453, s1.acc: 98.2734, s1.loss_bbox: 0.0832, loss: 0.4122, grad_norm: 2.7631\r\n",
      "2025-09-15 11:47:42,569 - mmrotate - INFO - Epoch [16][600/928]\tlr: 2.500e-05, eta: 2:39:31, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0190, s0.loss_cls: 0.1013, s0.acc: 96.1704, s0.loss_bbox: 0.1053, s1.loss_cls: 0.0417, s1.acc: 98.4536, s1.loss_bbox: 0.0764, loss: 0.3703, grad_norm: 2.5503\r\n",
      "2025-09-15 11:49:35,514 - mmrotate - INFO - Epoch [16][700/928]\tlr: 2.500e-05, eta: 2:37:43, time: 1.129, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.1051, s0.acc: 96.0044, s0.loss_bbox: 0.1158, s1.loss_cls: 0.0426, s1.acc: 98.4346, s1.loss_bbox: 0.0773, loss: 0.3836, grad_norm: 2.6737\r\n",
      "2025-09-15 11:51:29,129 - mmrotate - INFO - Epoch [16][800/928]\tlr: 2.500e-05, eta: 2:35:54, time: 1.136, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.0992, s0.acc: 96.1792, s0.loss_bbox: 0.1071, s1.loss_cls: 0.0433, s1.acc: 98.3584, s1.loss_bbox: 0.0820, loss: 0.3673, grad_norm: 2.6259\r\n",
      "2025-09-15 11:53:21,176 - mmrotate - INFO - Epoch [16][900/928]\tlr: 2.500e-05, eta: 2:34:05, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0275, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.0979, s0.acc: 96.2427, s0.loss_bbox: 0.1118, s1.loss_cls: 0.0403, s1.acc: 98.4727, s1.loss_bbox: 0.0759, loss: 0.3704, grad_norm: 2.6395\r\n",
      "2025-09-15 11:53:52,588 - mmrotate - INFO - Saving checkpoint at 16 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 141s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 11:56:21,979 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5394 | 0.704  | 0.595 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.595 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 11:56:22,061 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 11:56:22,062 - mmrotate - INFO - Epoch(val) [16][464]\tmAP: 0.5953\r\n",
      "2025-09-15 11:58:17,182 - mmrotate - INFO - Epoch [17][100/928]\tlr: 2.500e-05, eta: 2:31:29, time: 1.151, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1070, s0.acc: 95.8828, s0.loss_bbox: 0.1074, s1.loss_cls: 0.0450, s1.acc: 98.3115, s1.loss_bbox: 0.0801, loss: 0.3805, grad_norm: 2.6369\r\n",
      "2025-09-15 12:00:09,567 - mmrotate - INFO - Epoch [17][200/928]\tlr: 2.500e-05, eta: 2:29:40, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0293, loss_rpn_bbox: 0.0195, s0.loss_cls: 0.1133, s0.acc: 95.6533, s0.loss_bbox: 0.1254, s1.loss_cls: 0.0460, s1.acc: 98.2764, s1.loss_bbox: 0.0788, loss: 0.4123, grad_norm: 2.8956\r\n",
      "2025-09-15 12:02:01,996 - mmrotate - INFO - Epoch [17][300/928]\tlr: 2.500e-05, eta: 2:27:51, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1049, s0.acc: 96.0732, s0.loss_bbox: 0.1114, s1.loss_cls: 0.0419, s1.acc: 98.4297, s1.loss_bbox: 0.0749, loss: 0.3759, grad_norm: 2.7650\r\n",
      "2025-09-15 12:03:55,287 - mmrotate - INFO - Epoch [17][400/928]\tlr: 2.500e-05, eta: 2:26:03, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.1085, s0.acc: 95.9585, s0.loss_bbox: 0.1131, s1.loss_cls: 0.0435, s1.acc: 98.3721, s1.loss_bbox: 0.0800, loss: 0.3857, grad_norm: 2.6084\r\n",
      "2025-09-15 12:05:48,270 - mmrotate - INFO - Epoch [17][500/928]\tlr: 2.500e-05, eta: 2:24:14, time: 1.130, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0282, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.1065, s0.acc: 95.9297, s0.loss_bbox: 0.1079, s1.loss_cls: 0.0447, s1.acc: 98.3413, s1.loss_bbox: 0.0825, loss: 0.3883, grad_norm: 2.7153\r\n",
      "2025-09-15 12:07:40,237 - mmrotate - INFO - Epoch [17][600/928]\tlr: 2.500e-05, eta: 2:22:25, time: 1.120, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.0212, loss_rpn_bbox: 0.0150, s0.loss_cls: 0.0961, s0.acc: 96.3403, s0.loss_bbox: 0.1042, s1.loss_cls: 0.0389, s1.acc: 98.5137, s1.loss_bbox: 0.0711, loss: 0.3464, grad_norm: 2.5406\r\n",
      "2025-09-15 12:09:33,063 - mmrotate - INFO - Epoch [17][700/928]\tlr: 2.500e-05, eta: 2:20:36, time: 1.128, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0964, s0.acc: 96.2778, s0.loss_bbox: 0.1061, s1.loss_cls: 0.0399, s1.acc: 98.5068, s1.loss_bbox: 0.0741, loss: 0.3511, grad_norm: 2.5014\r\n",
      "2025-09-15 12:11:26,555 - mmrotate - INFO - Epoch [17][800/928]\tlr: 2.500e-05, eta: 2:18:47, time: 1.135, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0254, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.1059, s0.acc: 95.9985, s0.loss_bbox: 0.1140, s1.loss_cls: 0.0430, s1.acc: 98.3774, s1.loss_bbox: 0.0827, loss: 0.3883, grad_norm: 2.6672\r\n",
      "2025-09-15 12:13:19,369 - mmrotate - INFO - Epoch [17][900/928]\tlr: 2.500e-05, eta: 2:16:58, time: 1.128, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0275, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.1006, s0.acc: 96.1851, s0.loss_bbox: 0.1064, s1.loss_cls: 0.0433, s1.acc: 98.4189, s1.loss_bbox: 0.0797, loss: 0.3739, grad_norm: 2.6963\r\n",
      "2025-09-15 12:13:50,812 - mmrotate - INFO - Saving checkpoint at 17 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.4 task/s, elapsed: 139s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 12:16:17,949 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5015 | 0.706  | 0.604 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.604 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 12:16:18,031 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 12:16:18,032 - mmrotate - INFO - Epoch(val) [17][464]\tmAP: 0.6039\r\n",
      "2025-09-15 12:18:12,469 - mmrotate - INFO - Epoch [18][100/928]\tlr: 2.500e-05, eta: 2:14:25, time: 1.144, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0238, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.1064, s0.acc: 96.0396, s0.loss_bbox: 0.1068, s1.loss_cls: 0.0448, s1.acc: 98.3486, s1.loss_bbox: 0.0816, loss: 0.3788, grad_norm: 2.6468\r\n",
      "2025-09-15 12:20:05,754 - mmrotate - INFO - Epoch [18][200/928]\tlr: 2.500e-05, eta: 2:12:36, time: 1.133, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.0161, s0.loss_cls: 0.1023, s0.acc: 96.1470, s0.loss_bbox: 0.1070, s1.loss_cls: 0.0431, s1.acc: 98.4312, s1.loss_bbox: 0.0735, loss: 0.3691, grad_norm: 2.6849\r\n",
      "2025-09-15 12:21:58,011 - mmrotate - INFO - Epoch [18][300/928]\tlr: 2.500e-05, eta: 2:10:47, time: 1.123, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.1026, s0.acc: 96.1440, s0.loss_bbox: 0.1052, s1.loss_cls: 0.0412, s1.acc: 98.4517, s1.loss_bbox: 0.0724, loss: 0.3634, grad_norm: 2.6289\r\n",
      "2025-09-15 12:23:49,987 - mmrotate - INFO - Epoch [18][400/928]\tlr: 2.500e-05, eta: 2:08:57, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.0182, s0.loss_cls: 0.1075, s0.acc: 95.9048, s0.loss_bbox: 0.1127, s1.loss_cls: 0.0439, s1.acc: 98.3330, s1.loss_bbox: 0.0816, loss: 0.3896, grad_norm: 2.6615\r\n",
      "2025-09-15 12:25:41,587 - mmrotate - INFO - Epoch [18][500/928]\tlr: 2.500e-05, eta: 2:07:08, time: 1.116, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0249, loss_rpn_bbox: 0.0164, s0.loss_cls: 0.1069, s0.acc: 95.8765, s0.loss_bbox: 0.1102, s1.loss_cls: 0.0456, s1.acc: 98.2744, s1.loss_bbox: 0.0836, loss: 0.3876, grad_norm: 2.6065\r\n",
      "2025-09-15 12:27:33,772 - mmrotate - INFO - Epoch [18][600/928]\tlr: 2.500e-05, eta: 2:05:18, time: 1.122, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1047, s0.acc: 95.9839, s0.loss_bbox: 0.1111, s1.loss_cls: 0.0430, s1.acc: 98.3740, s1.loss_bbox: 0.0810, loss: 0.3809, grad_norm: 2.6396\r\n",
      "2025-09-15 12:29:25,853 - mmrotate - INFO - Epoch [18][700/928]\tlr: 2.500e-05, eta: 2:03:29, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.0178, s0.loss_cls: 0.1084, s0.acc: 95.8262, s0.loss_bbox: 0.1173, s1.loss_cls: 0.0445, s1.acc: 98.3164, s1.loss_bbox: 0.0822, loss: 0.3942, grad_norm: 2.6962\r\n",
      "2025-09-15 12:31:17,737 - mmrotate - INFO - Epoch [18][800/928]\tlr: 2.500e-05, eta: 2:01:39, time: 1.119, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0959, s0.acc: 96.3638, s0.loss_bbox: 0.1122, s1.loss_cls: 0.0391, s1.acc: 98.5020, s1.loss_bbox: 0.0758, loss: 0.3618, grad_norm: 2.6414\r\n",
      "2025-09-15 12:33:09,826 - mmrotate - INFO - Epoch [18][900/928]\tlr: 2.500e-05, eta: 1:59:50, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0177, s0.loss_cls: 0.0994, s0.acc: 96.2026, s0.loss_bbox: 0.1117, s1.loss_cls: 0.0406, s1.acc: 98.4668, s1.loss_bbox: 0.0764, loss: 0.3708, grad_norm: 2.6175\r\n",
      "2025-09-15 12:33:41,219 - mmrotate - INFO - Saving checkpoint at 18 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 140s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 12:36:09,599 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4854 | 0.716  | 0.608 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.608 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 12:36:09,696 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 12:36:09,697 - mmrotate - INFO - Epoch(val) [18][464]\tmAP: 0.6083\r\n",
      "2025-09-15 12:38:04,878 - mmrotate - INFO - Epoch [19][100/928]\tlr: 2.500e-05, eta: 1:57:19, time: 1.151, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.0981, s0.acc: 96.3350, s0.loss_bbox: 0.0975, s1.loss_cls: 0.0403, s1.acc: 98.5156, s1.loss_bbox: 0.0762, loss: 0.3512, grad_norm: 2.4242\r\n",
      "2025-09-15 12:39:57,840 - mmrotate - INFO - Epoch [19][200/928]\tlr: 2.500e-05, eta: 1:55:30, time: 1.130, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0225, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1021, s0.acc: 96.0864, s0.loss_bbox: 0.1120, s1.loss_cls: 0.0414, s1.acc: 98.4399, s1.loss_bbox: 0.0792, loss: 0.3742, grad_norm: 2.6679\r\n",
      "2025-09-15 12:41:50,899 - mmrotate - INFO - Epoch [19][300/928]\tlr: 2.500e-05, eta: 1:53:41, time: 1.131, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0254, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.1005, s0.acc: 96.1431, s0.loss_bbox: 0.1138, s1.loss_cls: 0.0429, s1.acc: 98.3711, s1.loss_bbox: 0.0774, loss: 0.3762, grad_norm: 2.7509\r\n",
      "2025-09-15 12:43:43,214 - mmrotate - INFO - Epoch [19][400/928]\tlr: 2.500e-05, eta: 1:51:52, time: 1.123, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0980, s0.acc: 96.2935, s0.loss_bbox: 0.1082, s1.loss_cls: 0.0396, s1.acc: 98.5215, s1.loss_bbox: 0.0749, loss: 0.3592, grad_norm: 2.5508\r\n",
      "2025-09-15 12:45:35,894 - mmrotate - INFO - Epoch [19][500/928]\tlr: 2.500e-05, eta: 1:50:03, time: 1.127, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.0193, s0.loss_cls: 0.1172, s0.acc: 95.4512, s0.loss_bbox: 0.1194, s1.loss_cls: 0.0499, s1.acc: 98.1099, s1.loss_bbox: 0.0885, loss: 0.4230, grad_norm: 2.9096\r\n",
      "2025-09-15 12:47:28,401 - mmrotate - INFO - Epoch [19][600/928]\tlr: 2.500e-05, eta: 1:48:13, time: 1.125, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.1029, s0.acc: 96.1479, s0.loss_bbox: 0.1104, s1.loss_cls: 0.0417, s1.acc: 98.4321, s1.loss_bbox: 0.0749, loss: 0.3714, grad_norm: 2.7004\r\n",
      "2025-09-15 12:49:22,048 - mmrotate - INFO - Epoch [19][700/928]\tlr: 2.500e-05, eta: 1:46:24, time: 1.136, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1051, s0.acc: 95.9487, s0.loss_bbox: 0.1072, s1.loss_cls: 0.0455, s1.acc: 98.2876, s1.loss_bbox: 0.0824, loss: 0.3805, grad_norm: 2.6328\r\n",
      "2025-09-15 12:51:14,773 - mmrotate - INFO - Epoch [19][800/928]\tlr: 2.500e-05, eta: 1:44:35, time: 1.127, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0274, loss_rpn_bbox: 0.0179, s0.loss_cls: 0.1099, s0.acc: 95.7998, s0.loss_bbox: 0.1238, s1.loss_cls: 0.0468, s1.acc: 98.2578, s1.loss_bbox: 0.0815, loss: 0.4073, grad_norm: 2.7683\r\n",
      "2025-09-15 12:53:07,198 - mmrotate - INFO - Epoch [19][900/928]\tlr: 2.500e-05, eta: 1:42:45, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.0999, s0.acc: 96.2485, s0.loss_bbox: 0.1020, s1.loss_cls: 0.0400, s1.acc: 98.4951, s1.loss_bbox: 0.0730, loss: 0.3542, grad_norm: 2.5481\r\n",
      "2025-09-15 12:53:38,845 - mmrotate - INFO - Saving checkpoint at 19 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 141s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 12:56:08,386 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5422 | 0.712  | 0.607 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.607 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 12:56:08,471 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 12:56:08,471 - mmrotate - INFO - Epoch(val) [19][464]\tmAP: 0.6071\r\n",
      "2025-09-15 12:58:04,032 - mmrotate - INFO - Epoch [20][100/928]\tlr: 2.500e-05, eta: 1:40:17, time: 1.155, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.0966, s0.acc: 96.3525, s0.loss_bbox: 0.1074, s1.loss_cls: 0.0392, s1.acc: 98.5010, s1.loss_bbox: 0.0752, loss: 0.3606, grad_norm: 2.6048\r\n",
      "2025-09-15 12:59:56,651 - mmrotate - INFO - Epoch [20][200/928]\tlr: 2.500e-05, eta: 1:38:27, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.1133, s0.acc: 95.6133, s0.loss_bbox: 0.1202, s1.loss_cls: 0.0464, s1.acc: 98.2227, s1.loss_bbox: 0.0818, loss: 0.4059, grad_norm: 2.7175\r\n",
      "2025-09-15 13:01:48,894 - mmrotate - INFO - Epoch [20][300/928]\tlr: 2.500e-05, eta: 1:36:38, time: 1.122, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.1040, s0.acc: 96.0254, s0.loss_bbox: 0.1106, s1.loss_cls: 0.0429, s1.acc: 98.3867, s1.loss_bbox: 0.0833, loss: 0.3811, grad_norm: 2.6020\r\n",
      "2025-09-15 13:03:42,185 - mmrotate - INFO - Epoch [20][400/928]\tlr: 2.500e-05, eta: 1:34:49, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.0173, s0.loss_cls: 0.1111, s0.acc: 95.7832, s0.loss_bbox: 0.1217, s1.loss_cls: 0.0453, s1.acc: 98.2954, s1.loss_bbox: 0.0841, loss: 0.4036, grad_norm: 2.7520\r\n",
      "2025-09-15 13:05:35,901 - mmrotate - INFO - Epoch [20][500/928]\tlr: 2.500e-05, eta: 1:33:00, time: 1.137, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0994, s0.acc: 96.2153, s0.loss_bbox: 0.1050, s1.loss_cls: 0.0412, s1.acc: 98.4888, s1.loss_bbox: 0.0735, loss: 0.3583, grad_norm: 2.5958\r\n",
      "2025-09-15 13:07:29,893 - mmrotate - INFO - Epoch [20][600/928]\tlr: 2.500e-05, eta: 1:31:11, time: 1.140, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.0978, s0.acc: 96.2788, s0.loss_bbox: 0.1069, s1.loss_cls: 0.0428, s1.acc: 98.4155, s1.loss_bbox: 0.0765, loss: 0.3635, grad_norm: 2.6458\r\n",
      "2025-09-15 13:09:24,162 - mmrotate - INFO - Epoch [20][700/928]\tlr: 2.500e-05, eta: 1:29:22, time: 1.143, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0253, loss_rpn_bbox: 0.0174, s0.loss_cls: 0.1078, s0.acc: 95.8315, s0.loss_bbox: 0.1159, s1.loss_cls: 0.0444, s1.acc: 98.3442, s1.loss_bbox: 0.0820, loss: 0.3928, grad_norm: 2.6985\r\n",
      "2025-09-15 13:11:17,835 - mmrotate - INFO - Epoch [20][800/928]\tlr: 2.500e-05, eta: 1:27:32, time: 1.137, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.0977, s0.acc: 96.3618, s0.loss_bbox: 0.1038, s1.loss_cls: 0.0400, s1.acc: 98.5107, s1.loss_bbox: 0.0737, loss: 0.3542, grad_norm: 2.7319\r\n",
      "2025-09-15 13:13:11,504 - mmrotate - INFO - Epoch [20][900/928]\tlr: 2.500e-05, eta: 1:25:43, time: 1.137, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0284, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.1062, s0.acc: 95.9248, s0.loss_bbox: 0.1096, s1.loss_cls: 0.0448, s1.acc: 98.3066, s1.loss_bbox: 0.0791, loss: 0.3853, grad_norm: 2.8528\r\n",
      "2025-09-15 13:13:43,379 - mmrotate - INFO - Saving checkpoint at 20 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 143s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 13:16:14,895 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5269 | 0.709  | 0.607 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.607 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 13:16:14,979 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 13:16:14,980 - mmrotate - INFO - Epoch(val) [20][464]\tmAP: 0.6072\r\n",
      "2025-09-15 13:18:10,611 - mmrotate - INFO - Epoch [21][100/928]\tlr: 2.500e-05, eta: 1:23:16, time: 1.156, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0253, loss_rpn_bbox: 0.0179, s0.loss_cls: 0.1038, s0.acc: 96.0732, s0.loss_bbox: 0.1102, s1.loss_cls: 0.0430, s1.acc: 98.4316, s1.loss_bbox: 0.0765, loss: 0.3768, grad_norm: 2.6725\r\n",
      "2025-09-15 13:20:04,983 - mmrotate - INFO - Epoch [21][200/928]\tlr: 2.500e-05, eta: 1:21:27, time: 1.144, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0177, s0.loss_cls: 0.1024, s0.acc: 96.0786, s0.loss_bbox: 0.1202, s1.loss_cls: 0.0412, s1.acc: 98.4565, s1.loss_bbox: 0.0767, loss: 0.3825, grad_norm: 2.7749\r\n",
      "2025-09-15 13:21:58,764 - mmrotate - INFO - Epoch [21][300/928]\tlr: 2.500e-05, eta: 1:19:38, time: 1.138, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0157, s0.loss_cls: 0.1028, s0.acc: 96.1294, s0.loss_bbox: 0.1047, s1.loss_cls: 0.0412, s1.acc: 98.4600, s1.loss_bbox: 0.0744, loss: 0.3620, grad_norm: 2.6166\r\n",
      "2025-09-15 13:23:52,072 - mmrotate - INFO - Epoch [21][400/928]\tlr: 2.500e-05, eta: 1:17:48, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0178, s0.loss_cls: 0.0994, s0.acc: 96.2368, s0.loss_bbox: 0.1154, s1.loss_cls: 0.0422, s1.acc: 98.3999, s1.loss_bbox: 0.0765, loss: 0.3741, grad_norm: 2.6312\r\n",
      "2025-09-15 13:25:45,246 - mmrotate - INFO - Epoch [21][500/928]\tlr: 2.500e-05, eta: 1:15:59, time: 1.132, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.1039, s0.acc: 95.9644, s0.loss_bbox: 0.1191, s1.loss_cls: 0.0438, s1.acc: 98.3223, s1.loss_bbox: 0.0820, loss: 0.3860, grad_norm: 2.7284\r\n",
      "2025-09-15 13:27:38,580 - mmrotate - INFO - Epoch [21][600/928]\tlr: 2.500e-05, eta: 1:14:09, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0239, loss_rpn_bbox: 0.0154, s0.loss_cls: 0.1068, s0.acc: 96.0195, s0.loss_bbox: 0.1076, s1.loss_cls: 0.0442, s1.acc: 98.3735, s1.loss_bbox: 0.0830, loss: 0.3809, grad_norm: 2.6456\r\n",
      "2025-09-15 13:29:31,832 - mmrotate - INFO - Epoch [21][700/928]\tlr: 2.500e-05, eta: 1:12:20, time: 1.133, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0238, loss_rpn_bbox: 0.0148, s0.loss_cls: 0.0997, s0.acc: 96.2163, s0.loss_bbox: 0.1101, s1.loss_cls: 0.0408, s1.acc: 98.4556, s1.loss_bbox: 0.0750, loss: 0.3641, grad_norm: 2.6069\r\n",
      "2025-09-15 13:31:26,465 - mmrotate - INFO - Epoch [21][800/928]\tlr: 2.500e-05, eta: 1:10:31, time: 1.146, data_time: 0.021, memory: 6886, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.0177, s0.loss_cls: 0.1048, s0.acc: 96.1328, s0.loss_bbox: 0.1104, s1.loss_cls: 0.0428, s1.acc: 98.4502, s1.loss_bbox: 0.0783, loss: 0.3811, grad_norm: 2.7581\r\n",
      "2025-09-15 13:33:20,570 - mmrotate - INFO - Epoch [21][900/928]\tlr: 2.500e-05, eta: 1:08:41, time: 1.141, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0254, loss_rpn_bbox: 0.0183, s0.loss_cls: 0.1068, s0.acc: 95.9517, s0.loss_bbox: 0.1052, s1.loss_cls: 0.0456, s1.acc: 98.3018, s1.loss_bbox: 0.0832, loss: 0.3845, grad_norm: 2.6454\r\n",
      "2025-09-15 13:33:52,743 - mmrotate - INFO - Saving checkpoint at 21 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.2 task/s, elapsed: 144s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 13:36:25,290 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4924 | 0.712  | 0.606 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.606 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 13:36:25,374 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 13:36:25,375 - mmrotate - INFO - Epoch(val) [21][464]\tmAP: 0.6059\r\n",
      "2025-09-15 13:38:21,956 - mmrotate - INFO - Epoch [22][100/928]\tlr: 2.500e-05, eta: 1:06:16, time: 1.165, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1032, s0.acc: 96.0244, s0.loss_bbox: 0.1081, s1.loss_cls: 0.0432, s1.acc: 98.3306, s1.loss_bbox: 0.0772, loss: 0.3729, grad_norm: 2.6463\r\n",
      "2025-09-15 13:40:16,198 - mmrotate - INFO - Epoch [22][200/928]\tlr: 2.500e-05, eta: 1:04:26, time: 1.142, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0281, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.1053, s0.acc: 95.9902, s0.loss_bbox: 0.1127, s1.loss_cls: 0.0436, s1.acc: 98.3306, s1.loss_bbox: 0.0814, loss: 0.3896, grad_norm: 2.6746\r\n",
      "2025-09-15 13:42:09,919 - mmrotate - INFO - Epoch [22][300/928]\tlr: 2.500e-05, eta: 1:02:37, time: 1.137, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1072, s0.acc: 95.9136, s0.loss_bbox: 0.1134, s1.loss_cls: 0.0434, s1.acc: 98.3804, s1.loss_bbox: 0.0811, loss: 0.3877, grad_norm: 2.8836\r\n",
      "2025-09-15 13:44:03,181 - mmrotate - INFO - Epoch [22][400/928]\tlr: 2.500e-05, eta: 1:00:47, time: 1.133, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1081, s0.acc: 96.0171, s0.loss_bbox: 0.1265, s1.loss_cls: 0.0420, s1.acc: 98.4399, s1.loss_bbox: 0.0752, loss: 0.3939, grad_norm: 2.8148\r\n",
      "2025-09-15 13:45:56,692 - mmrotate - INFO - Epoch [22][500/928]\tlr: 2.500e-05, eta: 0:58:58, time: 1.135, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0220, loss_rpn_bbox: 0.0161, s0.loss_cls: 0.1027, s0.acc: 96.0444, s0.loss_bbox: 0.1112, s1.loss_cls: 0.0434, s1.acc: 98.3735, s1.loss_bbox: 0.0800, loss: 0.3755, grad_norm: 2.6557\r\n",
      "2025-09-15 13:47:50,351 - mmrotate - INFO - Epoch [22][600/928]\tlr: 2.500e-05, eta: 0:57:08, time: 1.137, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0261, loss_rpn_bbox: 0.0174, s0.loss_cls: 0.1062, s0.acc: 95.9346, s0.loss_bbox: 0.1087, s1.loss_cls: 0.0457, s1.acc: 98.2681, s1.loss_bbox: 0.0825, loss: 0.3866, grad_norm: 2.6301\r\n",
      "2025-09-15 13:49:44,337 - mmrotate - INFO - Epoch [22][700/928]\tlr: 2.500e-05, eta: 0:55:18, time: 1.140, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.1006, s0.acc: 96.2065, s0.loss_bbox: 0.1036, s1.loss_cls: 0.0415, s1.acc: 98.4331, s1.loss_bbox: 0.0780, loss: 0.3619, grad_norm: 2.6282\r\n",
      "2025-09-15 13:51:39,364 - mmrotate - INFO - Epoch [22][800/928]\tlr: 2.500e-05, eta: 0:53:29, time: 1.150, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.1028, s0.acc: 96.1191, s0.loss_bbox: 0.1050, s1.loss_cls: 0.0433, s1.acc: 98.3916, s1.loss_bbox: 0.0786, loss: 0.3725, grad_norm: 2.7577\r\n",
      "2025-09-15 13:53:34,148 - mmrotate - INFO - Epoch [22][900/928]\tlr: 2.500e-05, eta: 0:51:39, time: 1.148, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0169, s0.loss_cls: 0.1001, s0.acc: 96.2407, s0.loss_bbox: 0.1017, s1.loss_cls: 0.0417, s1.acc: 98.4438, s1.loss_bbox: 0.0772, loss: 0.3603, grad_norm: 2.4249\r\n",
      "2025-09-15 13:54:05,992 - mmrotate - INFO - Saving checkpoint at 22 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.2 task/s, elapsed: 143s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 13:56:37,784 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4933 | 0.716  | 0.605 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.605 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 13:56:37,872 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 13:56:37,873 - mmrotate - INFO - Epoch(val) [22][464]\tmAP: 0.6052\r\n",
      "2025-09-15 13:58:32,880 - mmrotate - INFO - Epoch [23][100/928]\tlr: 2.500e-05, eta: 0:49:15, time: 1.149, data_time: 0.043, memory: 6886, loss_rpn_cls: 0.0281, loss_rpn_bbox: 0.0204, s0.loss_cls: 0.1133, s0.acc: 95.6157, s0.loss_bbox: 0.1193, s1.loss_cls: 0.0472, s1.acc: 98.2046, s1.loss_bbox: 0.0863, loss: 0.4146, grad_norm: 2.8594\r\n",
      "2025-09-15 14:00:24,553 - mmrotate - INFO - Epoch [23][200/928]\tlr: 2.500e-05, eta: 0:47:25, time: 1.117, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.0160, s0.loss_cls: 0.1104, s0.acc: 95.7266, s0.loss_bbox: 0.1249, s1.loss_cls: 0.0447, s1.acc: 98.3267, s1.loss_bbox: 0.0871, loss: 0.4068, grad_norm: 2.7872\r\n",
      "2025-09-15 14:02:16,551 - mmrotate - INFO - Epoch [23][300/928]\tlr: 2.500e-05, eta: 0:45:35, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1019, s0.acc: 96.1406, s0.loss_bbox: 0.1085, s1.loss_cls: 0.0430, s1.acc: 98.4106, s1.loss_bbox: 0.0796, loss: 0.3735, grad_norm: 2.5652\r\n",
      "2025-09-15 14:04:08,332 - mmrotate - INFO - Epoch [23][400/928]\tlr: 2.500e-05, eta: 0:43:45, time: 1.118, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.0990, s0.acc: 96.2539, s0.loss_bbox: 0.1021, s1.loss_cls: 0.0414, s1.acc: 98.4409, s1.loss_bbox: 0.0744, loss: 0.3571, grad_norm: 2.4853\r\n",
      "2025-09-15 14:06:00,103 - mmrotate - INFO - Epoch [23][500/928]\tlr: 2.500e-05, eta: 0:41:55, time: 1.118, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.0975, s0.acc: 96.3267, s0.loss_bbox: 0.1093, s1.loss_cls: 0.0391, s1.acc: 98.5293, s1.loss_bbox: 0.0717, loss: 0.3529, grad_norm: 2.6223\r\n",
      "2025-09-15 14:07:52,343 - mmrotate - INFO - Epoch [23][600/928]\tlr: 2.500e-05, eta: 0:40:05, time: 1.122, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0278, loss_rpn_bbox: 0.0161, s0.loss_cls: 0.1028, s0.acc: 96.1035, s0.loss_bbox: 0.1105, s1.loss_cls: 0.0455, s1.acc: 98.3325, s1.loss_bbox: 0.0790, loss: 0.3818, grad_norm: 2.8523\r\n",
      "2025-09-15 14:09:44,097 - mmrotate - INFO - Epoch [23][700/928]\tlr: 2.500e-05, eta: 0:38:15, time: 1.118, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.1005, s0.acc: 96.1689, s0.loss_bbox: 0.1053, s1.loss_cls: 0.0413, s1.acc: 98.4673, s1.loss_bbox: 0.0760, loss: 0.3608, grad_norm: 2.6266\r\n",
      "2025-09-15 14:11:35,713 - mmrotate - INFO - Epoch [23][800/928]\tlr: 2.500e-05, eta: 0:36:25, time: 1.116, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0273, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1015, s0.acc: 96.1279, s0.loss_bbox: 0.1003, s1.loss_cls: 0.0444, s1.acc: 98.3276, s1.loss_bbox: 0.0805, loss: 0.3715, grad_norm: 2.5354\r\n",
      "2025-09-15 14:13:27,572 - mmrotate - INFO - Epoch [23][900/928]\tlr: 2.500e-05, eta: 0:34:35, time: 1.119, data_time: 0.018, memory: 6886, loss_rpn_cls: 0.0261, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1067, s0.acc: 95.9414, s0.loss_bbox: 0.1138, s1.loss_cls: 0.0435, s1.acc: 98.3745, s1.loss_bbox: 0.0802, loss: 0.3873, grad_norm: 2.7321\r\n",
      "2025-09-15 14:13:58,765 - mmrotate - INFO - Saving checkpoint at 23 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 139s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 14:16:26,795 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5628 | 0.724  | 0.613 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.613 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 14:16:26,879 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 14:16:26,880 - mmrotate - INFO - Epoch(val) [23][464]\tmAP: 0.6125\r\n",
      "2025-09-15 14:18:21,574 - mmrotate - INFO - Epoch [24][100/928]\tlr: 2.500e-05, eta: 0:32:12, time: 1.146, data_time: 0.042, memory: 6886, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.1018, s0.acc: 96.0908, s0.loss_bbox: 0.1180, s1.loss_cls: 0.0422, s1.acc: 98.4116, s1.loss_bbox: 0.0795, loss: 0.3783, grad_norm: 2.7009\r\n",
      "2025-09-15 14:20:13,760 - mmrotate - INFO - Epoch [24][200/928]\tlr: 2.500e-05, eta: 0:30:22, time: 1.122, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.0180, s0.loss_cls: 0.1043, s0.acc: 96.0273, s0.loss_bbox: 0.1090, s1.loss_cls: 0.0430, s1.acc: 98.3867, s1.loss_bbox: 0.0794, loss: 0.3783, grad_norm: 2.6223\r\n",
      "2025-09-15 14:22:05,465 - mmrotate - INFO - Epoch [24][300/928]\tlr: 2.500e-05, eta: 0:28:32, time: 1.117, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.0149, s0.loss_cls: 0.1009, s0.acc: 96.1792, s0.loss_bbox: 0.1046, s1.loss_cls: 0.0419, s1.acc: 98.4263, s1.loss_bbox: 0.0770, loss: 0.3637, grad_norm: 2.6705\r\n",
      "2025-09-15 14:23:57,621 - mmrotate - INFO - Epoch [24][400/928]\tlr: 2.500e-05, eta: 0:26:42, time: 1.122, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0286, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.1076, s0.acc: 95.9355, s0.loss_bbox: 0.1116, s1.loss_cls: 0.0447, s1.acc: 98.3013, s1.loss_bbox: 0.0803, loss: 0.3913, grad_norm: 2.7370\r\n",
      "2025-09-15 14:25:49,790 - mmrotate - INFO - Epoch [24][500/928]\tlr: 2.500e-05, eta: 0:24:52, time: 1.122, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.1008, s0.acc: 96.1577, s0.loss_bbox: 0.0985, s1.loss_cls: 0.0414, s1.acc: 98.4482, s1.loss_bbox: 0.0753, loss: 0.3588, grad_norm: 2.5097\r\n",
      "2025-09-15 14:27:41,877 - mmrotate - INFO - Epoch [24][600/928]\tlr: 2.500e-05, eta: 0:23:02, time: 1.121, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0175, s0.loss_cls: 0.1036, s0.acc: 96.0093, s0.loss_bbox: 0.1104, s1.loss_cls: 0.0432, s1.acc: 98.3599, s1.loss_bbox: 0.0818, loss: 0.3794, grad_norm: 2.7785\r\n",
      "2025-09-15 14:29:33,821 - mmrotate - INFO - Epoch [24][700/928]\tlr: 2.500e-05, eta: 0:21:12, time: 1.119, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0252, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.1013, s0.acc: 96.1245, s0.loss_bbox: 0.1086, s1.loss_cls: 0.0424, s1.acc: 98.3838, s1.loss_bbox: 0.0787, loss: 0.3721, grad_norm: 2.8379\r\n",
      "2025-09-15 14:31:26,322 - mmrotate - INFO - Epoch [24][800/928]\tlr: 2.500e-05, eta: 0:19:22, time: 1.125, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.1027, s0.acc: 96.1416, s0.loss_bbox: 0.1071, s1.loss_cls: 0.0427, s1.acc: 98.4165, s1.loss_bbox: 0.0787, loss: 0.3699, grad_norm: 2.6312\r\n",
      "2025-09-15 14:33:18,920 - mmrotate - INFO - Epoch [24][900/928]\tlr: 2.500e-05, eta: 0:17:32, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.0174, s0.loss_cls: 0.1082, s0.acc: 95.8926, s0.loss_bbox: 0.1196, s1.loss_cls: 0.0452, s1.acc: 98.3428, s1.loss_bbox: 0.0829, loss: 0.4013, grad_norm: 2.8320\r\n",
      "2025-09-15 14:33:50,320 - mmrotate - INFO - Saving checkpoint at 24 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 140s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 14:36:18,441 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5407 | 0.725  | 0.623 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.623 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 14:36:18,594 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/redet_train/best_mAP_epoch_14.pth was removed\r\n",
      "2025-09-15 14:36:19,737 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_24.pth.\r\n",
      "2025-09-15 14:36:19,738 - mmrotate - INFO - Best mAP is 0.6232 at 24 epoch.\r\n",
      "2025-09-15 14:36:19,739 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 14:36:19,739 - mmrotate - INFO - Epoch(val) [24][464]\tmAP: 0.6232\r\n",
      "2025-09-15 14:38:14,427 - mmrotate - INFO - Epoch [25][100/928]\tlr: 2.500e-05, eta: 0:15:10, time: 1.146, data_time: 0.044, memory: 6886, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.0170, s0.loss_cls: 0.1007, s0.acc: 96.1567, s0.loss_bbox: 0.1081, s1.loss_cls: 0.0418, s1.acc: 98.4248, s1.loss_bbox: 0.0786, loss: 0.3708, grad_norm: 2.6550\r\n",
      "2025-09-15 14:40:06,916 - mmrotate - INFO - Epoch [25][200/928]\tlr: 2.500e-05, eta: 0:13:20, time: 1.125, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0242, loss_rpn_bbox: 0.0173, s0.loss_cls: 0.1063, s0.acc: 95.9834, s0.loss_bbox: 0.1084, s1.loss_cls: 0.0448, s1.acc: 98.3018, s1.loss_bbox: 0.0816, loss: 0.3827, grad_norm: 2.6981\r\n",
      "2025-09-15 14:41:58,943 - mmrotate - INFO - Epoch [25][300/928]\tlr: 2.500e-05, eta: 0:11:30, time: 1.120, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.1027, s0.acc: 96.1494, s0.loss_bbox: 0.1140, s1.loss_cls: 0.0429, s1.acc: 98.3755, s1.loss_bbox: 0.0803, loss: 0.3799, grad_norm: 2.6636\r\n",
      "2025-09-15 14:43:51,498 - mmrotate - INFO - Epoch [25][400/928]\tlr: 2.500e-05, eta: 0:09:40, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.0172, s0.loss_cls: 0.1027, s0.acc: 96.1099, s0.loss_bbox: 0.1123, s1.loss_cls: 0.0443, s1.acc: 98.3696, s1.loss_bbox: 0.0798, loss: 0.3851, grad_norm: 2.6370\r\n",
      "2025-09-15 14:45:44,108 - mmrotate - INFO - Epoch [25][500/928]\tlr: 2.500e-05, eta: 0:07:51, time: 1.126, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.0171, s0.loss_cls: 0.1045, s0.acc: 96.0015, s0.loss_bbox: 0.1099, s1.loss_cls: 0.0435, s1.acc: 98.3667, s1.loss_bbox: 0.0816, loss: 0.3789, grad_norm: 2.6634\r\n",
      "2025-09-15 14:47:36,495 - mmrotate - INFO - Epoch [25][600/928]\tlr: 2.500e-05, eta: 0:06:00, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0224, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.1000, s0.acc: 96.1118, s0.loss_bbox: 0.1056, s1.loss_cls: 0.0412, s1.acc: 98.4629, s1.loss_bbox: 0.0762, loss: 0.3614, grad_norm: 2.6518\r\n",
      "2025-09-15 14:49:28,928 - mmrotate - INFO - Epoch [25][700/928]\tlr: 2.500e-05, eta: 0:04:10, time: 1.124, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.0150, s0.loss_cls: 0.1000, s0.acc: 96.2476, s0.loss_bbox: 0.1171, s1.loss_cls: 0.0401, s1.acc: 98.4795, s1.loss_bbox: 0.0768, loss: 0.3721, grad_norm: 2.7002\r\n",
      "2025-09-15 14:51:22,044 - mmrotate - INFO - Epoch [25][800/928]\tlr: 2.500e-05, eta: 0:02:20, time: 1.131, data_time: 0.019, memory: 6886, loss_rpn_cls: 0.0254, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1047, s0.acc: 95.9819, s0.loss_bbox: 0.1081, s1.loss_cls: 0.0455, s1.acc: 98.2715, s1.loss_bbox: 0.0858, loss: 0.3861, grad_norm: 2.6706\r\n",
      "2025-09-15 14:53:15,553 - mmrotate - INFO - Epoch [25][900/928]\tlr: 2.500e-05, eta: 0:00:30, time: 1.135, data_time: 0.020, memory: 6886, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.1017, s0.acc: 96.1831, s0.loss_bbox: 0.1020, s1.loss_cls: 0.0410, s1.acc: 98.4673, s1.loss_bbox: 0.0757, loss: 0.3611, grad_norm: 2.6287\r\n",
      "2025-09-15 14:53:47,281 - mmrotate - INFO - Saving checkpoint at 25 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.3 task/s, elapsed: 141s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-15 14:56:16,853 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4908 | 0.709  | 0.612 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.612 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-15 14:56:16,938 - mmrotate - INFO - Exp name: redet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-15 14:56:16,939 - mmrotate - INFO - Epoch(val) [25][464]\tmAP: 0.6119\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       learning_rate ▆███████████▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            momentum ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm █▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁▁▂▁▂▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁▁▂▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss █▆▇█▆▅▅▃▄▃▃▄▂▃▂▁▂▂▂▂▃▁▂▂▂▃▁▃▃▃▁▂▁▃▂▂▃▂▃▂\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss_rpn_bbox █▆▅▅▅▄▄▃▃▄▄▃▃▂▁▂▁▂▂▂▁▂▁▁▁▁▁▂▂▂▁▁▂▂▂▂▂▂▁▂\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/loss_rpn_cls █▇▆▆▆▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/s0.acc █▆▄▂▁▂▂▄▃▄▄▃▄▃▃▄▃▄▄▃▄▄▃▄▄▃▅▄▄▃▄▄▃▄▅▄▄▄▄▄\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/s0.loss_bbox ██▆▅▄▇▄▅▅▅▅▃▂▃▄▂▂▂▂▃▁▃▂▂▂▂▂▂▂▃▁▁▂▂▁▂▃▁▂▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/s0.loss_cls ▃▅▅▆█▆▅▆▆▆▃▂▂▂▃▂▃▂▂▁▂▃▂▁▁▃▁▁▂▁▃▂▂▂▂▂▁▂▂▂\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/s1.acc ▇█▇▇▇▅▅▃▃▂▂▂▂▃▂▁▂▃▃▃▂▂▃▂▃▁▃▃▂▁▃▃▁▂▂▂▃▂▂▃\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/s1.loss_bbox ▄▁▃▄▅▄▅▇▆▇███▇▇▇█▇▇▆▇█▇▆▇█▇▇▇▇▇▇█▇▆▇▇▇▇▇\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/s1.loss_cls ▄▃▄▄▃▂▃▁▂▃▃▆▅▅▅▅▆▅▆▆▅▆▆▅▅▆▅▆▆█▄▆▆▆▄▅▆▅▆▆\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             val/mAP ▁▁▂▃▄▅▆▇▇████████████████\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       learning_rate 3e-05\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            momentum 0.9\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm 2.62873\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss 0.36113\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss_rpn_bbox 0.01657\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/loss_rpn_cls 0.02412\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/s0.acc 96.18311\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/s0.loss_bbox 0.10205\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/s0.loss_cls 0.10171\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/s1.acc 98.46729\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/s1.loss_bbox 0.07565\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/s1.loss_cls 0.04102\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             val/mAP 0.61192\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mredet_train\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/SOTA/runs/tuun175x\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/SOTA\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250915_063511-tuun175x/logs\u001b[0m\r\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the Model\n",
    "%cd /kaggle/working/mmrotate\n",
    "!mkdir -p /kaggle/working/runs/redet_train\n",
    "\n",
    "\n",
    "!python tools/train.py \\\n",
    "    configs/redet/redet_r50_fpn_1x_sccos.py \\\n",
    "    --work-dir /kaggle/working/runs/redet_train \\\n",
    "    --gpus 1 \\\n",
    "\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20914632",
   "metadata": {
    "_cell_guid": "ab4714da-9fba-442d-bb5d-466767a50780",
    "_uuid": "e7978bc1-29c8-44f4-9240-281ce3681a04",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-15T14:56:23.974711Z",
     "iopub.status.busy": "2025-09-15T14:56:23.974429Z",
     "iopub.status.idle": "2025-09-15T15:01:04.062117Z",
     "shell.execute_reply": "2025-09-15T15:01:04.061142Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 280.628525,
     "end_time": "2025-09-15T15:01:04.063525",
     "exception": false,
     "start_time": "2025-09-15T14:56:23.435000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "Found best checkpoint: /kaggle/working/runs/redet_train/best_mAP_epoch_24.pth\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\r\n",
      "  full_mask[mask] = norms.to(torch.uint8)\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "load checkpoint from local path: /kaggle/working/runs/redet_train/best_mAP_epoch_24.pth\r\n",
      "[                                                  ] 0/464, elapsed: 0s, ETA:/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "[                                 ] 1/464, 0.7 task/s, elapsed: 1s, ETA:   687s/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 2.0 task/s, elapsed: 236s, ETA:     0s\r\n",
      "writing results to /kaggle/working/runs/redet_test/results.pkl\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 2140 | 5691 | 0.608  | 0.516 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.516 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "{'mAP': 0.5158151388168335}\r\n",
      "FIRNet testing completed. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Test FIRNet (uncomment to run)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%cd /kaggle/working/mmrotate\n",
    "\n",
    "# Step 1: Find the best checkpoint file automatically\n",
    "checkpoint_dir = '/kaggle/working/runs/redet_train'\n",
    "best_checkpoint_path = None\n",
    "# Search for the best checkpoint file\n",
    "for filename in glob.glob(os.path.join(checkpoint_dir, 'best_mAP_*.pth')):\n",
    "    best_checkpoint_path = filename\n",
    "    break  # Take the first one found\n",
    "\n",
    "if best_checkpoint_path:\n",
    "    print(f\"Found best checkpoint: {best_checkpoint_path}\")\n",
    "    \n",
    "    # Step 2: Run the test command with the found checkpoint\n",
    "    !mkdir -p /kaggle/working/runs/redet_test\n",
    "    !python tools/test.py \\\n",
    "        configs/redet/redet_r50_fpn_1x_sccos.py \\\n",
    "        {best_checkpoint_path} \\\n",
    "        --eval mAP \\\n",
    "        --out /kaggle/working/runs/redet_test/results.pkl \\\n",
    "        --show-dir /kaggle/working/runs/redet_test/vis\n",
    "    \n",
    "    print(\"FIRNet testing completed. Results saved.\")\n",
    "else:\n",
    "    print(f\"Error: No best checkpoint found in {checkpoint_dir}. Please ensure training was successful.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8134003,
     "sourceId": 12859844,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30651.640844,
   "end_time": "2025-09-15T15:01:05.157191",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-15T06:30:13.516347",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
