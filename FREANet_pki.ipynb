{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169a7276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:54:55.278345Z",
     "iopub.status.busy": "2025-09-16T14:54:55.278043Z",
     "iopub.status.idle": "2025-09-16T14:55:02.278764Z",
     "shell.execute_reply": "2025-09-16T14:55:02.278038Z"
    },
    "papermill": {
     "duration": 7.008529,
     "end_time": "2025-09-16T14:55:02.279940",
     "exception": false,
     "start_time": "2025-09-16T14:54:55.271411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanish-jain140301\u001b[0m (\u001b[33mtanish1403\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb -q\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "\n",
    "wandb.login(key = secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423949fb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-16T14:55:02.291417Z",
     "iopub.status.busy": "2025-09-16T14:55:02.291135Z",
     "iopub.status.idle": "2025-09-16T14:55:02.415064Z",
     "shell.execute_reply": "2025-09-16T14:55:02.414246Z"
    },
    "papermill": {
     "duration": 0.130657,
     "end_time": "2025-09-16T14:55:02.416632",
     "exception": false,
     "start_time": "2025-09-16T14:55:02.285975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef475fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:55:02.426716Z",
     "iopub.status.busy": "2025-09-16T14:55:02.426439Z",
     "iopub.status.idle": "2025-09-16T14:57:41.948258Z",
     "shell.execute_reply": "2025-09-16T14:57:41.947392Z"
    },
    "papermill": {
     "duration": 159.528313,
     "end_time": "2025-09-16T14:57:41.949684",
     "exception": false,
     "start_time": "2025-09-16T14:55:02.421371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m409.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\r\n",
      "datasets 3.6.0 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 3.6.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "pytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\r\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "pymc 5.23.0 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "yfinance 0.2.63 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "dataproc-spark-connect 0.7.5 requires tqdm>=4.67, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\r\n",
      "pytensor 2.31.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "# !pip install mmcv-full==1.7.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html -q\n",
    "!pip install mmdet==2.28.2 -q\n",
    "!pip install -U openmim -q\n",
    "!mim install \"mmengine>=0.7.0\" -q\n",
    "!pip install xmltodict -q  # For dataset conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8e30b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:57:42.023563Z",
     "iopub.status.busy": "2025-09-16T14:57:42.022894Z",
     "iopub.status.idle": "2025-09-16T14:57:54.822978Z",
     "shell.execute_reply": "2025-09-16T14:57:54.822236Z"
    },
    "papermill": {
     "duration": 12.838268,
     "end_time": "2025-09-16T14:57:54.824577",
     "exception": false,
     "start_time": "2025-09-16T14:57:41.986309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\r\n",
      "Collecting mmcv==2.0.1\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.1-cp311-cp311-manylinux1_x86_64.whl (74.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (0.10.7)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.1) (4.11.0.86)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.0.1) (3.7.2)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.0.1) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.0.1) (3.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv==2.0.1) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv==2.0.1) (4.3.8)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv==2.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv==2.0.1) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mmcv==2.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mmcv==2.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.0.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.0.1) (2.19.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mmcv==2.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.0.1) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv==2.0.1) (1.17.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!mim install 'mmcv==2.0.1'\n",
    "# !pip uninstall mmcv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66812f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:57:54.958575Z",
     "iopub.status.busy": "2025-09-16T14:57:54.957922Z",
     "iopub.status.idle": "2025-09-16T14:58:06.462449Z",
     "shell.execute_reply": "2025-09-16T14:58:06.461450Z"
    },
    "papermill": {
     "duration": 11.547454,
     "end_time": "2025-09-16T14:58:06.464033",
     "exception": false,
     "start_time": "2025-09-16T14:57:54.916579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\r\n",
      "Collecting mmcv-full\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv_full-1.7.2-cp311-cp311-manylinux1_x86_64.whl (70.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (2.4.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv-full) (4.11.0.86)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mmcv-full) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-full) (4.3.8)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv-full) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmcv-full) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mmcv-full) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mmcv-full) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mmcv-full) (2024.2.0)\r\n",
      "Installing collected packages: mmcv-full\r\n",
      "Successfully installed mmcv-full-1.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!mim install 'mmcv-full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977d969a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:06.550387Z",
     "iopub.status.busy": "2025-09-16T14:58:06.550005Z",
     "iopub.status.idle": "2025-09-16T14:58:06.564904Z",
     "shell.execute_reply": "2025-09-16T14:58:06.564342Z"
    },
    "papermill": {
     "duration": 0.058507,
     "end_time": "2025-09-16T14:58:06.566011",
     "exception": false,
     "start_time": "2025-09-16T14:58:06.507504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Prepare Dataset (SCCOS to DOTA format)\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import xmltodict\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "dataset_path = \"/kaggle/input/sccos-dataset/\"\n",
    "working_dir = \"/kaggle/working/sccos_dota\"\n",
    "train_images_dir = os.path.join(working_dir, \"train/images\")\n",
    "train_labels_dir = os.path.join(working_dir, \"train/labels\")\n",
    "val_images_dir = os.path.join(working_dir, \"val/images\")\n",
    "val_labels_dir = os.path.join(working_dir, \"val/labels\")\n",
    "test_images_dir = os.path.join(working_dir, \"test/images\")\n",
    "test_labels_dir = os.path.join(working_dir, \"test/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a91298e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:06.650293Z",
     "iopub.status.busy": "2025-09-16T14:58:06.649734Z",
     "iopub.status.idle": "2025-09-16T14:58:18.318343Z",
     "shell.execute_reply": "2025-09-16T14:58:18.317563Z"
    },
    "papermill": {
     "duration": 11.712131,
     "end_time": "2025-09-16T14:58:18.319862",
     "exception": false,
     "start_time": "2025-09-16T14:58:06.607731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/mmrotate'...\r\n",
      "remote: Enumerating objects: 482, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (482/482), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (333/333), done.\u001b[K\r\n",
      "remote: Total 482 (delta 143), reused 474 (delta 135), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (482/482), 11.52 MiB | 9.96 MiB/s, done.\r\n",
      "Resolving deltas: 100% (143/143), done.\r\n",
      "/kaggle/working/mmrotate\n",
      "Obtaining file:///kaggle/working/mmrotate\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting e2cnn (from mmrotate==0.3.4)\r\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (3.7.2)\r\n",
      "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (1.7.2)\r\n",
      "Requirement already satisfied: mmdet<3.0.0,>=2.25.1 in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (2.28.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (1.26.4)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (2.0.10)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (1.17.0)\r\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (3.1.10)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mmrotate==0.3.4) (2.0.1+cu118)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmdet<3.0.0,>=2.25.1->mmrotate==0.3.4) (1.15.3)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from e2cnn->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (11.2.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmrotate==0.3.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mmrotate==0.3.4) (2.4.1)\r\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (2.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv-full->mmrotate==0.3.4) (4.11.0.86)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (3.14.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (3.1.6)\r\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->mmrotate==0.3.4) (2.0.0)\r\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->mmrotate==0.3.4) (3.31.6)\r\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->mmrotate==0.3.4) (15.0.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mmrotate==0.3.4) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mmrotate==0.3.4) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->e2cnn->mmrotate==0.3.4) (1.3.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (4.3.8)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: e2cnn, mmrotate\r\n",
      "  Running setup.py develop for mmrotate\r\n",
      "Successfully installed e2cnn-0.2.3 mmrotate-0.3.4\r\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Clone and Install MMRotate 0.3.4\n",
    "!git clone https://github.com/zhangpeng2001/nirnet.git /kaggle/working/mmrotate\n",
    "%cd /kaggle/working/mmrotate\n",
    "# !git checkout v0.3.4  # Ensure exact version\n",
    "!pip install -r requirements/build.txt -q\n",
    "!pip install -v -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eade8341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:18.423548Z",
     "iopub.status.busy": "2025-09-16T14:58:18.423251Z",
     "iopub.status.idle": "2025-09-16T14:58:22.023997Z",
     "shell.execute_reply": "2025-09-16T14:58:22.023242Z"
    },
    "papermill": {
     "duration": 3.659326,
     "end_time": "2025-09-16T14:58:22.025442",
     "exception": false,
     "start_time": "2025-09-16T14:58:18.366116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yapf==0.40.1\r\n",
      "  Downloading yapf-0.40.1-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.11/dist-packages (from yapf==0.40.1) (8.7.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf==0.40.1) (4.3.8)\r\n",
      "Collecting tomli>=2.0.1 (from yapf==0.40.1)\r\n",
      "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.6.0->yapf==0.40.1) (3.23.0)\r\n",
      "Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tomli, yapf\r\n",
      "  Attempting uninstall: yapf\r\n",
      "    Found existing installation: yapf 0.43.0\r\n",
      "    Uninstalling yapf-0.43.0:\r\n",
      "      Successfully uninstalled yapf-0.43.0\r\n",
      "Successfully installed tomli-2.2.1 yapf-0.40.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install yapf==0.40.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b92fe75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:22.114687Z",
     "iopub.status.busy": "2025-09-16T14:58:22.114399Z",
     "iopub.status.idle": "2025-09-16T14:58:23.955003Z",
     "shell.execute_reply": "2025-09-16T14:58:23.953837Z"
    },
    "papermill": {
     "duration": 1.887099,
     "end_time": "2025-09-16T14:58:23.956736",
     "exception": false,
     "start_time": "2025-09-16T14:58:22.069637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcv                                  2.0.1\r\n",
      "mmcv-full                             1.7.2\r\n",
      "mmdet                                 2.28.2\r\n",
      "mmengine                              0.10.7\r\n",
      "mmrotate                              0.3.4               /kaggle/working/mmrotate\r\n",
      "pytorch-ignite                        0.5.2\r\n",
      "pytorch-lightning                     2.5.2\r\n",
      "torch                                 2.0.1+cu118\r\n",
      "torchao                               0.10.0\r\n",
      "torchaudio                            2.0.2+cu118\r\n",
      "torchdata                             0.11.0\r\n",
      "torchinfo                             1.8.0\r\n",
      "torchmetrics                          1.7.3\r\n",
      "torchsummary                          1.5.1\r\n",
      "torchtune                             0.6.1\r\n",
      "torchvision                           0.15.2+cu118\r\n",
      "yapf                                  0.40.1\r\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify Installations\n",
    "!pip list | grep -E 'torch|mmcv|mmdet|mmengine|mmrotate|yapf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d637b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.048750Z",
     "iopub.status.busy": "2025-09-16T14:58:24.047927Z",
     "iopub.status.idle": "2025-09-16T14:58:24.054371Z",
     "shell.execute_reply": "2025-09-16T14:58:24.053802Z"
    },
    "papermill": {
     "duration": 0.052034,
     "end_time": "2025-09-16T14:58:24.055450",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.003416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/mmrotate/configs/_base_/datasets/dotav1_ss1024.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmrotate/configs/_base_/datasets/dotav1_ss1024.py\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'DOTADataset'\n",
    "data_root = 'data/dotav1_ss1024/'\n",
    "\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RResize', img_scale=(1024, 1024)),\n",
    "    dict(type='RRandomFlip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='RResize'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=4,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'trainval/annfiles_v1/',\n",
    "        img_prefix=data_root + 'trainval/images/',\n",
    "        pipeline=train_pipeline),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'val/annfiles_v1/',\n",
    "        img_prefix=data_root + 'val/images/',\n",
    "        pipeline=test_pipeline),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'test/images/',\n",
    "        img_prefix=data_root + 'test/images/',\n",
    "        pipeline=test_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da908c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.144074Z",
     "iopub.status.busy": "2025-09-16T14:58:24.143828Z",
     "iopub.status.idle": "2025-09-16T14:58:24.150763Z",
     "shell.execute_reply": "2025-09-16T14:58:24.149905Z"
    },
    "papermill": {
     "duration": 0.052578,
     "end_time": "2025-09-16T14:58:24.151898",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.099320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmrotate/models/necks/nirnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmrotate/models/necks/nirnet.py\n",
    "import torch\n",
    "\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import auto_fp16\n",
    "from mmdet.models.necks import FPN\n",
    "from mmcv.cnn.bricks.transformer import MultiheadAttention\n",
    "\n",
    "from ..builder import ROTATED_NECKS\n",
    "\n",
    "\n",
    "@ROTATED_NECKS.register_module()\n",
    "class NIRNet(FPN):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 num_groups=4,  # New: For group attention\n",
    "                 conv_cfg=None,\n",
    "                 norm_cfg=None,\n",
    "                 act_cfg=None,\n",
    "                 **kwargs):\n",
    "        super(NIRNet, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            num_outs,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            **kwargs)\n",
    "\n",
    "        self.num_groups = num_groups  # New: Group attention param\n",
    "\n",
    "        self.encoder_conv = ConvModule(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            groups=out_channels,\n",
    "            inplace=False)\n",
    "        self.fusion_conv = ConvModule(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            inplace=False)\n",
    "        self.excite_conv = ConvModule(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            inplace=False)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.fcm_ip_channel_fc = torch.nn.Linear(out_channels // 2, 1)\n",
    "        self.fcm_ip_channel_atten = MultiheadAttention(embed_dims=16, num_heads=8)\n",
    "        self.fcm_sp_channel_atten = MultiheadAttention(embed_dims=16, num_heads=8)\n",
    "        self.fcm_sp_channel_fc = torch.nn.Linear(out_channels // 2, 1)\n",
    "\n",
    "        # New: Lightweight group attention convs (one per group, shared across paths for efficiency)\n",
    "        self.group_attn_convs = torch.nn.ModuleList([\n",
    "            ConvModule(\n",
    "                out_channels // (2 * num_groups),  # Split channels further for IP/SP\n",
    "                out_channels // (2 * num_groups),\n",
    "                1,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=None) for _ in range(num_groups)\n",
    "        ])\n",
    "\n",
    "    @auto_fp16()\n",
    "    def forward(self, inputs):\n",
    "        outs = super(NIRNet, self).forward(inputs)\n",
    "        outs = self.dpic(outs)\n",
    "        return tuple(outs)\n",
    "\n",
    "    def dpic(self, feats):\n",
    "\n",
    "        encoder_feats = []\n",
    "        \n",
    "        for feat in feats:\n",
    "            split_feat = self.encoder_conv(feat)\n",
    "            dw_feat, pw_feat = torch.split(split_feat, split_size_or_sections=128, dim=1)\n",
    "            # Enhanced NPM with frequency\n",
    "            weight1, weight2 = self.fp_npm(feat)\n",
    "            # Enhanced FCM with group attention\n",
    "            fcm_sp_feat = self.fcm_sp(pw_feat * (1 + weight1))\n",
    "            dw_feat = dw_feat * (1 + weight2)\n",
    "            pw_dw_features = torch.cat([fcm_sp_feat, dw_feat])\n",
    "            fcm_ip_feat = self.fcm_ip(dw_feat)\n",
    "            # Concatenation and fusion\n",
    "            fusion_feat = self.fusion_conv(torch.cat([fcm_ip_feat , fcm_sp_feat], dim=1))\n",
    "            encoder_feats.append(fusion_feat + feat)\n",
    "            \n",
    "        return encoder_feats\n",
    "    \n",
    "    def fcm_ip(self, feat):\n",
    "        # Optimal mask\n",
    "        pixel_feat = torch.max(feat, 1, keepdim=True)[0]\n",
    "        pixel_feat = pixel_feat + self.fcm_ip_channel_fc(feat.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # Optimal descriptor\n",
    "        flatten_feat = feat.view(feat.size(0), feat.size(1), -1)\n",
    "        channel_feat_mean = torch.mean(flatten_feat, 2, keepdim=True).view(feat.size(0), 8, 16)\n",
    "        channel_feat_max = torch.max(flatten_feat, 2, keepdim=True)[0].view(feat.size(0), 8, 16)\n",
    "        channel_feat = self.fcm_ip_channel_atten(channel_feat_mean, channel_feat_mean, channel_feat_max)\n",
    "        channel_feat = channel_feat.view(channel_feat.size(0), -1).unsqueeze(-1).unsqueeze(-1)\n",
    "        # New: Group attention\n",
    "        channel_feat = self._apply_group_attention(channel_feat)\n",
    "        # Optimal feature\n",
    "        fcm_ip_feat = pixel_feat * channel_feat \n",
    "        return fcm_ip_feat\n",
    "    \n",
    "    def fcm_sp(self, feat):\n",
    "        # Holistic mask\n",
    "        pixel_feat = torch.mean(feat, 1, keepdim=True)\n",
    "        pixel_feat = pixel_feat + self.fcm_sp_channel_fc(feat.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # Holistic descriptor\n",
    "        flatten_feat = feat.view(feat.size(0), feat.size(1), -1)\n",
    "        channel_feat_mean = self.sigmoid(torch.mean(flatten_feat, 2, keepdim=True).view(feat.size(0), 8, 16))\n",
    "        channel_feat_max = self.sigmoid(torch.max(flatten_feat, 2, keepdim=True)[0].view(feat.size(0), 8, 16))\n",
    "        channel_feat = self.fcm_sp_channel_atten(channel_feat_mean, channel_feat_mean, channel_feat_max)\n",
    "        channel_feat = channel_feat.view(channel_feat.size(0), -1).unsqueeze(-1).unsqueeze(-1)\n",
    "        # New: Group attention\n",
    "        channel_feat = self._apply_group_attention(channel_feat)\n",
    "        # Holistic feature\n",
    "        fcm_sp_feat = pixel_feat * channel_feat\n",
    "        return fcm_sp_feat\n",
    "\n",
    "    def fp_npm(self, feat):\n",
    "        # Original spatial min\n",
    "        pixel_feat = torch.min(feat, 1, keepdim=True)[0]\n",
    "        channel_feat = torch.min(torch.min(feat, 2, keepdim=True)[0], 3, keepdim=True)[0]\n",
    "        pcmin_feat = pixel_feat * channel_feat\n",
    "        # New: Frequency perception (low-freq blur, high-freq residual)\n",
    "        low_freq = torch.nn.functional.avg_pool2d(feat, kernel_size=3, stride=1, padding=1)\n",
    "        high_freq = feat - low_freq\n",
    "        freq_min = torch.min(low_freq, high_freq)\n",
    "        # Fuse spatial + freq\n",
    "        pcmin_feat = pcmin_feat + freq_min  # Simple addition for fusion\n",
    "        excitation = self.excite_conv(pcmin_feat)\n",
    "        excitation = self.sigmoid(excitation)\n",
    "        excitation1, excitation2 = torch.split(excitation, split_size_or_sections=128, dim=1)\n",
    "        return excitation1, excitation2\n",
    "\n",
    "    # New: Helper for group attention\n",
    "    def _apply_group_attention(self, feat):\n",
    "        groups = torch.chunk(feat, self.num_groups, dim=1)  # Split channels\n",
    "        attn_groups = [self.sigmoid(self.group_attn_convs[i](g)) * g for i, g in enumerate(groups)]\n",
    "        return torch.cat(attn_groups, dim=1)  # Fuse back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef559d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.242541Z",
     "iopub.status.busy": "2025-09-16T14:58:24.242262Z",
     "iopub.status.idle": "2025-09-16T14:58:24.254184Z",
     "shell.execute_reply": "2025-09-16T14:58:24.253596Z"
    },
    "papermill": {
     "duration": 0.057846,
     "end_time": "2025-09-16T14:58:24.255249",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.197403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mmrotate/models/backbones/pkinet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmrotate/models/backbones/pkinet.py\n",
    "import math\n",
    "from typing import Optional, Union, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from mmcv.cnn import ConvModule, build_norm_layer\n",
    "from mmcv.cnn.bricks import DropPath\n",
    "from mmengine.model import BaseModule, constant_init\n",
    "from mmengine.model.weight_init import trunc_normal_init, normal_init\n",
    "from mmengine.logging import MMLogger\n",
    "\n",
    "from mmrotate.models.builder import ROTATED_BACKBONES\n",
    "from mmrotate.models.utils import autopad, make_divisible, BHWC2BCHW, BCHW2BHWC\n",
    "\n",
    "\n",
    "class GSiLU(BaseModule):\n",
    "    \"\"\"Global Sigmoid-Gated Linear Unit, reproduced from paper <SIMPLE CNN FOR VISION>\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.adpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(self.adpool(x))\n",
    "\n",
    "\n",
    "class CAA(BaseModule):\n",
    "    \"\"\"Context Anchor Attention\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: int,\n",
    "            h_kernel_size: int = 11,\n",
    "            v_kernel_size: int = 11,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        self.avg_pool = nn.AvgPool2d(7, 1, 3)\n",
    "        self.conv1 = ConvModule(channels, channels, 1, 1, 0,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.h_conv = ConvModule(channels, channels, (1, h_kernel_size), 1,\n",
    "                                 (0, h_kernel_size // 2), groups=channels,\n",
    "                                 norm_cfg=None, act_cfg=None)\n",
    "        self.v_conv = ConvModule(channels, channels, (v_kernel_size, 1), 1,\n",
    "                                 (v_kernel_size // 2, 0), groups=channels,\n",
    "                                 norm_cfg=None, act_cfg=None)\n",
    "        self.conv2 = ConvModule(channels, channels, 1, 1, 0,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_factor = self.act(self.conv2(self.v_conv(self.h_conv(self.conv1(self.avg_pool(x))))))\n",
    "        return attn_factor\n",
    "\n",
    "\n",
    "class ConvFFN(BaseModule):\n",
    "    \"\"\"Multi-layer perceptron implemented with ConvModule\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: Optional[int] = None,\n",
    "            hidden_channels_scale: float = 4.0,\n",
    "            hidden_kernel_size: int = 3,\n",
    "            dropout_rate: float = 0.,\n",
    "            add_identity: bool = True,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        out_channels = out_channels or in_channels\n",
    "        hidden_channels = int(in_channels * hidden_channels_scale)\n",
    "\n",
    "        self.ffn_layers = nn.Sequential(\n",
    "            BCHW2BHWC(),\n",
    "            nn.LayerNorm(in_channels),\n",
    "            BHWC2BCHW(),\n",
    "            ConvModule(in_channels, hidden_channels, kernel_size=1, stride=1, padding=0,\n",
    "                       norm_cfg=norm_cfg, act_cfg=act_cfg),\n",
    "            ConvModule(hidden_channels, hidden_channels, kernel_size=hidden_kernel_size, stride=1,\n",
    "                       padding=hidden_kernel_size // 2, groups=hidden_channels,\n",
    "                       norm_cfg=norm_cfg, act_cfg=None),\n",
    "            GSiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            ConvModule(hidden_channels, out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                       norm_cfg=norm_cfg, act_cfg=act_cfg),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.add_identity = add_identity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.ffn_layers(x) if self.add_identity else self.ffn_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Stem(BaseModule):\n",
    "    \"\"\"Stem layer\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            expansion: float = 1.0,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        hidden_channels = make_divisible(int(out_channels * expansion), 8)\n",
    "\n",
    "        self.down_conv = ConvModule(in_channels, hidden_channels, kernel_size=3, stride=2, padding=1,\n",
    "                                    norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.conv1 = ConvModule(hidden_channels, hidden_channels, kernel_size=3, stride=1, padding=1,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.conv2 = ConvModule(hidden_channels, out_channels, kernel_size=3, stride=1, padding=1,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv2(self.conv1(self.down_conv(x)))\n",
    "\n",
    "\n",
    "class DownSamplingLayer(BaseModule):\n",
    "    \"\"\"Down sampling layer\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: Optional[int] = None,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        out_channels = out_channels or (in_channels * 2)\n",
    "\n",
    "        self.down_conv = ConvModule(in_channels, out_channels, kernel_size=3, stride=2, padding=1,\n",
    "                                    norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_conv(x)\n",
    "\n",
    "\n",
    "class InceptionBottleneck(BaseModule):\n",
    "    \"\"\"Bottleneck with Inception module\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: Optional[int] = None,\n",
    "            kernel_sizes: Sequence[int] = (3, 5, 7, 9, 11),\n",
    "            dilations: Sequence[int] = (1, 1, 1, 1, 1),\n",
    "            expansion: float = 1.0,\n",
    "            add_identity: bool = True,\n",
    "            with_caa: bool = True,\n",
    "            caa_kernel_size: int = 11,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        out_channels = out_channels or in_channels\n",
    "        hidden_channels = make_divisible(int(out_channels * expansion), 8)\n",
    "\n",
    "        self.pre_conv = ConvModule(in_channels, hidden_channels, 1, 1, 0, 1,\n",
    "                                   norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "\n",
    "        self.dw_conv = ConvModule(hidden_channels, hidden_channels, kernel_sizes[0], 1,\n",
    "                                  autopad(kernel_sizes[0], None, dilations[0]), dilations[0],\n",
    "                                  groups=hidden_channels, norm_cfg=None, act_cfg=None)\n",
    "        self.dw_conv1 = ConvModule(hidden_channels, hidden_channels, kernel_sizes[1], 1,\n",
    "                                   autopad(kernel_sizes[1], None, dilations[1]), dilations[1],\n",
    "                                   groups=hidden_channels, norm_cfg=None, act_cfg=None)\n",
    "        self.dw_conv2 = ConvModule(hidden_channels, hidden_channels, kernel_sizes[2], 1,\n",
    "                                   autopad(kernel_sizes[2], None, dilations[2]), dilations[2],\n",
    "                                   groups=hidden_channels, norm_cfg=None, act_cfg=None)\n",
    "        self.dw_conv3 = ConvModule(hidden_channels, hidden_channels, kernel_sizes[3], 1,\n",
    "                                   autopad(kernel_sizes[3], None, dilations[3]), dilations[3],\n",
    "                                   groups=hidden_channels, norm_cfg=None, act_cfg=None)\n",
    "        self.dw_conv4 = ConvModule(hidden_channels, hidden_channels, kernel_sizes[4], 1,\n",
    "                                   autopad(kernel_sizes[4], None, dilations[4]), dilations[4],\n",
    "                                   groups=hidden_channels, norm_cfg=None, act_cfg=None)\n",
    "        self.pw_conv = ConvModule(hidden_channels, hidden_channels, 1, 1, 0, 1,\n",
    "                                  norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "\n",
    "        if with_caa:\n",
    "            self.caa_factor = CAA(hidden_channels, caa_kernel_size, caa_kernel_size, None, None)\n",
    "        else:\n",
    "            self.caa_factor = None\n",
    "\n",
    "        self.add_identity = add_identity and in_channels == out_channels\n",
    "\n",
    "        self.post_conv = ConvModule(hidden_channels, out_channels, 1, 1, 0, 1,\n",
    "                                    norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_conv(x)\n",
    "\n",
    "        y = x  # if there is an inplace operation of x, use y = x.clone() instead of y = x\n",
    "        x = self.dw_conv(x)\n",
    "        x = x + self.dw_conv1(x) + self.dw_conv2(x) + self.dw_conv3(x) + self.dw_conv4(x)\n",
    "        x = self.pw_conv(x)\n",
    "        if self.caa_factor is not None:\n",
    "            y = self.caa_factor(y)\n",
    "        if self.add_identity:\n",
    "            y = x * y\n",
    "            x = x + y\n",
    "        else:\n",
    "            x = x * y\n",
    "\n",
    "        x = self.post_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PKIBlock(BaseModule):\n",
    "    \"\"\"Poly Kernel Inception Block\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: Optional[int] = None,\n",
    "            kernel_sizes: Sequence[int] = (3, 5, 7, 9, 11),\n",
    "            dilations: Sequence[int] = (1, 1, 1, 1, 1),\n",
    "            with_caa: bool = True,\n",
    "            caa_kernel_size: int = 11,\n",
    "            expansion: float = 1.0,\n",
    "            ffn_scale: float = 4.0,\n",
    "            ffn_kernel_size: int = 3,\n",
    "            dropout_rate: float = 0.,\n",
    "            drop_path_rate: float = 0.,\n",
    "            layer_scale: Optional[float] = 1.0,\n",
    "            add_identity: bool = True,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        out_channels = out_channels or in_channels\n",
    "        hidden_channels = make_divisible(int(out_channels * expansion), 8)\n",
    "\n",
    "        if norm_cfg is not None:\n",
    "            self.norm1 = build_norm_layer(norm_cfg, in_channels)[1]\n",
    "            self.norm2 = build_norm_layer(norm_cfg, hidden_channels)[1]\n",
    "        else:\n",
    "            self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "            self.norm2 = nn.BatchNorm2d(hidden_channels)\n",
    "\n",
    "        self.block = InceptionBottleneck(in_channels, hidden_channels, kernel_sizes, dilations,\n",
    "                                         expansion=1.0, add_identity=True,\n",
    "                                         with_caa=with_caa, caa_kernel_size=caa_kernel_size,\n",
    "                                         norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.ffn = ConvFFN(hidden_channels, out_channels, ffn_scale, ffn_kernel_size, dropout_rate, add_identity=False,\n",
    "                           norm_cfg=None, act_cfg=None)\n",
    "        self.drop_path = DropPath(drop_path_rate) if drop_path_rate > 0 else nn.Identity()\n",
    "\n",
    "        self.layer_scale = layer_scale\n",
    "        if self.layer_scale:\n",
    "            self.gamma1 = nn.Parameter(layer_scale * torch.ones(hidden_channels), requires_grad=True)\n",
    "            self.gamma2 = nn.Parameter(layer_scale * torch.ones(out_channels), requires_grad=True)\n",
    "        self.add_identity = add_identity and in_channels == out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.layer_scale:\n",
    "            if self.add_identity:\n",
    "                x = x + self.drop_path(self.gamma1.unsqueeze(-1).unsqueeze(-1) * self.block(self.norm1(x)))\n",
    "                x = x + self.drop_path(self.gamma2.unsqueeze(-1).unsqueeze(-1) * self.ffn(self.norm2(x)))\n",
    "            else:\n",
    "                x = self.drop_path(self.gamma1.unsqueeze(-1).unsqueeze(-1) * self.block(self.norm1(x)))\n",
    "                x = self.drop_path(self.gamma2.unsqueeze(-1).unsqueeze(-1) * self.ffn(self.norm2(x)))\n",
    "        else:\n",
    "            if self.add_identity:\n",
    "                x = x + self.drop_path(self.block(self.norm1(x)))\n",
    "                x = x + self.drop_path(self.ffn(self.norm2(x)))\n",
    "            else:\n",
    "                x = self.drop_path(self.block(self.norm1(x)))\n",
    "                x = self.drop_path(self.ffn(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PKIStage(BaseModule):\n",
    "    \"\"\"Poly Kernel Inception Stage\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            num_blocks: int,\n",
    "            kernel_sizes: Sequence[int] = (3, 5, 7, 9, 11),\n",
    "            dilations: Sequence[int] = (1, 1, 1, 1, 1),\n",
    "            expansion: float = 0.5,\n",
    "            ffn_scale: float = 4.0,\n",
    "            ffn_kernel_size: int = 3,\n",
    "            dropout_rate: float = 0.,\n",
    "            drop_path_rate: Union[float, list] = 0.,\n",
    "            layer_scale: Optional[float] = 1.0,\n",
    "            shortcut_with_ffn: bool = True,\n",
    "            shortcut_ffn_scale: float = 4.0,\n",
    "            shortcut_ffn_kernel_size: int = 5,\n",
    "            add_identity: bool = True,\n",
    "            with_caa: bool = True,\n",
    "            caa_kernel_size: int = 11,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(init_cfg)\n",
    "        hidden_channels = make_divisible(int(out_channels * expansion), 8)\n",
    "\n",
    "        self.downsample = DownSamplingLayer(in_channels, out_channels, norm_cfg, act_cfg)\n",
    "\n",
    "        self.conv1 = ConvModule(out_channels, 2 * hidden_channels, kernel_size=1, stride=1, padding=0, dilation=1,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.conv2 = ConvModule(2 * hidden_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.conv3 = ConvModule(out_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1,\n",
    "                                norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "\n",
    "        self.ffn = ConvFFN(hidden_channels, hidden_channels, shortcut_ffn_scale, shortcut_ffn_kernel_size, 0.,\n",
    "                           add_identity=True, norm_cfg=None, act_cfg=None) if shortcut_with_ffn else None\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            PKIBlock(hidden_channels, hidden_channels, kernel_sizes, dilations, with_caa,\n",
    "                     caa_kernel_size+2*i, 1.0, ffn_scale, ffn_kernel_size, dropout_rate,\n",
    "                     drop_path_rate[i] if isinstance(drop_path_rate, list) else drop_path_rate,\n",
    "                     layer_scale, add_identity, norm_cfg, act_cfg) for i in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "\n",
    "        x, y = list(self.conv1(x).chunk(2, 1))\n",
    "        if self.ffn is not None:\n",
    "            x = self.ffn(x)\n",
    "\n",
    "        z = [x]\n",
    "        t = torch.zeros(y.shape, device=y.device)\n",
    "        for block in self.blocks:\n",
    "            t = t + block(y)\n",
    "        z.append(t)\n",
    "        z = torch.cat(z, dim=1)\n",
    "        z = self.conv2(z)\n",
    "        z = self.conv3(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "@ROTATED_BACKBONES.register_module()\n",
    "class PKINet(BaseModule):\n",
    "    \"\"\"Poly Kernel Inception Network\"\"\"\n",
    "    arch_settings = {\n",
    "        # from left to right: (indices)\n",
    "        # in_channels(0), out_channels(1), num_blocks(2), kernel_sizes(3), dilations(4), expansion(5),\n",
    "        # ffn_scale(6), ffn_kernel_size(7), dropout_rate(8), layer_scale(9), shortcut_with_ffn(10),\n",
    "        # shortcut_ffn_scale(11), shortcut_ffn_kernel_size(12), add_identity(13), with_caa(14), caa_kernel_size(15)\n",
    "        'T': [[16, 32, 4, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 8.0, 5, True, True, 11],\n",
    "              [32, 64, 14, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 8.0, 7, True, True, 11],\n",
    "              [64, 128, 22, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 4.0, 9, True, True, 11],\n",
    "              [128, 256, 4, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 4.0, 11, True, True, 11]],\n",
    "\n",
    "        'S': [[32, 64, 4, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 8.0, 5, True, True, 11],\n",
    "              [64, 128, 12, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 8.0, 7, True, True, 11],\n",
    "              [128, 256, 20, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 4.0, 9, True, True, 11],\n",
    "              [256, 512, 4, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 4.0, 11, True, True, 11]],\n",
    "\n",
    "        'B': [[40, 80, 6, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 8.0, 5, True, True, 11],\n",
    "              [80, 160, 16, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 8.0, 7, True, True, 11],\n",
    "              [160, 320, 24, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 4.0, 9, True, True, 11],\n",
    "              [320, 640, 6, (3, 5, 7, 9, 11), (1, 1, 1, 1, 1), 0.5, 4.0, 3, 0.1, 1.0, True, 4.0, 11, True, True, 11]],\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            arch: str = 'S',\n",
    "            out_indices: Sequence[int] = (2, 3, 4),\n",
    "            drop_path_rate: float = 0.1,\n",
    "            frozen_stages: int = -1,\n",
    "            norm_eval: bool = False,\n",
    "            arch_setting: Optional[Sequence[list]] = None,\n",
    "            norm_cfg: Optional[dict] = dict(type='BN', momentum=0.03, eps=0.001),\n",
    "            act_cfg: Optional[dict] = dict(type='SiLU'),\n",
    "            init_cfg: Optional[dict] = dict(type='Kaiming',\n",
    "                                            layer='Conv2d',\n",
    "                                            a=math.sqrt(5),\n",
    "                                            distribution='uniform',\n",
    "                                            mode='fan_in',\n",
    "                                            nonlinearity='leaky_relu'),\n",
    "    ):\n",
    "        super().__init__(init_cfg=init_cfg)\n",
    "        arch_setting = arch_setting or self.arch_settings[arch]\n",
    "\n",
    "        assert set(out_indices).issubset(i for i in range(len(arch_setting) + 1))\n",
    "        if frozen_stages not in range(-1, len(arch_setting) + 1):\n",
    "            raise ValueError(f'frozen_stages must be in range(-1, len(arch_setting) + 1). But received {frozen_stages}')\n",
    "\n",
    "        self.out_indices = out_indices\n",
    "        self.frozen_stages = frozen_stages\n",
    "        self.norm_eval = norm_eval\n",
    "        self.stages = nn.ModuleList()\n",
    "\n",
    "        self.stem = Stem(3, arch_setting[0][0], expansion=1.0, norm_cfg=norm_cfg, act_cfg=act_cfg)\n",
    "        self.stages.append(self.stem)\n",
    "\n",
    "        depths = [x[2] for x in arch_setting]\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        for i, (in_channels, out_channels, num_blocks, kernel_sizes, dilations, expansion, ffn_scale, ffn_kernel_size,\n",
    "                dropout_rate, layer_scale, shortcut_with_ffn, shortcut_ffn_scale, shortcut_ffn_kernel_size,\n",
    "                add_identity, with_caa, caa_kernel_size) in enumerate(arch_setting):\n",
    "            stage = PKIStage(in_channels, out_channels, num_blocks, kernel_sizes, dilations, expansion,\n",
    "                             ffn_scale, ffn_kernel_size, dropout_rate, dpr[sum(depths[:i]):sum(depths[:i + 1])],\n",
    "                             layer_scale, shortcut_with_ffn, shortcut_ffn_scale, shortcut_ffn_kernel_size,\n",
    "                             add_identity, with_caa, caa_kernel_size, norm_cfg, act_cfg)\n",
    "            self.stages.append(stage)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            x = stage(x)\n",
    "            if i in self.out_indices:\n",
    "                outs.append(x)\n",
    "        return tuple(outs)\n",
    "\n",
    "    def init_weights(self):\n",
    "        logger = MMLogger.get_current_instance()\n",
    "        if self.init_cfg is None:\n",
    "            logger.warning(f'No pre-trained weights for {self.__class__.__name__}, training start from scratch.')\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    trunc_normal_init(m, std=.02, bias=0.)\n",
    "                elif isinstance(m, nn.LayerNorm):\n",
    "                    constant_init(m, val=1.0, bias=0.)\n",
    "                elif isinstance(m, nn.Conv2d):\n",
    "                    fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                    fan_out //= m.groups\n",
    "                    normal_init(m, mean=0, std=math.sqrt(2.0 / fan_out), bias=0)\n",
    "        else:\n",
    "            super().init_weights()\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()\n",
    "\n",
    "    def _freeze_stages(self):\n",
    "        if self.frozen_stages >= 0:\n",
    "            for i in range(self.frozen_stages):\n",
    "                m = self.stages[i]\n",
    "                m.eval()\n",
    "                for param in m.parameters():\n",
    "                    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dde6045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.344979Z",
     "iopub.status.busy": "2025-09-16T14:58:24.344455Z",
     "iopub.status.idle": "2025-09-16T14:58:24.349107Z",
     "shell.execute_reply": "2025-09-16T14:58:24.348388Z"
    },
    "papermill": {
     "duration": 0.050652,
     "end_time": "2025-09-16T14:58:24.350292",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.299640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmrotate/models/backbones/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmrotate/models/backbones/__init__.py\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from .re_resnet import ReResNet\n",
    "from .pkinet import PKINet\n",
    "\n",
    "__all__ = ['ReResNet', 'PKINet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22409024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.438804Z",
     "iopub.status.busy": "2025-09-16T14:58:24.438525Z",
     "iopub.status.idle": "2025-09-16T14:58:24.442539Z",
     "shell.execute_reply": "2025-09-16T14:58:24.441816Z"
    },
    "papermill": {
     "duration": 0.049674,
     "end_time": "2025-09-16T14:58:24.443764",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.394090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/kaggle/working/mmrotate/configs/firnet\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1a7db36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.533393Z",
     "iopub.status.busy": "2025-09-16T14:58:24.533005Z",
     "iopub.status.idle": "2025-09-16T14:58:24.538514Z",
     "shell.execute_reply": "2025-09-16T14:58:24.537889Z"
    },
    "papermill": {
     "duration": 0.051149,
     "end_time": "2025-09-16T14:58:24.539594",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.488445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/mmrotate/mmrotate/models/utils/cnn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmrotate/mmrotate/models/utils/cnn.py\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def autopad(kernel_size: int, padding: int = None, dilation: int = 1):\n",
    "    assert kernel_size % 2 == 1, 'if use autopad, kernel size must be odd'\n",
    "    if dilation > 1:\n",
    "        kernel_size = dilation * (kernel_size - 1) + 1\n",
    "    if padding is None:\n",
    "        padding = kernel_size // 2\n",
    "    return padding\n",
    "\n",
    "\n",
    "def make_divisible(value, divisor, min_value=None, min_ratio=0.9):\n",
    "    \"\"\"Make divisible function.\n",
    "\n",
    "    This function rounds the channel number to the nearest value that can be\n",
    "    divisible by the divisor. It is taken from the original tf repo. It ensures\n",
    "    that all layers have a channel number that is divisible by divisor. It can\n",
    "    be seen here: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py  # noqa\n",
    "\n",
    "    Args:\n",
    "        value (int, float): The original channel number.\n",
    "        divisor (int): The divisor to fully divide the channel number.\n",
    "        min_value (int): The minimum value of the output channel.\n",
    "            Default: None, means that the minimum value equal to the divisor.\n",
    "        min_ratio (float): The minimum ratio of the rounded channel number to\n",
    "            the original channel number. Default: 0.9.\n",
    "\n",
    "    Returns:\n",
    "        int: The modified output channel number.\n",
    "    \"\"\"\n",
    "\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_value = max(min_value, int(value + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than (1-min_ratio).\n",
    "    if new_value < min_ratio * value:\n",
    "        new_value += divisor\n",
    "    return new_value\n",
    "\n",
    "\n",
    "class BCHW2BHWC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x):\n",
    "        return x.permute([0, 2, 3, 1])\n",
    "\n",
    "\n",
    "class BHWC2BCHW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x):\n",
    "        return x.permute([0, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b25a42da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.627163Z",
     "iopub.status.busy": "2025-09-16T14:58:24.626893Z",
     "iopub.status.idle": "2025-09-16T14:58:24.631652Z",
     "shell.execute_reply": "2025-09-16T14:58:24.631048Z"
    },
    "papermill": {
     "duration": 0.049005,
     "end_time": "2025-09-16T14:58:24.632675",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.583670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/mmrotate/mmrotate/models/utils/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/mmrotate/mmrotate/models/utils/__init__.py\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from .cnn import autopad, make_divisible, BCHW2BHWC, BHWC2BCHW\n",
    "from .enn import (build_enn_divide_feature, build_enn_feature,\n",
    "                  build_enn_norm_layer, build_enn_trivial_feature, ennAvgPool,\n",
    "                  ennConv, ennInterpolate, ennMaxPool, ennReLU, ennTrivialConv)\n",
    "from .orconv import ORConv2d\n",
    "from .ripool import RotationInvariantPooling\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'autopad', 'make_divisible', 'BCHW2BHWC', 'BHWC2BCHW',\n",
    "    'ORConv2d', 'RotationInvariantPooling', 'ennConv', 'ennReLU', 'ennAvgPool',\n",
    "    'ennMaxPool', 'ennInterpolate', 'build_enn_divide_feature',\n",
    "    'build_enn_feature', 'build_enn_norm_layer', 'build_enn_trivial_feature',\n",
    "    'ennTrivialConv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85dedfc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.718291Z",
     "iopub.status.busy": "2025-09-16T14:58:24.718009Z",
     "iopub.status.idle": "2025-09-16T14:58:24.725108Z",
     "shell.execute_reply": "2025-09-16T14:58:24.724434Z"
    },
    "papermill": {
     "duration": 0.051449,
     "end_time": "2025-09-16T14:58:24.726313",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.674864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs/firnet/firnet_r50_fpn_1x_sccos.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/firnet/firnet_r50_fpn_1x_sccos.py\n",
    "_base_ = [\n",
    "    '../_base_/default_runtime.py', '../_base_/schedules/schedule_1x.py',\n",
    "    '../_base_/datasets/dotav1_ss1024.py'\n",
    "]\n",
    "angle_version = 'le135'\n",
    "model = dict(\n",
    "    type='OrientedRCNN',\n",
    "     backbone=dict(\n",
    "        type='PKINet',\n",
    "        arch='T',\n",
    "        drop_path_rate=0.1,\n",
    "        out_indices=(1, 2, 3, 4),\n",
    "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
    "        act_cfg=dict(type='SiLU'),\n",
    "    ),\n",
    "    \n",
    "    neck=dict(\n",
    "        type='NIRNet',\n",
    "        in_channels=[32, 64, 128, 256],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    rpn_head=dict(\n",
    "        type='OrientedRPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        version=angle_version,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='MidpointOffsetCoder',\n",
    "            angle_range=angle_version,\n",
    "            target_means=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(\n",
    "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
    "    roi_head=dict(\n",
    "        type='OrientedStandardRoIHead',\n",
    "        bbox_roi_extractor=dict(\n",
    "            type='RotatedSingleRoIExtractor',\n",
    "            roi_layer=dict(\n",
    "                type='RoIAlignRotated',\n",
    "                out_size=7,\n",
    "                sample_num=2,\n",
    "                clockwise=True),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        bbox_head=dict(\n",
    "            type='RotatedShared2FCBBoxHead',\n",
    "            in_channels=256,\n",
    "            fc_out_channels=1024,\n",
    "            roi_feat_size=7,\n",
    "            num_classes=1,\n",
    "            bbox_coder=dict(\n",
    "                type='DeltaXYWHAOBBoxCoder',\n",
    "                angle_range=angle_version,\n",
    "                norm_factor=None,\n",
    "                edge_swap=True,\n",
    "                proj_xy=True,\n",
    "                target_means=(.0, .0, .0, .0, .0),\n",
    "                target_stds=(0.1, 0.1, 0.2, 0.2, 0.1)),\n",
    "            reg_class_agnostic=True,\n",
    "            loss_cls=dict(\n",
    "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))),\n",
    "    train_cfg=dict(\n",
    "        rpn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.3,\n",
    "                min_pos_iou=0.3,\n",
    "                match_low_quality=True,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=256,\n",
    "                pos_fraction=0.5,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=False),\n",
    "            allowed_border=0,\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        rpn_proposal=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.8),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.5,\n",
    "                neg_iou_thr=0.5,\n",
    "                min_pos_iou=0.5,\n",
    "                match_low_quality=False,\n",
    "                iou_calculator=dict(type='RBboxOverlaps2D'),\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RRandomSampler',\n",
    "                num=512,\n",
    "                pos_fraction=0.25,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=True),\n",
    "            pos_weight=-1,\n",
    "            debug=False)),\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.8),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            nms_pre=2000,\n",
    "            min_bbox_size=0,\n",
    "            score_thr=0.05,\n",
    "            nms=dict(iou_thr=0.1),\n",
    "            max_per_img=2000)))\n",
    "\n",
    "dataset_type = 'DOTADataset'\n",
    "# data_root = '/kaggle/working/sccos_dota/'\n",
    "data_root = '/kaggle/input/sccos-dota/sccos_dota/'\n",
    "classes = ('ship',)  # Explicitly define classes\n",
    "\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RResize', img_scale=(1024, 1024)),\n",
    "    dict(type='RRandomFlip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='RResize'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=4,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'train/labels/',\n",
    "        img_prefix=data_root + 'train/images/',\n",
    "        pipeline=train_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'val/labels/',\n",
    "        img_prefix=data_root + 'val/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'test/labels/',\n",
    "        img_prefix=data_root + 'test/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)))\n",
    "evaluation = dict(interval=1, metric='mAP', save_best='mAP') # Add save_best here\n",
    "lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=1000,\n",
    "    warmup_ratio=0.3333333333333333,\n",
    "    step=[8, 11])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=10)\n",
    "checkpoint_config = dict(interval=1) # Keep interval for saving\n",
    "log_config = dict(\n",
    "    interval=100,\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        dict(type='WandbLoggerHook',\n",
    "             init_kwargs=dict(\n",
    "                 project='FREANet_training',\n",
    "                 name='FREANet_PKI'),\n",
    "             interval=100)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247fa000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:24.815823Z",
     "iopub.status.busy": "2025-09-16T14:58:24.815074Z",
     "iopub.status.idle": "2025-09-16T14:58:36.250028Z",
     "shell.execute_reply": "2025-09-16T14:58:36.249208Z"
    },
    "papermill": {
     "duration": 11.482084,
     "end_time": "2025-09-16T14:58:36.251530",
     "exception": false,
     "start_time": "2025-09-16T14:58:24.769446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/cnn/utils/flops_counter.py:536: UserWarning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\r\n",
      "  warnings.warn('variables __flops__ or __params__ are already '\r\n",
      "OrientedRCNN(\r\n",
      "  22.299 M, 99.864% Params, 244.235 GFLOPs, 100.544% FLOPs, \r\n",
      "  (backbone): PKINet(\r\n",
      "    4.129 M, 18.491% Params, 22.691 GFLOPs, 9.341% FLOPs, \r\n",
      "    (stages): ModuleList(\r\n",
      "      (0): Stem(\r\n",
      "        0.005 M, 0.023% Params, 1.321 GFLOPs, 0.544% FLOPs, \r\n",
      "        (down_conv): ConvModule(\r\n",
      "          0.0 M, 0.002% Params, 0.113 GFLOPs, 0.047% FLOPs, \r\n",
      "          (conv): Conv2d(0.0 M, 0.002% Params, 0.113 GFLOPs, 0.047% FLOPs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv1): ConvModule(\r\n",
      "          0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, \r\n",
      "          (conv): Conv2d(0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv2): ConvModule(\r\n",
      "          0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, \r\n",
      "          (conv): Conv2d(0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): PKIStage(\r\n",
      "        0.052 M, 0.234% Params, 3.451 GFLOPs, 1.421% FLOPs, \r\n",
      "        (downsample): DownSamplingLayer(\r\n",
      "          0.005 M, 0.021% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "          (down_conv): ConvModule(\r\n",
      "            0.005 M, 0.021% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "            (conv): Conv2d(0.005 M, 0.021% Params, 0.302 GFLOPs, 0.124% FLOPs, 16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "            (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (conv1): ConvModule(\r\n",
      "          0.001 M, 0.005% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.001 M, 0.005% Params, 0.067 GFLOPs, 0.028% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv2): ConvModule(\r\n",
      "          0.001 M, 0.005% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.001 M, 0.005% Params, 0.067 GFLOPs, 0.028% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv3): ConvModule(\r\n",
      "          0.001 M, 0.005% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.001 M, 0.005% Params, 0.067 GFLOPs, 0.028% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (ffn): ConvFFN(\r\n",
      "          0.008 M, 0.034% Params, 0.506 GFLOPs, 0.208% FLOPs, \r\n",
      "          (ffn_layers): Sequential(\r\n",
      "            0.008 M, 0.034% Params, 0.506 GFLOPs, 0.208% FLOPs, \r\n",
      "            (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (1): LayerNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, (16,), eps=1e-05, elementwise_affine=True)\r\n",
      "            (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (3): ConvModule(\r\n",
      "              0.002 M, 0.010% Params, 0.143 GFLOPs, 0.059% FLOPs, \r\n",
      "              (conv): Conv2d(0.002 M, 0.010% Params, 0.143 GFLOPs, 0.059% FLOPs, 16, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (4): ConvModule(\r\n",
      "              0.003 M, 0.015% Params, 0.218 GFLOPs, 0.090% FLOPs, \r\n",
      "              (conv): Conv2d(0.003 M, 0.015% Params, 0.218 GFLOPs, 0.090% FLOPs, 128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\r\n",
      "            )\r\n",
      "            (5): GSiLU(\r\n",
      "              0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "              (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, output_size=1)\r\n",
      "            )\r\n",
      "            (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "            (7): ConvModule(\r\n",
      "              0.002 M, 0.009% Params, 0.135 GFLOPs, 0.056% FLOPs, \r\n",
      "              (conv): Conv2d(0.002 M, 0.009% Params, 0.135 GFLOPs, 0.056% FLOPs, 128, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (blocks): ModuleList(\r\n",
      "          (0): PKIBlock(\r\n",
      "            0.009 M, 0.041% Params, 0.604 GFLOPs, 0.249% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.006 M, 0.028% Params, 0.416 GFLOPs, 0.171% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, 16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, 16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, 16, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, 16, 16, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=16)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.001 M, 0.004% Params, 0.062 GFLOPs, 0.025% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.013 GFLOPs, 0.005% FLOPs, 16, 16, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=16)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.013 GFLOPs, 0.005% FLOPs, 16, 16, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=16)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, (16,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, 16, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): Identity(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (1): PKIBlock(\r\n",
      "            0.009 M, 0.041% Params, 0.608 GFLOPs, 0.250% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.006 M, 0.029% Params, 0.42 GFLOPs, 0.173% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, 16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, 16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, 16, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, 16, 16, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=16)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.001 M, 0.004% Params, 0.066 GFLOPs, 0.027% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.015 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.015 GFLOPs, 0.006% FLOPs, 16, 16, kernel_size=(1, 13), stride=(1, 1), padding=(0, 6), groups=16)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.015 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.015 GFLOPs, 0.006% FLOPs, 16, 16, kernel_size=(13, 1), stride=(1, 1), padding=(6, 0), groups=16)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, (16,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, 16, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (2): PKIBlock(\r\n",
      "            0.009 M, 0.041% Params, 0.612 GFLOPs, 0.252% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.006 M, 0.029% Params, 0.425 GFLOPs, 0.175% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, 16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, 16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, 16, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, 16, 16, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=16)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.001 M, 0.005% Params, 0.07 GFLOPs, 0.029% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), groups=16)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(15, 1), stride=(1, 1), padding=(7, 0), groups=16)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, (16,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, 16, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (3): PKIBlock(\r\n",
      "            0.009 M, 0.042% Params, 0.617 GFLOPs, 0.254% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.007 M, 0.029% Params, 0.429 GFLOPs, 0.177% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.01 GFLOPs, 0.004% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.002% Params, 0.027 GFLOPs, 0.011% FLOPs, 16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.052 GFLOPs, 0.022% FLOPs, 16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.086 GFLOPs, 0.035% FLOPs, 16, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=16)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.009% Params, 0.128 GFLOPs, 0.053% FLOPs, 16, 16, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=16)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.001 M, 0.005% Params, 0.074 GFLOPs, 0.031% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.019 GFLOPs, 0.008% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.019 GFLOPs, 0.008% FLOPs, 16, 16, kernel_size=(1, 17), stride=(1, 1), padding=(0, 8), groups=16)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.019 GFLOPs, 0.008% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.019 GFLOPs, 0.008% FLOPs, 16, 16, kernel_size=(17, 1), stride=(1, 1), padding=(8, 0), groups=16)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.001% Params, 0.018 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.017 GFLOPs, 0.007% FLOPs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.003 M, 0.013% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, (16,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.071 GFLOPs, 0.029% FLOPs, 16, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.042 GFLOPs, 0.017% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 16, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (2): PKIStage(\r\n",
      "        0.421 M, 1.885% Params, 6.937 GFLOPs, 2.856% FLOPs, \r\n",
      "        (downsample): DownSamplingLayer(\r\n",
      "          0.018 M, 0.083% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "          (down_conv): ConvModule(\r\n",
      "            0.018 M, 0.083% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "            (conv): Conv2d(0.018 M, 0.083% Params, 0.302 GFLOPs, 0.124% FLOPs, 32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "            (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (conv1): ConvModule(\r\n",
      "          0.004 M, 0.018% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.004 M, 0.018% Params, 0.067 GFLOPs, 0.028% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv2): ConvModule(\r\n",
      "          0.004 M, 0.018% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.004 M, 0.018% Params, 0.067 GFLOPs, 0.028% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv3): ConvModule(\r\n",
      "          0.004 M, 0.018% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.004 M, 0.018% Params, 0.067 GFLOPs, 0.028% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (ffn): ConvFFN(\r\n",
      "          0.03 M, 0.132% Params, 0.488 GFLOPs, 0.201% FLOPs, \r\n",
      "          (ffn_layers): Sequential(\r\n",
      "            0.03 M, 0.132% Params, 0.488 GFLOPs, 0.201% FLOPs, \r\n",
      "            (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "            (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (3): ConvModule(\r\n",
      "              0.008 M, 0.038% Params, 0.138 GFLOPs, 0.057% FLOPs, \r\n",
      "              (conv): Conv2d(0.008 M, 0.038% Params, 0.138 GFLOPs, 0.057% FLOPs, 32, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (4): ConvModule(\r\n",
      "              0.013 M, 0.057% Params, 0.21 GFLOPs, 0.086% FLOPs, \r\n",
      "              (conv): Conv2d(0.013 M, 0.057% Params, 0.21 GFLOPs, 0.086% FLOPs, 256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\r\n",
      "            )\r\n",
      "            (5): GSiLU(\r\n",
      "              0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "              (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, output_size=1)\r\n",
      "            )\r\n",
      "            (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "            (7): ConvModule(\r\n",
      "              0.008 M, 0.037% Params, 0.135 GFLOPs, 0.055% FLOPs, \r\n",
      "              (conv): Conv2d(0.008 M, 0.037% Params, 0.135 GFLOPs, 0.055% FLOPs, 256, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (blocks): ModuleList(\r\n",
      "          (0): PKIBlock(\r\n",
      "            0.025 M, 0.112% Params, 0.411 GFLOPs, 0.169% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.015 M, 0.068% Params, 0.25 GFLOPs, 0.103% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.003 M, 0.013% Params, 0.048 GFLOPs, 0.020% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.0 M, 0.002% Params, 0.006 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.002% Params, 0.006 GFLOPs, 0.003% FLOPs, 32, 32, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.0 M, 0.002% Params, 0.006 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.002% Params, 0.006 GFLOPs, 0.003% FLOPs, 32, 32, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (1): PKIBlock(\r\n",
      "            0.025 M, 0.112% Params, 0.413 GFLOPs, 0.170% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.015 M, 0.069% Params, 0.252 GFLOPs, 0.104% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.003 M, 0.013% Params, 0.05 GFLOPs, 0.021% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.0 M, 0.002% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.002% Params, 0.007 GFLOPs, 0.003% FLOPs, 32, 32, kernel_size=(1, 13), stride=(1, 1), padding=(0, 6), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.0 M, 0.002% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.0 M, 0.002% Params, 0.007 GFLOPs, 0.003% FLOPs, 32, 32, kernel_size=(13, 1), stride=(1, 1), padding=(6, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (2): PKIBlock(\r\n",
      "            0.025 M, 0.113% Params, 0.415 GFLOPs, 0.171% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.015 M, 0.069% Params, 0.254 GFLOPs, 0.105% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.003 M, 0.014% Params, 0.052 GFLOPs, 0.021% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 32, 32, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 32, 32, kernel_size=(15, 1), stride=(1, 1), padding=(7, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (3): PKIBlock(\r\n",
      "            0.025 M, 0.113% Params, 0.417 GFLOPs, 0.172% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.070% Params, 0.256 GFLOPs, 0.106% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.003 M, 0.015% Params, 0.054 GFLOPs, 0.022% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.009 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.009 GFLOPs, 0.004% FLOPs, 32, 32, kernel_size=(1, 17), stride=(1, 1), padding=(0, 8), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.009 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.009 GFLOPs, 0.004% FLOPs, 32, 32, kernel_size=(17, 1), stride=(1, 1), padding=(8, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (4): PKIBlock(\r\n",
      "            0.025 M, 0.114% Params, 0.419 GFLOPs, 0.173% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.071% Params, 0.258 GFLOPs, 0.106% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.003 M, 0.015% Params, 0.056 GFLOPs, 0.023% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.01 GFLOPs, 0.004% FLOPs, 32, 32, kernel_size=(1, 19), stride=(1, 1), padding=(0, 9), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.01 GFLOPs, 0.004% FLOPs, 32, 32, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (5): PKIBlock(\r\n",
      "            0.026 M, 0.115% Params, 0.422 GFLOPs, 0.174% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.071% Params, 0.261 GFLOPs, 0.107% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.016% Params, 0.058 GFLOPs, 0.024% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.012 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.012 GFLOPs, 0.005% FLOPs, 32, 32, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.012 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.012 GFLOPs, 0.005% FLOPs, 32, 32, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (6): PKIBlock(\r\n",
      "            0.026 M, 0.115% Params, 0.424 GFLOPs, 0.174% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.072% Params, 0.263 GFLOPs, 0.108% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.016% Params, 0.06 GFLOPs, 0.025% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.013 GFLOPs, 0.005% FLOPs, 32, 32, kernel_size=(1, 23), stride=(1, 1), padding=(0, 11), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.013 GFLOPs, 0.005% FLOPs, 32, 32, kernel_size=(23, 1), stride=(1, 1), padding=(11, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (7): PKIBlock(\r\n",
      "            0.026 M, 0.116% Params, 0.426 GFLOPs, 0.175% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.072% Params, 0.265 GFLOPs, 0.109% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.017% Params, 0.062 GFLOPs, 0.026% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(1, 25), stride=(1, 1), padding=(0, 12), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(25, 1), stride=(1, 1), padding=(12, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (8): PKIBlock(\r\n",
      "            0.026 M, 0.116% Params, 0.428 GFLOPs, 0.176% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.073% Params, 0.267 GFLOPs, 0.110% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.027% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.015 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.015 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(1, 27), stride=(1, 1), padding=(0, 13), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.015 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.015 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(27, 1), stride=(1, 1), padding=(13, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (9): PKIBlock(\r\n",
      "            0.026 M, 0.117% Params, 0.43 GFLOPs, 0.177% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.016 M, 0.073% Params, 0.269 GFLOPs, 0.111% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.018% Params, 0.067 GFLOPs, 0.027% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.016 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.016 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(1, 29), stride=(1, 1), padding=(0, 14), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.016 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.016 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(29, 1), stride=(1, 1), padding=(14, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (10): PKIBlock(\r\n",
      "            0.026 M, 0.117% Params, 0.432 GFLOPs, 0.178% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.017 M, 0.074% Params, 0.271 GFLOPs, 0.112% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (11): PKIBlock(\r\n",
      "            0.026 M, 0.118% Params, 0.434 GFLOPs, 0.179% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.017 M, 0.075% Params, 0.273 GFLOPs, 0.112% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.019% Params, 0.071 GFLOPs, 0.029% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.018 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 33), stride=(1, 1), padding=(0, 16), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.018 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.018 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(33, 1), stride=(1, 1), padding=(16, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (12): PKIBlock(\r\n",
      "            0.026 M, 0.119% Params, 0.436 GFLOPs, 0.180% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.017 M, 0.075% Params, 0.275 GFLOPs, 0.113% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.004 M, 0.020% Params, 0.073 GFLOPs, 0.030% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.019 GFLOPs, 0.008% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.019 GFLOPs, 0.008% FLOPs, 32, 32, kernel_size=(1, 35), stride=(1, 1), padding=(0, 17), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.019 GFLOPs, 0.008% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.019 GFLOPs, 0.008% FLOPs, 32, 32, kernel_size=(35, 1), stride=(1, 1), padding=(17, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (13): PKIBlock(\r\n",
      "            0.027 M, 0.119% Params, 0.438 GFLOPs, 0.180% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.017 M, 0.076% Params, 0.277 GFLOPs, 0.114% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                (conv): Conv2d(0.0 M, 0.001% Params, 0.005 GFLOPs, 0.002% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.004% Params, 0.014 GFLOPs, 0.006% FLOPs, 32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.026 GFLOPs, 0.011% FLOPs, 32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.012% Params, 0.043 GFLOPs, 0.018% FLOPs, 32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=32)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.017% Params, 0.064 GFLOPs, 0.026% FLOPs, 32, 32, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=32)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.005 M, 0.020% Params, 0.075 GFLOPs, 0.031% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.02 GFLOPs, 0.008% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.02 GFLOPs, 0.008% FLOPs, 32, 32, kernel_size=(1, 37), stride=(1, 1), padding=(0, 18), groups=32)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.02 GFLOPs, 0.008% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.02 GFLOPs, 0.008% FLOPs, 32, 32, kernel_size=(37, 1), stride=(1, 1), padding=(18, 0), groups=32)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.005% Params, 0.017 GFLOPs, 0.007% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.01 M, 0.043% Params, 0.161 GFLOPs, 0.066% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, (32,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.069 GFLOPs, 0.028% FLOPs, 32, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.021 GFLOPs, 0.009% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.018% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (3): PKIStage(\r\n",
      "        1.919 M, 8.593% Params, 7.889 GFLOPs, 3.248% FLOPs, \r\n",
      "        (downsample): DownSamplingLayer(\r\n",
      "          0.074 M, 0.330% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "          (down_conv): ConvModule(\r\n",
      "            0.074 M, 0.330% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "            (conv): Conv2d(0.074 M, 0.330% Params, 0.302 GFLOPs, 0.124% FLOPs, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "            (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (conv1): ConvModule(\r\n",
      "          0.016 M, 0.073% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.016 M, 0.073% Params, 0.067 GFLOPs, 0.028% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv2): ConvModule(\r\n",
      "          0.016 M, 0.073% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.016 M, 0.073% Params, 0.067 GFLOPs, 0.028% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv3): ConvModule(\r\n",
      "          0.016 M, 0.073% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.016 M, 0.073% Params, 0.067 GFLOPs, 0.028% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (ffn): ConvFFN(\r\n",
      "          0.054 M, 0.243% Params, 0.223 GFLOPs, 0.092% FLOPs, \r\n",
      "          (ffn_layers): Sequential(\r\n",
      "            0.054 M, 0.243% Params, 0.223 GFLOPs, 0.092% FLOPs, \r\n",
      "            (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "            (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (3): ConvModule(\r\n",
      "              0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "              (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (4): ConvModule(\r\n",
      "              0.021 M, 0.094% Params, 0.086 GFLOPs, 0.035% FLOPs, \r\n",
      "              (conv): Conv2d(0.021 M, 0.094% Params, 0.086 GFLOPs, 0.035% FLOPs, 256, 256, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=256)\r\n",
      "            )\r\n",
      "            (5): GSiLU(\r\n",
      "              0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "              (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "            )\r\n",
      "            (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "            (7): ConvModule(\r\n",
      "              0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "              (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (blocks): ModuleList(\r\n",
      "          (0): PKIBlock(\r\n",
      "            0.076 M, 0.343% Params, 0.315 GFLOPs, 0.129% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.041 M, 0.182% Params, 0.167 GFLOPs, 0.069% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.01 M, 0.044% Params, 0.041 GFLOPs, 0.017% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (1): PKIBlock(\r\n",
      "            0.077 M, 0.344% Params, 0.316 GFLOPs, 0.130% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.041 M, 0.183% Params, 0.168 GFLOPs, 0.069% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.01 M, 0.045% Params, 0.042 GFLOPs, 0.017% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.004 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(1, 13), stride=(1, 1), padding=(0, 6), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.004% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.004% Params, 0.004 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(13, 1), stride=(1, 1), padding=(6, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (2): PKIBlock(\r\n",
      "            0.077 M, 0.345% Params, 0.317 GFLOPs, 0.130% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.041 M, 0.185% Params, 0.169 GFLOPs, 0.070% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.01 M, 0.046% Params, 0.043 GFLOPs, 0.018% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.004 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.004 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.004 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(15, 1), stride=(1, 1), padding=(7, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (3): PKIBlock(\r\n",
      "            0.077 M, 0.346% Params, 0.318 GFLOPs, 0.131% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.041 M, 0.186% Params, 0.17 GFLOPs, 0.070% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.011 M, 0.048% Params, 0.044 GFLOPs, 0.018% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.005 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(1, 17), stride=(1, 1), padding=(0, 8), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.005% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.005% Params, 0.005 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(17, 1), stride=(1, 1), padding=(8, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (4): PKIBlock(\r\n",
      "            0.078 M, 0.347% Params, 0.319 GFLOPs, 0.131% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.042 M, 0.187% Params, 0.171 GFLOPs, 0.070% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.011 M, 0.049% Params, 0.045 GFLOPs, 0.018% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.005 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(1, 19), stride=(1, 1), padding=(0, 9), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.005 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(19, 1), stride=(1, 1), padding=(9, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (5): PKIBlock(\r\n",
      "            0.078 M, 0.348% Params, 0.32 GFLOPs, 0.132% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.042 M, 0.188% Params, 0.172 GFLOPs, 0.071% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.011 M, 0.050% Params, 0.046 GFLOPs, 0.019% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.006 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.006 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(1, 21), stride=(1, 1), padding=(0, 10), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.001 M, 0.006% Params, 0.006 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.001 M, 0.006% Params, 0.006 GFLOPs, 0.002% FLOPs, 64, 64, kernel_size=(21, 1), stride=(1, 1), padding=(10, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (6): PKIBlock(\r\n",
      "            0.078 M, 0.349% Params, 0.321 GFLOPs, 0.132% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.042 M, 0.189% Params, 0.173 GFLOPs, 0.071% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.011 M, 0.051% Params, 0.047 GFLOPs, 0.019% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.007% Params, 0.006 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.007% Params, 0.006 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(1, 23), stride=(1, 1), padding=(0, 11), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.007% Params, 0.006 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.007% Params, 0.006 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(23, 1), stride=(1, 1), padding=(11, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (7): PKIBlock(\r\n",
      "            0.078 M, 0.351% Params, 0.322 GFLOPs, 0.133% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.042 M, 0.190% Params, 0.174 GFLOPs, 0.072% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.012 M, 0.052% Params, 0.048 GFLOPs, 0.020% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(1, 25), stride=(1, 1), padding=(0, 12), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(25, 1), stride=(1, 1), padding=(12, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (8): PKIBlock(\r\n",
      "            0.079 M, 0.352% Params, 0.323 GFLOPs, 0.133% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.043 M, 0.191% Params, 0.175 GFLOPs, 0.072% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.012 M, 0.053% Params, 0.049 GFLOPs, 0.020% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.008% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.008% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(1, 27), stride=(1, 1), padding=(0, 13), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.008% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.008% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(27, 1), stride=(1, 1), padding=(13, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (9): PKIBlock(\r\n",
      "            0.079 M, 0.353% Params, 0.324 GFLOPs, 0.133% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.043 M, 0.193% Params, 0.176 GFLOPs, 0.073% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.012 M, 0.054% Params, 0.05 GFLOPs, 0.021% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(1, 29), stride=(1, 1), padding=(0, 14), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(29, 1), stride=(1, 1), padding=(14, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (10): PKIBlock(\r\n",
      "            0.079 M, 0.354% Params, 0.325 GFLOPs, 0.134% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.043 M, 0.194% Params, 0.177 GFLOPs, 0.073% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.012 M, 0.056% Params, 0.051 GFLOPs, 0.021% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.009% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(31, 1), stride=(1, 1), padding=(15, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (11): PKIBlock(\r\n",
      "            0.079 M, 0.355% Params, 0.326 GFLOPs, 0.134% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.044 M, 0.195% Params, 0.179 GFLOPs, 0.073% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.013 M, 0.057% Params, 0.052 GFLOPs, 0.021% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(1, 33), stride=(1, 1), padding=(0, 16), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(33, 1), stride=(1, 1), padding=(16, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (12): PKIBlock(\r\n",
      "            0.08 M, 0.356% Params, 0.327 GFLOPs, 0.135% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.044 M, 0.196% Params, 0.18 GFLOPs, 0.074% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.013 M, 0.058% Params, 0.053 GFLOPs, 0.022% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(1, 35), stride=(1, 1), padding=(0, 17), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.010% Params, 0.009 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(35, 1), stride=(1, 1), padding=(17, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (13): PKIBlock(\r\n",
      "            0.08 M, 0.357% Params, 0.328 GFLOPs, 0.135% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.044 M, 0.197% Params, 0.181 GFLOPs, 0.074% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.013 M, 0.059% Params, 0.054 GFLOPs, 0.022% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(1, 37), stride=(1, 1), padding=(0, 18), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(37, 1), stride=(1, 1), padding=(18, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (14): PKIBlock(\r\n",
      "            0.08 M, 0.359% Params, 0.329 GFLOPs, 0.136% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.044 M, 0.198% Params, 0.182 GFLOPs, 0.075% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.013 M, 0.060% Params, 0.055 GFLOPs, 0.023% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(1, 39), stride=(1, 1), padding=(0, 19), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 64, 64, kernel_size=(39, 1), stride=(1, 1), padding=(19, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (15): PKIBlock(\r\n",
      "            0.08 M, 0.360% Params, 0.33 GFLOPs, 0.136% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.045 M, 0.199% Params, 0.183 GFLOPs, 0.075% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.014 M, 0.061% Params, 0.056 GFLOPs, 0.023% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.012% Params, 0.011 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.012% Params, 0.011 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(1, 41), stride=(1, 1), padding=(0, 20), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.012% Params, 0.011 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.012% Params, 0.011 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(41, 1), stride=(1, 1), padding=(20, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (16): PKIBlock(\r\n",
      "            0.081 M, 0.361% Params, 0.331 GFLOPs, 0.136% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.045 M, 0.201% Params, 0.184 GFLOPs, 0.076% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.014 M, 0.062% Params, 0.057 GFLOPs, 0.024% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(1, 43), stride=(1, 1), padding=(0, 21), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(43, 1), stride=(1, 1), padding=(21, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (17): PKIBlock(\r\n",
      "            0.081 M, 0.362% Params, 0.332 GFLOPs, 0.137% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.045 M, 0.202% Params, 0.185 GFLOPs, 0.076% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.014 M, 0.064% Params, 0.058 GFLOPs, 0.024% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(1, 45), stride=(1, 1), padding=(0, 22), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.013% Params, 0.012 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(45, 1), stride=(1, 1), padding=(22, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (18): PKIBlock(\r\n",
      "            0.081 M, 0.363% Params, 0.333 GFLOPs, 0.137% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.045 M, 0.203% Params, 0.186 GFLOPs, 0.077% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.014 M, 0.065% Params, 0.06 GFLOPs, 0.024% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(1, 47), stride=(1, 1), padding=(0, 23), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(47, 1), stride=(1, 1), padding=(23, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (19): PKIBlock(\r\n",
      "            0.081 M, 0.364% Params, 0.334 GFLOPs, 0.138% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.046 M, 0.204% Params, 0.187 GFLOPs, 0.077% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.015 M, 0.066% Params, 0.061 GFLOPs, 0.025% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(1, 49), stride=(1, 1), padding=(0, 24), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(49, 1), stride=(1, 1), padding=(24, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (20): PKIBlock(\r\n",
      "            0.082 M, 0.365% Params, 0.336 GFLOPs, 0.138% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.046 M, 0.205% Params, 0.188 GFLOPs, 0.077% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.015 M, 0.067% Params, 0.062 GFLOPs, 0.025% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, 64, 64, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, 64, 64, kernel_size=(51, 1), stride=(1, 1), padding=(25, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (21): PKIBlock(\r\n",
      "            0.082 M, 0.367% Params, 0.337 GFLOPs, 0.139% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.046 M, 0.206% Params, 0.189 GFLOPs, 0.078% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.003% Params, 0.003 GFLOPs, 0.001% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.002 M, 0.007% Params, 0.007 GFLOPs, 0.003% FLOPs, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.014% Params, 0.013 GFLOPs, 0.005% FLOPs, 64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, \r\n",
      "                (conv): Conv2d(0.005 M, 0.024% Params, 0.021 GFLOPs, 0.009% FLOPs, 64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, \r\n",
      "                (conv): Conv2d(0.008 M, 0.035% Params, 0.032 GFLOPs, 0.013% FLOPs, 64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=64)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.015 M, 0.068% Params, 0.063 GFLOPs, 0.026% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, 64, 64, kernel_size=(1, 53), stride=(1, 1), padding=(0, 26), groups=64)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.015% Params, 0.014 GFLOPs, 0.006% FLOPs, 64, 64, kernel_size=(53, 1), stride=(1, 1), padding=(26, 0), groups=64)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.004 M, 0.019% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.004 M, 0.018% Params, 0.017 GFLOPs, 0.007% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.036 M, 0.160% Params, 0.148 GFLOPs, 0.061% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, (64,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.075% Params, 0.068 GFLOPs, 0.028% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, \r\n",
      "                  (conv): Conv2d(0.003 M, 0.011% Params, 0.01 GFLOPs, 0.004% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.016 M, 0.074% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (4): PKIStage(\r\n",
      "        1.727 M, 7.734% Params, 1.771 GFLOPs, 0.729% FLOPs, \r\n",
      "        (downsample): DownSamplingLayer(\r\n",
      "          0.295 M, 1.321% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "          (down_conv): ConvModule(\r\n",
      "            0.295 M, 1.321% Params, 0.302 GFLOPs, 0.124% FLOPs, \r\n",
      "            (conv): Conv2d(0.295 M, 1.321% Params, 0.302 GFLOPs, 0.124% FLOPs, 128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "            (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (conv1): ConvModule(\r\n",
      "          0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv2): ConvModule(\r\n",
      "          0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (conv3): ConvModule(\r\n",
      "          0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "          (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "          (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "        )\r\n",
      "        (ffn): ConvFFN(\r\n",
      "          0.194 M, 0.871% Params, 0.2 GFLOPs, 0.082% FLOPs, \r\n",
      "          (ffn_layers): Sequential(\r\n",
      "            0.194 M, 0.871% Params, 0.2 GFLOPs, 0.082% FLOPs, \r\n",
      "            (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (1): LayerNorm(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.000% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\r\n",
      "            (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "            (3): ConvModule(\r\n",
      "              0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "              (conv): Conv2d(0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (4): ConvModule(\r\n",
      "              0.062 M, 0.280% Params, 0.064 GFLOPs, 0.026% FLOPs, \r\n",
      "              (conv): Conv2d(0.062 M, 0.280% Params, 0.064 GFLOPs, 0.026% FLOPs, 512, 512, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=512)\r\n",
      "            )\r\n",
      "            (5): GSiLU(\r\n",
      "              0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "              (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "            )\r\n",
      "            (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "            (7): ConvModule(\r\n",
      "              0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "              (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "            )\r\n",
      "            (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (blocks): ModuleList(\r\n",
      "          (0): PKIBlock(\r\n",
      "            0.259 M, 1.162% Params, 0.266 GFLOPs, 0.110% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.122 M, 0.548% Params, 0.125 GFLOPs, 0.052% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, 128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, 128, 128, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=128)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.036 M, 0.162% Params, 0.037 GFLOPs, 0.015% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.007% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.007% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(1, 11), stride=(1, 1), padding=(0, 5), groups=128)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.007% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.007% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0), groups=128)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.000% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (1): PKIBlock(\r\n",
      "            0.26 M, 1.164% Params, 0.267 GFLOPs, 0.110% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.123 M, 0.550% Params, 0.126 GFLOPs, 0.052% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, 128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, 128, 128, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=128)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.037 M, 0.164% Params, 0.038 GFLOPs, 0.015% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.008% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.008% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(1, 13), stride=(1, 1), padding=(0, 6), groups=128)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.008% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.008% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(13, 1), stride=(1, 1), padding=(6, 0), groups=128)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.000% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (2): PKIBlock(\r\n",
      "            0.26 M, 1.167% Params, 0.267 GFLOPs, 0.110% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.123 M, 0.553% Params, 0.126 GFLOPs, 0.052% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, 128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, 128, 128, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=128)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.037 M, 0.166% Params, 0.038 GFLOPs, 0.016% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.009% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.009% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), groups=128)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.009% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.009% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(15, 1), stride=(1, 1), padding=(7, 0), groups=128)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.000% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "          (3): PKIBlock(\r\n",
      "            0.261 M, 1.169% Params, 0.268 GFLOPs, 0.110% FLOPs, \r\n",
      "            (norm1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (norm2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "            (block): InceptionBottleneck(\r\n",
      "              0.124 M, 0.555% Params, 0.127 GFLOPs, 0.052% FLOPs, \r\n",
      "              (pre_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (dw_conv): ConvModule(\r\n",
      "                0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.001 M, 0.006% Params, 0.001 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv1): ConvModule(\r\n",
      "                0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, \r\n",
      "                (conv): Conv2d(0.003 M, 0.015% Params, 0.003 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv2): ConvModule(\r\n",
      "                0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, \r\n",
      "                (conv): Conv2d(0.006 M, 0.029% Params, 0.007 GFLOPs, 0.003% FLOPs, 128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv3): ConvModule(\r\n",
      "                0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, \r\n",
      "                (conv): Conv2d(0.01 M, 0.047% Params, 0.011 GFLOPs, 0.004% FLOPs, 128, 128, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=128)\r\n",
      "              )\r\n",
      "              (dw_conv4): ConvModule(\r\n",
      "                0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.070% Params, 0.016 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5), groups=128)\r\n",
      "              )\r\n",
      "              (pw_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "              (caa_factor): CAA(\r\n",
      "                0.038 M, 0.169% Params, 0.039 GFLOPs, 0.016% FLOPs, \r\n",
      "                (avg_pool): AvgPool2d(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, kernel_size=7, stride=1, padding=3)\r\n",
      "                (conv1): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (h_conv): ConvModule(\r\n",
      "                  0.002 M, 0.010% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.010% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(1, 17), stride=(1, 1), padding=(0, 8), groups=128)\r\n",
      "                )\r\n",
      "                (v_conv): ConvModule(\r\n",
      "                  0.002 M, 0.010% Params, 0.002 GFLOPs, 0.001% FLOPs, \r\n",
      "                  (conv): Conv2d(0.002 M, 0.010% Params, 0.002 GFLOPs, 0.001% FLOPs, 128, 128, kernel_size=(17, 1), stride=(1, 1), padding=(8, 0), groups=128)\r\n",
      "                )\r\n",
      "                (conv2): ConvModule(\r\n",
      "                  0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                  (conv): Conv2d(0.017 M, 0.074% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (act): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "              )\r\n",
      "              (post_conv): ConvModule(\r\n",
      "                0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, \r\n",
      "                (conv): Conv2d(0.016 M, 0.073% Params, 0.017 GFLOPs, 0.007% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "                (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "                (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (ffn): ConvFFN(\r\n",
      "              0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "              (ffn_layers): Sequential(\r\n",
      "                0.137 M, 0.614% Params, 0.141 GFLOPs, 0.058% FLOPs, \r\n",
      "                (0): BCHW2BHWC(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (1): LayerNorm(0.0 M, 0.001% Params, 0.0 GFLOPs, 0.000% FLOPs, (128,), eps=1e-05, elementwise_affine=True)\r\n",
      "                (2): BHWC2BCHW(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "                (3): ConvModule(\r\n",
      "                  0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.296% Params, 0.068 GFLOPs, 0.028% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (4): ConvModule(\r\n",
      "                  0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, \r\n",
      "                  (conv): Conv2d(0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\r\n",
      "                )\r\n",
      "                (5): GSiLU(\r\n",
      "                  0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, \r\n",
      "                  (adpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.000% FLOPs, output_size=1)\r\n",
      "                )\r\n",
      "                (6): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "                (7): ConvModule(\r\n",
      "                  0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "                  (conv): Conv2d(0.066 M, 0.294% Params, 0.067 GFLOPs, 0.028% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "                )\r\n",
      "                (8): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.1, inplace=False)\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (drop_path): DropPath(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (stem): Stem(\r\n",
      "      0.005 M, 0.023% Params, 1.321 GFLOPs, 0.544% FLOPs, \r\n",
      "      (down_conv): ConvModule(\r\n",
      "        0.0 M, 0.002% Params, 0.113 GFLOPs, 0.047% FLOPs, \r\n",
      "        (conv): Conv2d(0.0 M, 0.002% Params, 0.113 GFLOPs, 0.047% FLOPs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "        (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "      )\r\n",
      "      (conv1): ConvModule(\r\n",
      "        0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, \r\n",
      "        (conv): Conv2d(0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "        (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "      )\r\n",
      "      (conv2): ConvModule(\r\n",
      "        0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, \r\n",
      "        (conv): Conv2d(0.002 M, 0.010% Params, 0.604 GFLOPs, 0.249% FLOPs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "        (bn): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\r\n",
      "        (activate): SiLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}\r\n",
      "  (neck): NIRNet(\r\n",
      "    3.671 M, 16.443% Params, 155.659 GFLOPs, 64.080% FLOPs, \r\n",
      "    (lateral_convs): ModuleList(\r\n",
      "      (0): ConvModule(\r\n",
      "        0.008 M, 0.038% Params, 0.554 GFLOPs, 0.228% FLOPs, \r\n",
      "        (conv): Conv2d(0.008 M, 0.038% Params, 0.554 GFLOPs, 0.228% FLOPs, 32, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      )\r\n",
      "      (1): ConvModule(\r\n",
      "        0.017 M, 0.075% Params, 0.273 GFLOPs, 0.112% FLOPs, \r\n",
      "        (conv): Conv2d(0.017 M, 0.075% Params, 0.273 GFLOPs, 0.112% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      )\r\n",
      "      (2): ConvModule(\r\n",
      "        0.033 M, 0.148% Params, 0.135 GFLOPs, 0.056% FLOPs, \r\n",
      "        (conv): Conv2d(0.033 M, 0.148% Params, 0.135 GFLOPs, 0.056% FLOPs, 128, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      )\r\n",
      "      (3): ConvModule(\r\n",
      "        0.066 M, 0.295% Params, 0.067 GFLOPs, 0.028% FLOPs, \r\n",
      "        (conv): Conv2d(0.066 M, 0.295% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (fpn_convs): ModuleList(\r\n",
      "      (0): ConvModule(\r\n",
      "        0.59 M, 2.643% Params, 38.671 GFLOPs, 15.920% FLOPs, \r\n",
      "        (conv): Conv2d(0.59 M, 2.643% Params, 38.671 GFLOPs, 15.920% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      )\r\n",
      "      (1): ConvModule(\r\n",
      "        0.59 M, 2.643% Params, 9.668 GFLOPs, 3.980% FLOPs, \r\n",
      "        (conv): Conv2d(0.59 M, 2.643% Params, 9.668 GFLOPs, 3.980% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      )\r\n",
      "      (2): ConvModule(\r\n",
      "        0.59 M, 2.643% Params, 2.417 GFLOPs, 0.995% FLOPs, \r\n",
      "        (conv): Conv2d(0.59 M, 2.643% Params, 2.417 GFLOPs, 0.995% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      )\r\n",
      "      (3): ConvModule(\r\n",
      "        0.59 M, 2.643% Params, 0.604 GFLOPs, 0.249% FLOPs, \r\n",
      "        (conv): Conv2d(0.59 M, 2.643% Params, 0.604 GFLOPs, 0.249% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (encoder_conv): ConvModule(\r\n",
      "      0.003 M, 0.011% Params, 0.223 GFLOPs, 0.092% FLOPs, \r\n",
      "      (conv): Conv2d(0.003 M, 0.011% Params, 0.223 GFLOPs, 0.092% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\r\n",
      "    )\r\n",
      "    (fusion_conv): ConvModule(\r\n",
      "      0.59 M, 2.643% Params, 51.512 GFLOPs, 21.206% FLOPs, \r\n",
      "      (conv): Conv2d(0.59 M, 2.643% Params, 51.512 GFLOPs, 21.206% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    )\r\n",
      "    (excite_conv): ConvModule(\r\n",
      "      0.59 M, 2.643% Params, 51.512 GFLOPs, 21.206% FLOPs, \r\n",
      "      (conv): Conv2d(0.59 M, 2.643% Params, 51.512 GFLOPs, 21.206% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    )\r\n",
      "    (sigmoid): Sigmoid(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "    (fcm_ip_channel_fc): Linear(0.0 M, 0.001% Params, 0.011 GFLOPs, 0.005% FLOPs, in_features=128, out_features=1, bias=True)\r\n",
      "    (fcm_ip_channel_atten): MultiheadAttention(\r\n",
      "      0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "      (attn): MultiheadAttention(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, in_features=16, out_features=16, bias=True)\r\n",
      "      )\r\n",
      "      (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "      (dropout_layer): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "    )\r\n",
      "    (fcm_sp_channel_atten): MultiheadAttention(\r\n",
      "      0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "      (attn): MultiheadAttention(\r\n",
      "        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, in_features=16, out_features=16, bias=True)\r\n",
      "      )\r\n",
      "      (proj_drop): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "      (dropout_layer): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.0, inplace=False)\r\n",
      "    )\r\n",
      "    (fcm_sp_channel_fc): Linear(0.0 M, 0.001% Params, 0.011 GFLOPs, 0.005% FLOPs, in_features=128, out_features=1, bias=True)\r\n",
      "    (group_attn_convs): ModuleList(\r\n",
      "      (0-3): 4 x ConvModule(\r\n",
      "        0.001 M, 0.005% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "        (conv): Conv2d(0.001 M, 0.005% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, 32, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\r\n",
      "  (rpn_head): OrientedRPNHead(\r\n",
      "    0.595 M, 2.667% Params, 51.983 GFLOPs, 21.400% FLOPs, \r\n",
      "    (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\r\n",
      "    (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "    (rpn_conv): Conv2d(0.59 M, 2.643% Params, 51.512 GFLOPs, 21.206% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (rpn_cls): Conv2d(0.001 M, 0.003% Params, 0.067 GFLOPs, 0.028% FLOPs, 256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    (rpn_reg): Conv2d(0.005 M, 0.021% Params, 0.404 GFLOPs, 0.166% FLOPs, 256, 18, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "  )\r\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\r\n",
      "  (roi_head): OrientedStandardRoIHead(\r\n",
      "    13.903 M, 62.264% Params, 13.903 GFLOPs, 5.723% FLOPs, \r\n",
      "    (bbox_roi_extractor): RotatedSingleRoIExtractor(\r\n",
      "      0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \r\n",
      "      (roi_layers): ModuleList(\r\n",
      "        (0): RoIAlignRotated(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True, clockwise=True)\r\n",
      "        (1): RoIAlignRotated(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True, clockwise=True)\r\n",
      "        (2): RoIAlignRotated(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True, clockwise=True)\r\n",
      "        (3): RoIAlignRotated(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True, clockwise=True)\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (bbox_head): RotatedShared2FCBBoxHead(\r\n",
      "      13.903 M, 62.264% Params, 13.903 GFLOPs, 5.723% FLOPs, \r\n",
      "      (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\r\n",
      "      (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\r\n",
      "      (fc_cls): Linear(0.002 M, 0.009% Params, 0.002 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=2, bias=True)\r\n",
      "      (fc_reg): Linear(0.005 M, 0.023% Params, 0.005 GFLOPs, 0.002% FLOPs, in_features=1024, out_features=5, bias=True)\r\n",
      "      (shared_convs): ModuleList()\r\n",
      "      (shared_fcs): ModuleList(\r\n",
      "        (0): Linear(12.846 M, 57.531% Params, 12.845 GFLOPs, 5.288% FLOPs, in_features=12544, out_features=1024, bias=True)\r\n",
      "        (1): Linear(1.05 M, 4.701% Params, 1.049 GFLOPs, 0.432% FLOPs, in_features=1024, out_features=1024, bias=True)\r\n",
      "      )\r\n",
      "      (cls_convs): ModuleList()\r\n",
      "      (cls_fcs): ModuleList()\r\n",
      "      (reg_convs): ModuleList()\r\n",
      "      (reg_fcs): ModuleList()\r\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, inplace=True)\r\n",
      "    )\r\n",
      "    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\r\n",
      "  )\r\n",
      ")\r\n",
      "==============================\r\n",
      "Input shape: (3, 1024, 1024)\r\n",
      "Flops: 242.91 GFLOPs\r\n",
      "Params: 22.33 M\r\n",
      "==============================\r\n",
      "!!!Please be cautious if you use the results in papers. You may need to check if all ops are supported and verify that the flops computation is correct.\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mmrotate\n",
    "!python tools/analysis_tools/get_flops.py configs/firnet/firnet_r50_fpn_1x_sccos.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b201dc79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T14:58:36.354215Z",
     "iopub.status.busy": "2025-09-16T14:58:36.353415Z",
     "iopub.status.idle": "2025-09-16T23:21:59.610902Z",
     "shell.execute_reply": "2025-09-16T23:21:59.610017Z"
    },
    "papermill": {
     "duration": 30203.309737,
     "end_time": "2025-09-16T23:21:59.612224",
     "exception": false,
     "start_time": "2025-09-16T14:58:36.302487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "2025-09-16 14:58:42,528 - mmrotate - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Tesla P100-PCIE-16GB\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Cuda compilation tools, release 12.5, V12.5.82\r\n",
      "GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n",
      "PyTorch: 2.0.1+cu118\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.2-Product Build 20250620 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.8\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.7\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.15.2+cu118\r\n",
      "OpenCV: 4.11.0\r\n",
      "MMCV: 1.7.2\r\n",
      "MMCV Compiler: GCC 9.3\r\n",
      "MMCV CUDA Compiler: 11.8\r\n",
      "MMRotate: 0.3.4+7250f04\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2025-09-16 14:58:42,661 - mmrotate - INFO - Distributed training: False\r\n",
      "2025-09-16 14:58:42,792 - mmrotate - INFO - Config:\r\n",
      "log_config = dict(\r\n",
      "    interval=100,\r\n",
      "    hooks=[\r\n",
      "        dict(type='TextLoggerHook'),\r\n",
      "        dict(\r\n",
      "            type='WandbLoggerHook',\r\n",
      "            init_kwargs=dict(project='FREANet_training', name='FREANet_PKI'),\r\n",
      "            interval=100)\r\n",
      "    ])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = None\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "evaluation = dict(interval=1, metric='mAP', save_best='mAP')\r\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\r\n",
      "lr_config = dict(\r\n",
      "    policy='step',\r\n",
      "    warmup='linear',\r\n",
      "    warmup_iters=1000,\r\n",
      "    warmup_ratio=0.3333333333333333,\r\n",
      "    step=[8, 11])\r\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=10)\r\n",
      "checkpoint_config = dict(interval=1)\r\n",
      "dataset_type = 'DOTADataset'\r\n",
      "data_root = '/kaggle/input/sccos-dota/sccos_dota/'\r\n",
      "img_norm_cfg = dict(\r\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "    dict(type='RRandomFlip', flip_ratio=0.5),\r\n",
      "    dict(\r\n",
      "        type='Normalize',\r\n",
      "        mean=[123.675, 116.28, 103.53],\r\n",
      "        std=[58.395, 57.12, 57.375],\r\n",
      "        to_rgb=True),\r\n",
      "    dict(type='Pad', size_divisor=32),\r\n",
      "    dict(type='DefaultFormatBundle'),\r\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='MultiScaleFlipAug',\r\n",
      "        img_scale=(1024, 1024),\r\n",
      "        flip=False,\r\n",
      "        transforms=[\r\n",
      "            dict(type='RResize'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img'])\r\n",
      "        ])\r\n",
      "]\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=2,\r\n",
      "    workers_per_gpu=4,\r\n",
      "    train=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/input/sccos-dota/sccos_dota/train/labels/',\r\n",
      "        img_prefix='/kaggle/input/sccos-dota/sccos_dota/train/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "            dict(type='RRandomFlip', flip_ratio=0.5),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    val=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/input/sccos-dota/sccos_dota/val/labels/',\r\n",
      "        img_prefix='/kaggle/input/sccos-dota/sccos_dota/val/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    test=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/input/sccos-dota/sccos_dota/test/labels/',\r\n",
      "        img_prefix='/kaggle/input/sccos-dota/sccos_dota/test/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )))\r\n",
      "angle_version = 'le135'\r\n",
      "model = dict(\r\n",
      "    type='OrientedRCNN',\r\n",
      "    backbone=dict(\r\n",
      "        type='PKINet',\r\n",
      "        arch='T',\r\n",
      "        drop_path_rate=0.1,\r\n",
      "        out_indices=(1, 2, 3, 4),\r\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\r\n",
      "        act_cfg=dict(type='SiLU')),\r\n",
      "    neck=dict(\r\n",
      "        type='NIRNet',\r\n",
      "        in_channels=[32, 64, 128, 256],\r\n",
      "        out_channels=256,\r\n",
      "        num_outs=5),\r\n",
      "    rpn_head=dict(\r\n",
      "        type='OrientedRPNHead',\r\n",
      "        in_channels=256,\r\n",
      "        feat_channels=256,\r\n",
      "        version='le135',\r\n",
      "        anchor_generator=dict(\r\n",
      "            type='AnchorGenerator',\r\n",
      "            scales=[8],\r\n",
      "            ratios=[0.5, 1.0, 2.0],\r\n",
      "            strides=[4, 8, 16, 32, 64]),\r\n",
      "        bbox_coder=dict(\r\n",
      "            type='MidpointOffsetCoder',\r\n",
      "            angle_range='le135',\r\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]),\r\n",
      "        loss_cls=dict(\r\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\r\n",
      "        loss_bbox=dict(\r\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\r\n",
      "    roi_head=dict(\r\n",
      "        type='OrientedStandardRoIHead',\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            type='RotatedSingleRoIExtractor',\r\n",
      "            roi_layer=dict(\r\n",
      "                type='RoIAlignRotated',\r\n",
      "                out_size=7,\r\n",
      "                sample_num=2,\r\n",
      "                clockwise=True),\r\n",
      "            out_channels=256,\r\n",
      "            featmap_strides=[4, 8, 16, 32]),\r\n",
      "        bbox_head=dict(\r\n",
      "            type='RotatedShared2FCBBoxHead',\r\n",
      "            in_channels=256,\r\n",
      "            fc_out_channels=1024,\r\n",
      "            roi_feat_size=7,\r\n",
      "            num_classes=1,\r\n",
      "            bbox_coder=dict(\r\n",
      "                type='DeltaXYWHAOBBoxCoder',\r\n",
      "                angle_range='le135',\r\n",
      "                norm_factor=None,\r\n",
      "                edge_swap=True,\r\n",
      "                proj_xy=True,\r\n",
      "                target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\r\n",
      "                target_stds=(0.1, 0.1, 0.2, 0.2, 0.1)),\r\n",
      "            reg_class_agnostic=True,\r\n",
      "            loss_cls=dict(\r\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\r\n",
      "            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))),\r\n",
      "    train_cfg=dict(\r\n",
      "        rpn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                match_low_quality=True,\r\n",
      "                ignore_iof_thr=-1),\r\n",
      "            sampler=dict(\r\n",
      "                type='RandomSampler',\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                add_gt_as_proposals=False),\r\n",
      "            allowed_border=0,\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            max_per_img=2000,\r\n",
      "            nms=dict(type='nms', iou_threshold=0.8),\r\n",
      "            min_bbox_size=0),\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                match_low_quality=False,\r\n",
      "                iou_calculator=dict(type='RBboxOverlaps2D'),\r\n",
      "                ignore_iof_thr=-1),\r\n",
      "            sampler=dict(\r\n",
      "                type='RRandomSampler',\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                add_gt_as_proposals=True),\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False)),\r\n",
      "    test_cfg=dict(\r\n",
      "        rpn=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            max_per_img=2000,\r\n",
      "            nms=dict(type='nms', iou_threshold=0.8),\r\n",
      "            min_bbox_size=0),\r\n",
      "        rcnn=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            score_thr=0.05,\r\n",
      "            nms=dict(iou_thr=0.1),\r\n",
      "            max_per_img=2000)))\r\n",
      "classes = ('ship', )\r\n",
      "work_dir = '/kaggle/working/runs/FIRNet_train'\r\n",
      "auto_resume = False\r\n",
      "gpu_ids = range(0, 1)\r\n",
      "\r\n",
      "2025-09-16 14:58:42,793 - mmrotate - INFO - Set random seed to 1048869419, deterministic: False\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "2025-09-16 14:58:43,585 - mmcv - INFO - initialize NIRNet with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\r\n",
      "2025-09-16 14:58:43,621 - mmcv - INFO - initialize OrientedRPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\r\n",
      "2025-09-16 14:58:43,626 - mmcv - INFO - initialize RotatedShared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\r\n",
      "2025-09-16 14:58:43,833 - mmcv - INFO - \r\n",
      "backbone.stages.0.down_conv.conv.weight - torch.Size([16, 3, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,833 - mmcv - INFO - \r\n",
      "backbone.stages.0.down_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,833 - mmcv - INFO - \r\n",
      "backbone.stages.0.down_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,833 - mmcv - INFO - \r\n",
      "backbone.stages.0.conv1.conv.weight - torch.Size([16, 16, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.0.conv1.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.0.conv1.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.0.conv2.conv.weight - torch.Size([16, 16, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.0.conv2.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.0.conv2.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.downsample.down_conv.conv.weight - torch.Size([32, 16, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.downsample.down_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.downsample.down_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv1.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv1.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,834 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv2.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv2.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv3.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv3.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.conv3.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.3.conv.weight - torch.Size([128, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,835 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.7.conv.weight - torch.Size([16, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.ffn.ffn_layers.7.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.gamma1 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.gamma2 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.norm1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.norm1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.norm2.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.norm2.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.pre_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.pre_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.pre_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv.conv.weight - torch.Size([16, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,836 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv1.conv.weight - torch.Size([16, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv2.conv.weight - torch.Size([16, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv3.conv.weight - torch.Size([16, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv3.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv4.conv.weight - torch.Size([16, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.dw_conv4.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.pw_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.pw_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.pw_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.conv1.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,837 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.h_conv.conv.weight - torch.Size([16, 1, 1, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.h_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.v_conv.conv.weight - torch.Size([16, 1, 11, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.v_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.conv2.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.caa_factor.conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.post_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.post_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.block.post_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,838 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.3.conv.weight - torch.Size([64, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.4.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.7.conv.weight - torch.Size([16, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.0.ffn.ffn_layers.7.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.gamma1 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.gamma2 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.norm1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.norm1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.norm2.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.norm2.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.pre_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,839 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.pre_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.pre_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv.conv.weight - torch.Size([16, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv1.conv.weight - torch.Size([16, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv2.conv.weight - torch.Size([16, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv3.conv.weight - torch.Size([16, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv3.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv4.conv.weight - torch.Size([16, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.dw_conv4.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.pw_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.pw_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,840 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.pw_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.conv1.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.h_conv.conv.weight - torch.Size([16, 1, 1, 13]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.h_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.v_conv.conv.weight - torch.Size([16, 1, 13, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.v_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.conv2.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.caa_factor.conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.post_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.post_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.block.post_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,841 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.3.conv.weight - torch.Size([64, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.4.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.7.conv.weight - torch.Size([16, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.1.ffn.ffn_layers.7.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.gamma1 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.gamma2 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.norm1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.norm1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.norm2.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.norm2.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,842 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.pre_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.pre_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.pre_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv.conv.weight - torch.Size([16, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv1.conv.weight - torch.Size([16, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv2.conv.weight - torch.Size([16, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv3.conv.weight - torch.Size([16, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv3.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv4.conv.weight - torch.Size([16, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.dw_conv4.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,843 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.pw_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.pw_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.pw_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.conv1.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.h_conv.conv.weight - torch.Size([16, 1, 1, 15]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.h_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.v_conv.conv.weight - torch.Size([16, 1, 15, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.v_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.conv2.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.caa_factor.conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.post_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,844 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.post_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.block.post_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.3.conv.weight - torch.Size([64, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.4.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.7.conv.weight - torch.Size([16, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.2.ffn.ffn_layers.7.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.gamma1 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.gamma2 - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.norm1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.norm1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,845 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.norm2.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.norm2.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.pre_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.pre_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.pre_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv.conv.weight - torch.Size([16, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv1.conv.weight - torch.Size([16, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv2.conv.weight - torch.Size([16, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv3.conv.weight - torch.Size([16, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,846 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv3.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv4.conv.weight - torch.Size([16, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.dw_conv4.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.pw_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.pw_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.pw_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.conv1.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.conv1.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.h_conv.conv.weight - torch.Size([16, 1, 1, 17]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.h_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.v_conv.conv.weight - torch.Size([16, 1, 17, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.v_conv.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.conv2.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,847 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.caa_factor.conv2.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.post_conv.conv.weight - torch.Size([16, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.post_conv.bn.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.block.post_conv.bn.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.1.weight - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.1.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.3.conv.weight - torch.Size([64, 16, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.4.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.7.conv.weight - torch.Size([16, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.1.blocks.3.ffn.ffn_layers.7.conv.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,848 - mmcv - INFO - \r\n",
      "backbone.stages.2.downsample.down_conv.conv.weight - torch.Size([64, 32, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.downsample.down_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.downsample.down_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv1.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv1.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv2.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv2.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv3.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv3.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.conv3.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,849 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.3.conv.weight - torch.Size([256, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.7.conv.weight - torch.Size([32, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,850 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,851 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 11, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,852 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.0.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,853 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,854 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 13]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,855 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 13, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,856 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.1.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,857 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,858 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 15]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 15, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,859 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.2.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,860 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,861 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 17]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 17, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,862 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,863 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.3.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,864 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 19]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,865 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 19, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,866 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.4.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,867 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 21]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,868 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 21, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,869 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.5.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,870 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,871 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 23]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 23, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,872 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.6.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,873 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,874 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 25]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 25, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,875 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.7.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,876 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,877 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 27]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 27, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,878 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.8.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,879 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,880 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 29]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 29, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,881 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.9.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,882 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,883 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 31]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 31, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,884 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,885 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.10.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,886 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 33]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,887 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 33, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,888 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.11.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,889 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,890 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 35]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 35, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,891 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.12.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.gamma1 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.gamma2 - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.norm1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.norm1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.norm2.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.norm2.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.pre_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.pre_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,892 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.pre_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv.conv.weight - torch.Size([32, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv1.conv.weight - torch.Size([32, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv2.conv.weight - torch.Size([32, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv3.conv.weight - torch.Size([32, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv4.conv.weight - torch.Size([32, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.dw_conv4.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.pw_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.pw_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.pw_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,893 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.conv1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.h_conv.conv.weight - torch.Size([32, 1, 1, 37]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.h_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.v_conv.conv.weight - torch.Size([32, 1, 37, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.v_conv.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.conv2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.caa_factor.conv2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.post_conv.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.post_conv.bn.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.block.post_conv.bn.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.1.weight - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.1.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,894 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.3.conv.weight - torch.Size([128, 32, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.4.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.7.conv.weight - torch.Size([32, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.2.blocks.13.ffn.ffn_layers.7.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.downsample.down_conv.conv.weight - torch.Size([128, 64, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.downsample.down_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.downsample.down_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv1.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv1.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv2.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,895 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv2.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv2.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv3.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv3.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.conv3.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,896 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,897 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,898 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 11, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,899 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.0.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,900 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,901 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 13]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 13, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,902 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.1.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,903 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,904 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 15]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 15, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,905 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.2.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,906 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,907 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 17]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 17, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,908 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.3.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,909 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,910 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 19]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 19, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,911 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.4.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,912 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,913 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 21]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 21, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,914 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,915 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.5.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,916 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 23]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,917 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 23, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,918 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.6.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,919 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,920 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 25]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 25, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,921 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.7.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,922 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,923 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 27]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 27, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,924 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.8.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,925 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,926 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 29]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 29, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,927 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.9.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,928 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,929 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 31]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 31, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,930 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.10.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,931 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,932 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 33]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 33, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,933 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,934 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.11.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,935 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 35]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,936 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 35, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,937 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.12.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,938 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,939 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 37]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 37, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,940 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.13.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,941 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,942 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 39]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 39, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,943 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.14.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,944 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,945 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 41]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 41, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,946 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.15.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,947 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,948 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 43]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 43, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,949 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.16.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,950 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,951 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 45]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 45, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,952 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.17.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,953 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,954 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 47]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,955 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 47, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,956 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.18.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,957 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,958 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 49]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 49, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,959 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.19.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,960 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,961 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 51]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 51, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,962 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.20.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,963 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.gamma1 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.gamma2 - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.norm1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.norm1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.norm2.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.norm2.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.pre_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.pre_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.pre_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv.conv.weight - torch.Size([64, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,964 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv1.conv.weight - torch.Size([64, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv2.conv.weight - torch.Size([64, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv3.conv.weight - torch.Size([64, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv3.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv4.conv.weight - torch.Size([64, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.dw_conv4.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.pw_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.pw_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.pw_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,965 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.conv1.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.h_conv.conv.weight - torch.Size([64, 1, 1, 53]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.h_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.v_conv.conv.weight - torch.Size([64, 1, 53, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.v_conv.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.conv2.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.caa_factor.conv2.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.post_conv.conv.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.post_conv.bn.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.block.post_conv.bn.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.1.weight - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,966 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.1.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.3.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.4.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.7.conv.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.3.blocks.21.ffn.ffn_layers.7.conv.bias - torch.Size([64]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.4.downsample.down_conv.conv.weight - torch.Size([256, 128, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.4.downsample.down_conv.bn.weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.4.downsample.down_conv.bn.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,967 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv1.conv.weight - torch.Size([256, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv1.bn.weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv1.bn.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv2.conv.weight - torch.Size([256, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv2.bn.weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv2.bn.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv3.conv.weight - torch.Size([256, 256, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv3.bn.weight - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.conv3.bn.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.3.conv.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,968 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.3.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.4.conv.weight - torch.Size([512, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.4.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.7.conv.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.ffn.ffn_layers.7.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.gamma1 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.gamma2 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.norm1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.norm1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.norm2.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.norm2.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,969 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.pre_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.pre_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.pre_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv1.conv.weight - torch.Size([128, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv2.conv.weight - torch.Size([128, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv3.conv.weight - torch.Size([128, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,970 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv4.conv.weight - torch.Size([128, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.dw_conv4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.pw_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.pw_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.pw_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.h_conv.conv.weight - torch.Size([128, 1, 1, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.h_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.v_conv.conv.weight - torch.Size([128, 1, 11, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.v_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,971 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.conv2.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.caa_factor.conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.post_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.post_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.block.post_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.3.conv.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.3.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.4.conv.weight - torch.Size([512, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.4.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.7.conv.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.0.ffn.ffn_layers.7.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.gamma1 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.gamma2 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.norm1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.norm1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.norm2.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,972 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.norm2.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.pre_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.pre_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.pre_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv1.conv.weight - torch.Size([128, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv2.conv.weight - torch.Size([128, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv3.conv.weight - torch.Size([128, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv4.conv.weight - torch.Size([128, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.dw_conv4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.pw_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.pw_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.pw_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.h_conv.conv.weight - torch.Size([128, 1, 1, 13]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.h_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,973 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.v_conv.conv.weight - torch.Size([128, 1, 13, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.v_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.conv2.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.caa_factor.conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.post_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.post_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.block.post_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.3.conv.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.3.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.4.conv.weight - torch.Size([512, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.4.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.7.conv.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,974 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.1.ffn.ffn_layers.7.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.gamma1 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.gamma2 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.norm1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.norm1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.norm2.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.norm2.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.pre_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.pre_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.pre_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv1.conv.weight - torch.Size([128, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,975 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv2.conv.weight - torch.Size([128, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv3.conv.weight - torch.Size([128, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv4.conv.weight - torch.Size([128, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.dw_conv4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.pw_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.pw_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.pw_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.h_conv.conv.weight - torch.Size([128, 1, 1, 15]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.h_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,976 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.v_conv.conv.weight - torch.Size([128, 1, 15, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.v_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.conv2.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.caa_factor.conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.post_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.post_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.block.post_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.3.conv.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.3.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.4.conv.weight - torch.Size([512, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.4.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.7.conv.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,977 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.2.ffn.ffn_layers.7.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.gamma1 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.gamma2 - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.norm1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.norm1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.norm2.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.norm2.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.pre_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.pre_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.pre_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv.conv.weight - torch.Size([128, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv1.conv.weight - torch.Size([128, 1, 5, 5]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv2.conv.weight - torch.Size([128, 1, 7, 7]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv3.conv.weight - torch.Size([128, 1, 9, 9]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv3.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv4.conv.weight - torch.Size([128, 1, 11, 11]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.dw_conv4.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.pw_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,978 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.pw_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.pw_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.conv1.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.h_conv.conv.weight - torch.Size([128, 1, 1, 17]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.h_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.v_conv.conv.weight - torch.Size([128, 1, 17, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.v_conv.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.conv2.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.caa_factor.conv2.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.post_conv.conv.weight - torch.Size([128, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.post_conv.bn.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.block.post_conv.bn.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.1.weight - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.1.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.3.conv.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.3.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.4.conv.weight - torch.Size([512, 1, 3, 3]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.4.conv.bias - torch.Size([512]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.7.conv.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "backbone.stages.4.blocks.3.ffn.ffn_layers.7.conv.bias - torch.Size([128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,979 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.weight - torch.Size([256, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.weight - torch.Size([256, 128, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.3.conv.weight - torch.Size([256, 256, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.lateral_convs.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.encoder_conv.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.encoder_conv.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fusion_conv.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.fusion_conv.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,980 - mmcv - INFO - \r\n",
      "neck.excite_conv.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.excite_conv.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_fc.weight - torch.Size([1, 128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_fc.bias - torch.Size([1]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.in_proj_weight - torch.Size([48, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.in_proj_bias - torch.Size([48]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.out_proj.weight - torch.Size([16, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.out_proj.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.in_proj_weight - torch.Size([48, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.in_proj_bias - torch.Size([48]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.out_proj.weight - torch.Size([16, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.out_proj.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_fc.weight - torch.Size([1, 128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_fc.bias - torch.Size([1]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.0.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.0.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.3.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,981 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "rpn_head.rpn_conv.bias - torch.Size([256]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "rpn_head.rpn_cls.bias - torch.Size([3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "rpn_head.rpn_reg.weight - torch.Size([18, 256, 1, 1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "rpn_head.rpn_reg.bias - torch.Size([18]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_cls.weight - torch.Size([2, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_cls.bias - torch.Size([2]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_reg.weight - torch.Size([5, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_reg.bias - torch.Size([5]): \r\n",
      "NormalInit: mean=0, std=0.001, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:58:43,982 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-09-16 14:59:07,248 - mmrotate - INFO - Start running, host: root@0e35d4fc8181, work_dir: /kaggle/working/runs/FIRNet_train\r\n",
      "2025-09-16 14:59:07,248 - mmrotate - INFO - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(ABOVE_NORMAL) OptimizerHook                      \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      "(VERY_LOW    ) WandbLoggerHook                    \r\n",
      " -------------------- \r\n",
      "2025-09-16 14:59:07,249 - mmrotate - INFO - workflow: [('train', 1)], max: 10 epochs\r\n",
      "2025-09-16 14:59:07,249 - mmrotate - INFO - Checkpoints will be saved to /kaggle/working/runs/FIRNet_train by HardDiskBackend.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanish-jain140301\u001b[0m (\u001b[33mtanish1403\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/mmrotate/wandb/run-20250916_145907-dalqxg2u\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mFREANet_PKI\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/FREANet_training\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/FREANet_training/runs/dalqxg2u\u001b[0m\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "2025-09-16 15:01:50,134 - mmrotate - INFO - Epoch [1][100/1855]\tlr: 9.983e-04, eta: 8:14:37, time: 1.609, data_time: 0.034, memory: 9259, loss_rpn_cls: 0.4577, loss_rpn_bbox: 0.1064, loss_cls: 0.0902, acc: 99.1816, loss_bbox: 0.0128, loss: 0.6671, grad_norm: 4.0495\r\n",
      "2025-09-16 15:04:27,854 - mmrotate - INFO - Epoch [1][200/1855]\tlr: 1.165e-03, eta: 8:07:09, time: 1.577, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1519, loss_rpn_bbox: 0.1163, loss_cls: 0.0588, acc: 99.0742, loss_bbox: 0.0192, loss: 0.3462, grad_norm: 5.1680\r\n",
      "2025-09-16 15:07:05,340 - mmrotate - INFO - Epoch [1][300/1855]\tlr: 1.332e-03, eta: 8:02:40, time: 1.575, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1478, loss_rpn_bbox: 0.1068, loss_cls: 0.0593, acc: 98.9629, loss_bbox: 0.0192, loss: 0.3331, grad_norm: 4.2219\r\n",
      "2025-09-16 15:09:43,010 - mmrotate - INFO - Epoch [1][400/1855]\tlr: 1.498e-03, eta: 7:59:15, time: 1.577, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1251, loss_rpn_bbox: 0.1029, loss_cls: 0.0447, acc: 99.1113, loss_bbox: 0.0148, loss: 0.2874, grad_norm: 3.5612\r\n",
      "2025-09-16 15:12:20,893 - mmrotate - INFO - Epoch [1][500/1855]\tlr: 1.665e-03, eta: 7:56:17, time: 1.579, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1496, loss_rpn_bbox: 0.1328, loss_cls: 0.0581, acc: 98.8203, loss_bbox: 0.0168, loss: 0.3572, grad_norm: 3.6571\r\n",
      "2025-09-16 15:14:58,770 - mmrotate - INFO - Epoch [1][600/1855]\tlr: 1.832e-03, eta: 7:53:25, time: 1.579, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1469, loss_rpn_bbox: 0.1280, loss_cls: 0.0423, acc: 99.1465, loss_bbox: 0.0100, loss: 0.3271, grad_norm: 3.2501\r\n",
      "2025-09-16 15:17:36,758 - mmrotate - INFO - Epoch [1][700/1855]\tlr: 1.998e-03, eta: 7:50:40, time: 1.580, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1047, loss_rpn_bbox: 0.0879, loss_cls: 0.0370, acc: 99.1963, loss_bbox: 0.0117, loss: 0.2412, grad_norm: 2.6293\r\n",
      "2025-09-16 15:20:14,140 - mmrotate - INFO - Epoch [1][800/1855]\tlr: 2.165e-03, eta: 7:47:43, time: 1.574, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.1331, loss_rpn_bbox: 0.1157, loss_cls: 0.0535, acc: 98.8115, loss_bbox: 0.0154, loss: 0.3176, grad_norm: 3.2165\r\n",
      "2025-09-16 15:22:51,742 - mmrotate - INFO - Epoch [1][900/1855]\tlr: 2.332e-03, eta: 7:44:55, time: 1.576, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1323, loss_rpn_bbox: 0.1175, loss_cls: 0.0470, acc: 98.8906, loss_bbox: 0.0139, loss: 0.3108, grad_norm: 2.7845\r\n",
      "2025-09-16 15:25:29,697 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 15:25:29,697 - mmrotate - INFO - Epoch [1][1000/1855]\tlr: 2.498e-03, eta: 7:42:16, time: 1.580, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.0921, loss_rpn_bbox: 0.0910, loss_cls: 0.0433, acc: 98.9736, loss_bbox: 0.0136, loss: 0.2400, grad_norm: 2.3312\r\n",
      "2025-09-16 15:28:07,451 - mmrotate - INFO - Epoch [1][1100/1855]\tlr: 2.500e-03, eta: 7:39:33, time: 1.578, data_time: 0.010, memory: 9259, loss_rpn_cls: 0.1312, loss_rpn_bbox: 0.1124, loss_cls: 0.0462, acc: 98.8535, loss_bbox: 0.0139, loss: 0.3037, grad_norm: 2.5381\r\n",
      "2025-09-16 15:30:44,860 - mmrotate - INFO - Epoch [1][1200/1855]\tlr: 2.500e-03, eta: 7:36:46, time: 1.574, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.1388, loss_rpn_bbox: 0.1227, loss_cls: 0.0459, acc: 98.7939, loss_bbox: 0.0127, loss: 0.3200, grad_norm: 2.2902\r\n",
      "2025-09-16 15:33:22,269 - mmrotate - INFO - Epoch [1][1300/1855]\tlr: 2.500e-03, eta: 7:34:01, time: 1.574, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.1116, loss_rpn_bbox: 0.0936, loss_cls: 0.0402, acc: 99.0498, loss_bbox: 0.0125, loss: 0.2579, grad_norm: 2.2074\r\n",
      "2025-09-16 15:35:59,297 - mmrotate - INFO - Epoch [1][1400/1855]\tlr: 2.500e-03, eta: 7:31:12, time: 1.570, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.1110, loss_rpn_bbox: 0.1160, loss_cls: 0.0430, acc: 98.8672, loss_bbox: 0.0129, loss: 0.2830, grad_norm: 2.2831\r\n",
      "2025-09-16 15:38:36,624 - mmrotate - INFO - Epoch [1][1500/1855]\tlr: 2.500e-03, eta: 7:28:28, time: 1.573, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.1009, loss_rpn_bbox: 0.1067, loss_cls: 0.0520, acc: 98.6875, loss_bbox: 0.0181, loss: 0.2777, grad_norm: 2.0859\r\n",
      "2025-09-16 15:41:14,151 - mmrotate - INFO - Epoch [1][1600/1855]\tlr: 2.500e-03, eta: 7:25:47, time: 1.575, data_time: 0.009, memory: 9259, loss_rpn_cls: 0.1004, loss_rpn_bbox: 0.0949, loss_cls: 0.0442, acc: 98.8213, loss_bbox: 0.0166, loss: 0.2562, grad_norm: 2.1089\r\n",
      "2025-09-16 15:43:51,743 - mmrotate - INFO - Epoch [1][1700/1855]\tlr: 2.500e-03, eta: 7:23:07, time: 1.576, data_time: 0.009, memory: 9386, loss_rpn_cls: 0.1075, loss_rpn_bbox: 0.1028, loss_cls: 0.0520, acc: 98.5859, loss_bbox: 0.0178, loss: 0.2801, grad_norm: 2.2305\r\n",
      "2025-09-16 15:46:29,445 - mmrotate - INFO - Epoch [1][1800/1855]\tlr: 2.500e-03, eta: 7:20:29, time: 1.577, data_time: 0.009, memory: 9386, loss_rpn_cls: 0.1062, loss_rpn_bbox: 0.0928, loss_cls: 0.0530, acc: 98.6152, loss_bbox: 0.0178, loss: 0.2698, grad_norm: 1.8674\r\n",
      "2025-09-16 15:47:56,109 - mmrotate - INFO - Saving checkpoint at 1 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 15:49:30,437 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 4410 | 0.041  | 0.045 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.045 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 15:49:31,304 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_1.pth.\r\n",
      "2025-09-16 15:49:31,305 - mmrotate - INFO - Best mAP is 0.0455 at 1 epoch.\r\n",
      "2025-09-16 15:49:31,305 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 15:49:31,306 - mmrotate - INFO - Epoch(val) [1][464]\tmAP: 0.0455\r\n",
      "2025-09-16 15:52:11,452 - mmrotate - INFO - Epoch [2][100/1855]\tlr: 2.500e-03, eta: 7:04:27, time: 1.601, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0914, loss_rpn_bbox: 0.0743, loss_cls: 0.0528, acc: 98.5732, loss_bbox: 0.0204, loss: 0.2389, grad_norm: 1.9433\r\n",
      "2025-09-16 15:54:48,985 - mmrotate - INFO - Epoch [2][200/1855]\tlr: 2.500e-03, eta: 7:02:27, time: 1.575, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0990, loss_rpn_bbox: 0.0989, loss_cls: 0.0540, acc: 98.4160, loss_bbox: 0.0225, loss: 0.2744, grad_norm: 1.9712\r\n",
      "2025-09-16 15:57:26,849 - mmrotate - INFO - Epoch [2][300/1855]\tlr: 2.500e-03, eta: 7:00:25, time: 1.579, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0957, loss_rpn_bbox: 0.1041, loss_cls: 0.0508, acc: 98.6514, loss_bbox: 0.0218, loss: 0.2723, grad_norm: 1.9799\r\n",
      "2025-09-16 16:00:04,253 - mmrotate - INFO - Epoch [2][400/1855]\tlr: 2.500e-03, eta: 6:58:17, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0859, loss_rpn_bbox: 0.0822, loss_cls: 0.0481, acc: 98.6465, loss_bbox: 0.0219, loss: 0.2380, grad_norm: 1.7873\r\n",
      "2025-09-16 16:02:41,751 - mmrotate - INFO - Epoch [2][500/1855]\tlr: 2.500e-03, eta: 6:56:07, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.1034, loss_rpn_bbox: 0.1157, loss_cls: 0.0612, acc: 98.3701, loss_bbox: 0.0235, loss: 0.3039, grad_norm: 2.0793\r\n",
      "2025-09-16 16:05:19,350 - mmrotate - INFO - Epoch [2][600/1855]\tlr: 2.500e-03, eta: 6:53:55, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0896, loss_rpn_bbox: 0.0985, loss_cls: 0.0577, acc: 98.3906, loss_bbox: 0.0246, loss: 0.2704, grad_norm: 1.8095\r\n",
      "2025-09-16 16:07:56,658 - mmrotate - INFO - Epoch [2][700/1855]\tlr: 2.500e-03, eta: 6:51:39, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0725, loss_rpn_bbox: 0.0629, loss_cls: 0.0465, acc: 98.7119, loss_bbox: 0.0197, loss: 0.2015, grad_norm: 1.6288\r\n",
      "2025-09-16 16:10:34,231 - mmrotate - INFO - Epoch [2][800/1855]\tlr: 2.500e-03, eta: 6:49:24, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0830, loss_rpn_bbox: 0.0797, loss_cls: 0.0637, acc: 98.2568, loss_bbox: 0.0306, loss: 0.2569, grad_norm: 1.8197\r\n",
      "2025-09-16 16:13:11,826 - mmrotate - INFO - Epoch [2][900/1855]\tlr: 2.500e-03, eta: 6:47:07, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0827, loss_rpn_bbox: 0.0941, loss_cls: 0.0657, acc: 98.1387, loss_bbox: 0.0299, loss: 0.2723, grad_norm: 1.9384\r\n",
      "2025-09-16 16:15:49,275 - mmrotate - INFO - Epoch [2][1000/1855]\tlr: 2.500e-03, eta: 6:44:47, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0932, loss_rpn_bbox: 0.0887, loss_cls: 0.0660, acc: 98.1602, loss_bbox: 0.0285, loss: 0.2764, grad_norm: 2.0187\r\n",
      "2025-09-16 16:18:26,820 - mmrotate - INFO - Epoch [2][1100/1855]\tlr: 2.500e-03, eta: 6:42:27, time: 1.575, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0883, loss_rpn_bbox: 0.0947, loss_cls: 0.0645, acc: 98.1396, loss_bbox: 0.0307, loss: 0.2782, grad_norm: 2.0674\r\n",
      "2025-09-16 16:21:04,283 - mmrotate - INFO - Epoch [2][1200/1855]\tlr: 2.500e-03, eta: 6:40:06, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0696, loss_rpn_bbox: 0.0813, loss_cls: 0.0562, acc: 98.4297, loss_bbox: 0.0252, loss: 0.2323, grad_norm: 1.6439\r\n",
      "2025-09-16 16:23:41,828 - mmrotate - INFO - Epoch [2][1300/1855]\tlr: 2.500e-03, eta: 6:37:44, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0842, loss_rpn_bbox: 0.0884, loss_cls: 0.0632, acc: 98.1357, loss_bbox: 0.0302, loss: 0.2661, grad_norm: 1.9139\r\n",
      "2025-09-16 16:26:19,114 - mmrotate - INFO - Epoch [2][1400/1855]\tlr: 2.500e-03, eta: 6:35:19, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0797, loss_rpn_bbox: 0.0893, loss_cls: 0.0655, acc: 98.1172, loss_bbox: 0.0314, loss: 0.2659, grad_norm: 1.9279\r\n",
      "2025-09-16 16:28:56,360 - mmrotate - INFO - Epoch [2][1500/1855]\tlr: 2.500e-03, eta: 6:32:54, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0731, loss_rpn_bbox: 0.0742, loss_cls: 0.0704, acc: 98.0752, loss_bbox: 0.0320, loss: 0.2496, grad_norm: 1.8316\r\n",
      "2025-09-16 16:31:33,810 - mmrotate - INFO - Epoch [2][1600/1855]\tlr: 2.500e-03, eta: 6:30:29, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0724, loss_rpn_bbox: 0.0813, loss_cls: 0.0833, acc: 97.5566, loss_bbox: 0.0422, loss: 0.2793, grad_norm: 2.1110\r\n",
      "2025-09-16 16:34:11,120 - mmrotate - INFO - Epoch [2][1700/1855]\tlr: 2.500e-03, eta: 6:28:03, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0780, loss_rpn_bbox: 0.0898, loss_cls: 0.0719, acc: 97.9170, loss_bbox: 0.0349, loss: 0.2746, grad_norm: 1.9097\r\n",
      "2025-09-16 16:36:48,847 - mmrotate - INFO - Epoch [2][1800/1855]\tlr: 2.500e-03, eta: 6:25:37, time: 1.577, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0767, loss_rpn_bbox: 0.0934, loss_cls: 0.0694, acc: 97.9961, loss_bbox: 0.0340, loss: 0.2734, grad_norm: 1.8770\r\n",
      "2025-09-16 16:38:15,727 - mmrotate - INFO - Saving checkpoint at 2 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.4 task/s, elapsed: 86s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 16:39:51,944 - mmrotate - INFO - \r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| class | gts  | dets  | recall | ap    |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| ship  | 1744 | 11478 | 0.185  | 0.114 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| mAP   |      |       |        | 0.114 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "2025-09-16 16:39:52,065 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_1.pth was removed\r\n",
      "2025-09-16 16:39:53,098 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_2.pth.\r\n",
      "2025-09-16 16:39:53,099 - mmrotate - INFO - Best mAP is 0.1136 at 2 epoch.\r\n",
      "2025-09-16 16:39:53,100 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 16:39:53,100 - mmrotate - INFO - Epoch(val) [2][464]\tmAP: 0.1136\r\n",
      "2025-09-16 16:42:32,881 - mmrotate - INFO - Epoch [3][100/1855]\tlr: 2.500e-03, eta: 6:16:23, time: 1.598, data_time: 0.033, memory: 9386, loss_rpn_cls: 0.0627, loss_rpn_bbox: 0.0862, loss_cls: 0.0621, acc: 98.2090, loss_bbox: 0.0296, loss: 0.2405, grad_norm: 1.8496\r\n",
      "2025-09-16 16:45:10,239 - mmrotate - INFO - Epoch [3][200/1855]\tlr: 2.500e-03, eta: 6:14:05, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0662, loss_rpn_bbox: 0.0801, loss_cls: 0.0794, acc: 97.5781, loss_bbox: 0.0430, loss: 0.2687, grad_norm: 1.9230\r\n",
      "2025-09-16 16:47:48,012 - mmrotate - INFO - Epoch [3][300/1855]\tlr: 2.500e-03, eta: 6:11:48, time: 1.578, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0733, loss_rpn_bbox: 0.0876, loss_cls: 0.0868, acc: 97.4893, loss_bbox: 0.0443, loss: 0.2921, grad_norm: 2.0590\r\n",
      "2025-09-16 16:50:26,255 - mmrotate - INFO - Epoch [3][400/1855]\tlr: 2.500e-03, eta: 6:09:32, time: 1.582, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0624, loss_rpn_bbox: 0.0695, loss_cls: 0.0673, acc: 97.9609, loss_bbox: 0.0355, loss: 0.2347, grad_norm: 1.7461\r\n",
      "2025-09-16 16:53:04,069 - mmrotate - INFO - Epoch [3][500/1855]\tlr: 2.500e-03, eta: 6:07:13, time: 1.578, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0705, loss_rpn_bbox: 0.0824, loss_cls: 0.0845, acc: 97.5088, loss_bbox: 0.0437, loss: 0.2812, grad_norm: 2.0204\r\n",
      "2025-09-16 16:55:41,755 - mmrotate - INFO - Epoch [3][600/1855]\tlr: 2.500e-03, eta: 6:04:52, time: 1.577, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0630, loss_rpn_bbox: 0.0681, loss_cls: 0.0771, acc: 97.7275, loss_bbox: 0.0410, loss: 0.2493, grad_norm: 1.8127\r\n",
      "2025-09-16 16:58:19,271 - mmrotate - INFO - Epoch [3][700/1855]\tlr: 2.500e-03, eta: 6:02:31, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0640, loss_rpn_bbox: 0.0583, loss_cls: 0.0710, acc: 97.8076, loss_bbox: 0.0381, loss: 0.2315, grad_norm: 1.7128\r\n",
      "2025-09-16 17:00:56,516 - mmrotate - INFO - Epoch [3][800/1855]\tlr: 2.500e-03, eta: 6:00:08, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0699, loss_rpn_bbox: 0.0781, loss_cls: 0.0784, acc: 97.7266, loss_bbox: 0.0411, loss: 0.2675, grad_norm: 1.8628\r\n",
      "2025-09-16 17:03:34,468 - mmrotate - INFO - Epoch [3][900/1855]\tlr: 2.500e-03, eta: 5:57:46, time: 1.580, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0785, loss_rpn_bbox: 0.0890, loss_cls: 0.0784, acc: 97.6260, loss_bbox: 0.0423, loss: 0.2883, grad_norm: 2.0755\r\n",
      "2025-09-16 17:06:11,724 - mmrotate - INFO - Epoch [3][1000/1855]\tlr: 2.500e-03, eta: 5:55:22, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0728, loss_rpn_bbox: 0.0751, loss_cls: 0.0810, acc: 97.4521, loss_bbox: 0.0462, loss: 0.2752, grad_norm: 1.8880\r\n",
      "2025-09-16 17:08:48,975 - mmrotate - INFO - Epoch [3][1100/1855]\tlr: 2.500e-03, eta: 5:52:57, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0675, loss_rpn_bbox: 0.1000, loss_cls: 0.0817, acc: 97.4414, loss_bbox: 0.0445, loss: 0.2936, grad_norm: 1.9622\r\n",
      "2025-09-16 17:11:26,464 - mmrotate - INFO - Epoch [3][1200/1855]\tlr: 2.500e-03, eta: 5:50:32, time: 1.575, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0647, loss_rpn_bbox: 0.0727, loss_cls: 0.0707, acc: 97.8359, loss_bbox: 0.0393, loss: 0.2474, grad_norm: 1.7220\r\n",
      "2025-09-16 17:14:03,773 - mmrotate - INFO - Epoch [3][1300/1855]\tlr: 2.500e-03, eta: 5:48:06, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0626, loss_rpn_bbox: 0.0856, loss_cls: 0.0803, acc: 97.5195, loss_bbox: 0.0438, loss: 0.2722, grad_norm: 1.9319\r\n",
      "2025-09-16 17:16:41,188 - mmrotate - INFO - Epoch [3][1400/1855]\tlr: 2.500e-03, eta: 5:45:40, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0638, loss_rpn_bbox: 0.0741, loss_cls: 0.0802, acc: 97.4746, loss_bbox: 0.0441, loss: 0.2623, grad_norm: 1.8657\r\n",
      "2025-09-16 17:19:18,445 - mmrotate - INFO - Epoch [3][1500/1855]\tlr: 2.500e-03, eta: 5:43:13, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0695, loss_rpn_bbox: 0.0694, loss_cls: 0.0771, acc: 97.5098, loss_bbox: 0.0427, loss: 0.2587, grad_norm: 1.9440\r\n",
      "2025-09-16 17:21:55,705 - mmrotate - INFO - Epoch [3][1600/1855]\tlr: 2.500e-03, eta: 5:40:46, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0663, loss_rpn_bbox: 0.0758, loss_cls: 0.0806, acc: 97.5732, loss_bbox: 0.0431, loss: 0.2658, grad_norm: 1.8680\r\n",
      "2025-09-16 17:24:32,867 - mmrotate - INFO - Epoch [3][1700/1855]\tlr: 2.500e-03, eta: 5:38:18, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0625, loss_rpn_bbox: 0.0738, loss_cls: 0.0753, acc: 97.7100, loss_bbox: 0.0421, loss: 0.2538, grad_norm: 1.8194\r\n",
      "2025-09-16 17:27:10,174 - mmrotate - INFO - Epoch [3][1800/1855]\tlr: 2.500e-03, eta: 5:35:50, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0873, loss_rpn_bbox: 0.1145, loss_cls: 0.0934, acc: 97.1895, loss_bbox: 0.0472, loss: 0.3424, grad_norm: 2.1117\r\n",
      "2025-09-16 17:28:36,810 - mmrotate - INFO - Saving checkpoint at 3 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 17:30:11,195 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 9844 | 0.338  | 0.198 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.198 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 17:30:11,320 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_2.pth was removed\r\n",
      "2025-09-16 17:30:12,094 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_3.pth.\r\n",
      "2025-09-16 17:30:12,096 - mmrotate - INFO - Best mAP is 0.1982 at 3 epoch.\r\n",
      "2025-09-16 17:30:12,096 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 17:30:12,097 - mmrotate - INFO - Epoch(val) [3][464]\tmAP: 0.1982\r\n",
      "2025-09-16 17:32:51,707 - mmrotate - INFO - Epoch [4][100/1855]\tlr: 2.500e-03, eta: 5:28:49, time: 1.596, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0518, loss_rpn_bbox: 0.0596, loss_cls: 0.0704, acc: 97.7598, loss_bbox: 0.0405, loss: 0.2224, grad_norm: 1.6912\r\n",
      "2025-09-16 17:35:29,077 - mmrotate - INFO - Epoch [4][200/1855]\tlr: 2.500e-03, eta: 5:26:25, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0639, loss_rpn_bbox: 0.0779, loss_cls: 0.0772, acc: 97.5957, loss_bbox: 0.0447, loss: 0.2637, grad_norm: 1.8803\r\n",
      "2025-09-16 17:38:06,509 - mmrotate - INFO - Epoch [4][300/1855]\tlr: 2.500e-03, eta: 5:24:01, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0599, loss_rpn_bbox: 0.0724, loss_cls: 0.0758, acc: 97.6055, loss_bbox: 0.0430, loss: 0.2510, grad_norm: 1.8458\r\n",
      "2025-09-16 17:40:43,545 - mmrotate - INFO - Epoch [4][400/1855]\tlr: 2.500e-03, eta: 5:21:36, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0735, loss_rpn_bbox: 0.0817, loss_cls: 0.0904, acc: 97.1523, loss_bbox: 0.0537, loss: 0.2993, grad_norm: 2.0474\r\n",
      "2025-09-16 17:43:20,993 - mmrotate - INFO - Epoch [4][500/1855]\tlr: 2.500e-03, eta: 5:19:11, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0762, loss_rpn_bbox: 0.0714, loss_cls: 0.0886, acc: 97.3477, loss_bbox: 0.0469, loss: 0.2831, grad_norm: 1.9006\r\n",
      "2025-09-16 17:45:58,092 - mmrotate - INFO - Epoch [4][600/1855]\tlr: 2.500e-03, eta: 5:16:45, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0549, loss_rpn_bbox: 0.0764, loss_cls: 0.0756, acc: 97.6465, loss_bbox: 0.0416, loss: 0.2485, grad_norm: 1.6945\r\n",
      "2025-09-16 17:48:35,300 - mmrotate - INFO - Epoch [4][700/1855]\tlr: 2.500e-03, eta: 5:14:19, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0522, loss_rpn_bbox: 0.0808, loss_cls: 0.0920, acc: 97.0928, loss_bbox: 0.0551, loss: 0.2801, grad_norm: 1.9389\r\n",
      "2025-09-16 17:51:12,563 - mmrotate - INFO - Epoch [4][800/1855]\tlr: 2.500e-03, eta: 5:11:53, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0720, loss_rpn_bbox: 0.0847, loss_cls: 0.0896, acc: 97.1680, loss_bbox: 0.0499, loss: 0.2962, grad_norm: 1.9931\r\n",
      "2025-09-16 17:53:49,692 - mmrotate - INFO - Epoch [4][900/1855]\tlr: 2.500e-03, eta: 5:09:26, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0482, loss_rpn_bbox: 0.0597, loss_cls: 0.0750, acc: 97.5605, loss_bbox: 0.0454, loss: 0.2284, grad_norm: 1.7130\r\n",
      "2025-09-16 17:56:26,914 - mmrotate - INFO - Epoch [4][1000/1855]\tlr: 2.500e-03, eta: 5:06:59, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0640, loss_rpn_bbox: 0.0825, loss_cls: 0.0940, acc: 97.0137, loss_bbox: 0.0521, loss: 0.2926, grad_norm: 1.9721\r\n",
      "2025-09-16 17:59:04,104 - mmrotate - INFO - Epoch [4][1100/1855]\tlr: 2.500e-03, eta: 5:04:31, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0602, loss_rpn_bbox: 0.0763, loss_cls: 0.0910, acc: 97.0762, loss_bbox: 0.0536, loss: 0.2811, grad_norm: 1.8153\r\n",
      "2025-09-16 18:01:41,083 - mmrotate - INFO - Epoch [4][1200/1855]\tlr: 2.500e-03, eta: 5:02:03, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0569, loss_rpn_bbox: 0.0691, loss_cls: 0.0914, acc: 97.0059, loss_bbox: 0.0585, loss: 0.2759, grad_norm: 1.9404\r\n",
      "2025-09-16 18:04:18,398 - mmrotate - INFO - Epoch [4][1300/1855]\tlr: 2.500e-03, eta: 4:59:36, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0463, loss_rpn_bbox: 0.0613, loss_cls: 0.0769, acc: 97.4922, loss_bbox: 0.0449, loss: 0.2295, grad_norm: 1.7602\r\n",
      "2025-09-16 18:06:55,662 - mmrotate - INFO - Epoch [4][1400/1855]\tlr: 2.500e-03, eta: 4:57:07, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0602, loss_rpn_bbox: 0.0782, loss_cls: 0.0795, acc: 97.3633, loss_bbox: 0.0476, loss: 0.2656, grad_norm: 1.8651\r\n",
      "2025-09-16 18:09:32,967 - mmrotate - INFO - Epoch [4][1500/1855]\tlr: 2.500e-03, eta: 4:54:39, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0672, loss_rpn_bbox: 0.0819, loss_cls: 0.0840, acc: 97.2129, loss_bbox: 0.0516, loss: 0.2848, grad_norm: 2.0127\r\n",
      "2025-09-16 18:12:10,018 - mmrotate - INFO - Epoch [4][1600/1855]\tlr: 2.500e-03, eta: 4:52:10, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0664, loss_rpn_bbox: 0.0860, loss_cls: 0.0879, acc: 97.1602, loss_bbox: 0.0516, loss: 0.2918, grad_norm: 2.0152\r\n",
      "2025-09-16 18:14:47,569 - mmrotate - INFO - Epoch [4][1700/1855]\tlr: 2.500e-03, eta: 4:49:42, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0471, loss_rpn_bbox: 0.0682, loss_cls: 0.0685, acc: 97.7803, loss_bbox: 0.0404, loss: 0.2242, grad_norm: 1.6974\r\n",
      "2025-09-16 18:17:24,642 - mmrotate - INFO - Epoch [4][1800/1855]\tlr: 2.500e-03, eta: 4:47:12, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0593, loss_rpn_bbox: 0.0815, loss_cls: 0.1007, acc: 96.6738, loss_bbox: 0.0628, loss: 0.3043, grad_norm: 2.0369\r\n",
      "2025-09-16 18:18:51,093 - mmrotate - INFO - Saving checkpoint at 4 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 18:20:25,407 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5452 | 0.349  | 0.241 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.241 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 18:20:25,532 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_3.pth was removed\r\n",
      "2025-09-16 18:20:26,305 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_4.pth.\r\n",
      "2025-09-16 18:20:26,306 - mmrotate - INFO - Best mAP is 0.2412 at 4 epoch.\r\n",
      "2025-09-16 18:20:26,307 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 18:20:26,307 - mmrotate - INFO - Epoch(val) [4][464]\tmAP: 0.2412\r\n",
      "2025-09-16 18:23:06,282 - mmrotate - INFO - Epoch [5][100/1855]\tlr: 2.500e-03, eta: 4:41:18, time: 1.600, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0649, loss_rpn_bbox: 0.0744, loss_cls: 0.0778, acc: 97.3984, loss_bbox: 0.0453, loss: 0.2625, grad_norm: 1.8451\r\n",
      "2025-09-16 18:25:43,558 - mmrotate - INFO - Epoch [5][200/1855]\tlr: 2.500e-03, eta: 4:38:51, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0529, loss_rpn_bbox: 0.0663, loss_cls: 0.0792, acc: 97.4004, loss_bbox: 0.0494, loss: 0.2478, grad_norm: 1.7341\r\n",
      "2025-09-16 18:28:20,801 - mmrotate - INFO - Epoch [5][300/1855]\tlr: 2.500e-03, eta: 4:36:24, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0554, loss_rpn_bbox: 0.0760, loss_cls: 0.0772, acc: 97.3799, loss_bbox: 0.0506, loss: 0.2592, grad_norm: 1.8046\r\n",
      "2025-09-16 18:30:57,889 - mmrotate - INFO - Epoch [5][400/1855]\tlr: 2.500e-03, eta: 4:33:56, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0591, loss_rpn_bbox: 0.0665, loss_cls: 0.0761, acc: 97.5371, loss_bbox: 0.0463, loss: 0.2480, grad_norm: 1.8457\r\n",
      "2025-09-16 18:33:35,055 - mmrotate - INFO - Epoch [5][500/1855]\tlr: 2.500e-03, eta: 4:31:28, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0494, loss_rpn_bbox: 0.0680, loss_cls: 0.0725, acc: 97.5947, loss_bbox: 0.0434, loss: 0.2333, grad_norm: 1.7894\r\n",
      "2025-09-16 18:36:12,599 - mmrotate - INFO - Epoch [5][600/1855]\tlr: 2.500e-03, eta: 4:29:00, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0508, loss_rpn_bbox: 0.0612, loss_cls: 0.0681, acc: 97.7412, loss_bbox: 0.0410, loss: 0.2211, grad_norm: 1.7466\r\n",
      "2025-09-16 18:38:49,712 - mmrotate - INFO - Epoch [5][700/1855]\tlr: 2.500e-03, eta: 4:26:32, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0559, loss_rpn_bbox: 0.0837, loss_cls: 0.0920, acc: 96.8359, loss_bbox: 0.0597, loss: 0.2913, grad_norm: 2.0648\r\n",
      "2025-09-16 18:41:27,016 - mmrotate - INFO - Epoch [5][800/1855]\tlr: 2.500e-03, eta: 4:24:04, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0451, loss_rpn_bbox: 0.0749, loss_cls: 0.0634, acc: 97.8584, loss_bbox: 0.0389, loss: 0.2223, grad_norm: 1.7413\r\n",
      "2025-09-16 18:44:04,071 - mmrotate - INFO - Epoch [5][900/1855]\tlr: 2.500e-03, eta: 4:21:35, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0475, loss_rpn_bbox: 0.0691, loss_cls: 0.0822, acc: 97.3125, loss_bbox: 0.0507, loss: 0.2495, grad_norm: 1.8577\r\n",
      "2025-09-16 18:46:41,384 - mmrotate - INFO - Epoch [5][1000/1855]\tlr: 2.500e-03, eta: 4:19:06, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0667, loss_rpn_bbox: 0.0727, loss_cls: 0.0833, acc: 97.3691, loss_bbox: 0.0485, loss: 0.2713, grad_norm: 1.9522\r\n",
      "2025-09-16 18:49:18,757 - mmrotate - INFO - Epoch [5][1100/1855]\tlr: 2.500e-03, eta: 4:16:37, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0604, loss_rpn_bbox: 0.0772, loss_cls: 0.0831, acc: 97.2021, loss_bbox: 0.0519, loss: 0.2727, grad_norm: 1.9105\r\n",
      "2025-09-16 18:51:55,994 - mmrotate - INFO - Epoch [5][1200/1855]\tlr: 2.500e-03, eta: 4:14:08, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0639, loss_rpn_bbox: 0.0934, loss_cls: 0.0946, acc: 96.7676, loss_bbox: 0.0658, loss: 0.3177, grad_norm: 2.1247\r\n",
      "2025-09-16 18:54:33,142 - mmrotate - INFO - Epoch [5][1300/1855]\tlr: 2.500e-03, eta: 4:11:39, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0587, loss_rpn_bbox: 0.0876, loss_cls: 0.0736, acc: 97.4795, loss_bbox: 0.0477, loss: 0.2676, grad_norm: 1.9729\r\n",
      "2025-09-16 18:57:10,567 - mmrotate - INFO - Epoch [5][1400/1855]\tlr: 2.500e-03, eta: 4:09:09, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0517, loss_rpn_bbox: 0.0765, loss_cls: 0.0953, acc: 96.7471, loss_bbox: 0.0600, loss: 0.2836, grad_norm: 1.9444\r\n",
      "2025-09-16 18:59:47,531 - mmrotate - INFO - Epoch [5][1500/1855]\tlr: 2.500e-03, eta: 4:06:39, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0497, loss_rpn_bbox: 0.0754, loss_cls: 0.0845, acc: 97.0713, loss_bbox: 0.0547, loss: 0.2644, grad_norm: 1.8804\r\n",
      "2025-09-16 19:02:24,587 - mmrotate - INFO - Epoch [5][1600/1855]\tlr: 2.500e-03, eta: 4:04:09, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0452, loss_rpn_bbox: 0.0718, loss_cls: 0.0716, acc: 97.5625, loss_bbox: 0.0451, loss: 0.2337, grad_norm: 1.7206\r\n",
      "2025-09-16 19:05:01,739 - mmrotate - INFO - Epoch [5][1700/1855]\tlr: 2.500e-03, eta: 4:01:39, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0565, loss_rpn_bbox: 0.0790, loss_cls: 0.0836, acc: 97.1992, loss_bbox: 0.0510, loss: 0.2700, grad_norm: 2.0697\r\n",
      "2025-09-16 19:07:39,115 - mmrotate - INFO - Epoch [5][1800/1855]\tlr: 2.500e-03, eta: 3:59:09, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0515, loss_rpn_bbox: 0.0663, loss_cls: 0.0848, acc: 97.0879, loss_bbox: 0.0580, loss: 0.2607, grad_norm: 1.8148\r\n",
      "2025-09-16 19:09:05,566 - mmrotate - INFO - Saving checkpoint at 5 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 19:10:39,426 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5762 | 0.436  | 0.307 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.307 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 19:10:39,552 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_4.pth was removed\r\n",
      "2025-09-16 19:10:40,347 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_5.pth.\r\n",
      "2025-09-16 19:10:40,348 - mmrotate - INFO - Best mAP is 0.3069 at 5 epoch.\r\n",
      "2025-09-16 19:10:40,349 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 19:10:40,349 - mmrotate - INFO - Epoch(val) [5][464]\tmAP: 0.3069\r\n",
      "2025-09-16 19:13:19,834 - mmrotate - INFO - Epoch [6][100/1855]\tlr: 2.500e-03, eta: 3:53:53, time: 1.595, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0513, loss_rpn_bbox: 0.0643, loss_cls: 0.0793, acc: 97.3057, loss_bbox: 0.0484, loss: 0.2433, grad_norm: 1.8656\r\n",
      "2025-09-16 19:15:57,131 - mmrotate - INFO - Epoch [6][200/1855]\tlr: 2.500e-03, eta: 3:51:24, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0456, loss_rpn_bbox: 0.0768, loss_cls: 0.0796, acc: 97.2949, loss_bbox: 0.0532, loss: 0.2552, grad_norm: 1.8553\r\n",
      "2025-09-16 19:18:34,300 - mmrotate - INFO - Epoch [6][300/1855]\tlr: 2.500e-03, eta: 3:48:55, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0342, loss_rpn_bbox: 0.0567, loss_cls: 0.0796, acc: 97.2256, loss_bbox: 0.0510, loss: 0.2215, grad_norm: 1.7483\r\n",
      "2025-09-16 19:21:11,391 - mmrotate - INFO - Epoch [6][400/1855]\tlr: 2.500e-03, eta: 3:46:26, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0504, loss_rpn_bbox: 0.0674, loss_cls: 0.0774, acc: 97.3369, loss_bbox: 0.0470, loss: 0.2422, grad_norm: 1.8798\r\n",
      "2025-09-16 19:23:48,458 - mmrotate - INFO - Epoch [6][500/1855]\tlr: 2.500e-03, eta: 3:43:56, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0453, loss_rpn_bbox: 0.0574, loss_cls: 0.0813, acc: 97.2627, loss_bbox: 0.0531, loss: 0.2371, grad_norm: 1.8592\r\n",
      "2025-09-16 19:26:26,029 - mmrotate - INFO - Epoch [6][600/1855]\tlr: 2.500e-03, eta: 3:41:27, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.0663, loss_cls: 0.0739, acc: 97.4531, loss_bbox: 0.0484, loss: 0.2306, grad_norm: 1.7698\r\n",
      "2025-09-16 19:29:03,316 - mmrotate - INFO - Epoch [6][700/1855]\tlr: 2.500e-03, eta: 3:38:57, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0605, loss_rpn_bbox: 0.0696, loss_cls: 0.0886, acc: 96.8604, loss_bbox: 0.0549, loss: 0.2735, grad_norm: 2.0231\r\n",
      "2025-09-16 19:31:40,497 - mmrotate - INFO - Epoch [6][800/1855]\tlr: 2.500e-03, eta: 3:36:28, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0579, loss_rpn_bbox: 0.0821, loss_cls: 0.0903, acc: 97.0293, loss_bbox: 0.0566, loss: 0.2869, grad_norm: 2.0853\r\n",
      "2025-09-16 19:34:17,450 - mmrotate - INFO - Epoch [6][900/1855]\tlr: 2.500e-03, eta: 3:33:57, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0504, loss_rpn_bbox: 0.0695, loss_cls: 0.0780, acc: 97.3135, loss_bbox: 0.0498, loss: 0.2476, grad_norm: 1.7517\r\n",
      "2025-09-16 19:36:54,867 - mmrotate - INFO - Epoch [6][1000/1855]\tlr: 2.500e-03, eta: 3:31:27, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0566, loss_rpn_bbox: 0.0690, loss_cls: 0.0985, acc: 96.6133, loss_bbox: 0.0654, loss: 0.2894, grad_norm: 2.0260\r\n",
      "2025-09-16 19:39:32,277 - mmrotate - INFO - Epoch [6][1100/1855]\tlr: 2.500e-03, eta: 3:28:57, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0597, loss_rpn_bbox: 0.0762, loss_cls: 0.0888, acc: 97.1221, loss_bbox: 0.0538, loss: 0.2786, grad_norm: 1.9262\r\n",
      "2025-09-16 19:42:09,701 - mmrotate - INFO - Epoch [6][1200/1855]\tlr: 2.500e-03, eta: 3:26:27, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0472, loss_rpn_bbox: 0.0671, loss_cls: 0.0766, acc: 97.3770, loss_bbox: 0.0504, loss: 0.2413, grad_norm: 1.7944\r\n",
      "2025-09-16 19:44:47,386 - mmrotate - INFO - Epoch [6][1300/1855]\tlr: 2.500e-03, eta: 3:23:57, time: 1.577, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0474, loss_rpn_bbox: 0.0687, loss_cls: 0.0867, acc: 96.9883, loss_bbox: 0.0588, loss: 0.2616, grad_norm: 1.9673\r\n",
      "2025-09-16 19:47:24,796 - mmrotate - INFO - Epoch [6][1400/1855]\tlr: 2.500e-03, eta: 3:21:26, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0466, loss_rpn_bbox: 0.0557, loss_cls: 0.0865, acc: 96.9785, loss_bbox: 0.0567, loss: 0.2455, grad_norm: 1.8744\r\n",
      "2025-09-16 19:50:02,483 - mmrotate - INFO - Epoch [6][1500/1855]\tlr: 2.500e-03, eta: 3:18:56, time: 1.577, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0480, loss_rpn_bbox: 0.0635, loss_cls: 0.0773, acc: 97.3994, loss_bbox: 0.0494, loss: 0.2382, grad_norm: 1.8286\r\n",
      "2025-09-16 19:52:39,742 - mmrotate - INFO - Epoch [6][1600/1855]\tlr: 2.500e-03, eta: 3:16:25, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0461, loss_rpn_bbox: 0.0665, loss_cls: 0.0814, acc: 97.1787, loss_bbox: 0.0556, loss: 0.2496, grad_norm: 1.9106\r\n",
      "2025-09-16 19:55:16,985 - mmrotate - INFO - Epoch [6][1700/1855]\tlr: 2.500e-03, eta: 3:13:54, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0505, loss_rpn_bbox: 0.0756, loss_cls: 0.0855, acc: 97.0166, loss_bbox: 0.0565, loss: 0.2681, grad_norm: 2.0884\r\n",
      "2025-09-16 19:57:54,185 - mmrotate - INFO - Epoch [6][1800/1855]\tlr: 2.500e-03, eta: 3:11:23, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0540, loss_rpn_bbox: 0.0912, loss_cls: 0.0875, acc: 96.9463, loss_bbox: 0.0591, loss: 0.2918, grad_norm: 2.0964\r\n",
      "2025-09-16 19:59:20,459 - mmrotate - INFO - Saving checkpoint at 6 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.6 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 20:00:54,378 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 6327 | 0.426  | 0.297 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.297 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 20:00:54,465 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 20:00:54,466 - mmrotate - INFO - Epoch(val) [6][464]\tmAP: 0.2974\r\n",
      "2025-09-16 20:03:34,005 - mmrotate - INFO - Epoch [7][100/1855]\tlr: 2.500e-03, eta: 3:06:34, time: 1.595, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0373, loss_rpn_bbox: 0.0550, loss_cls: 0.0792, acc: 97.1855, loss_bbox: 0.0537, loss: 0.2252, grad_norm: 1.7898\r\n",
      "2025-09-16 20:06:11,138 - mmrotate - INFO - Epoch [7][200/1855]\tlr: 2.500e-03, eta: 3:04:03, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0475, loss_rpn_bbox: 0.0794, loss_cls: 0.0863, acc: 96.9014, loss_bbox: 0.0583, loss: 0.2714, grad_norm: 2.0165\r\n",
      "2025-09-16 20:08:47,992 - mmrotate - INFO - Epoch [7][300/1855]\tlr: 2.500e-03, eta: 3:01:33, time: 1.569, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0443, loss_rpn_bbox: 0.0722, loss_cls: 0.0831, acc: 97.1328, loss_bbox: 0.0540, loss: 0.2536, grad_norm: 1.9326\r\n",
      "2025-09-16 20:11:25,043 - mmrotate - INFO - Epoch [7][400/1855]\tlr: 2.500e-03, eta: 2:59:02, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0436, loss_rpn_bbox: 0.0554, loss_cls: 0.0815, acc: 97.1006, loss_bbox: 0.0551, loss: 0.2357, grad_norm: 1.9652\r\n",
      "2025-09-16 20:14:01,974 - mmrotate - INFO - Epoch [7][500/1855]\tlr: 2.500e-03, eta: 2:56:32, time: 1.569, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0400, loss_rpn_bbox: 0.0599, loss_cls: 0.0828, acc: 97.1377, loss_bbox: 0.0570, loss: 0.2397, grad_norm: 1.9343\r\n",
      "2025-09-16 20:16:39,045 - mmrotate - INFO - Epoch [7][600/1855]\tlr: 2.500e-03, eta: 2:54:01, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0417, loss_rpn_bbox: 0.0670, loss_cls: 0.0824, acc: 97.0322, loss_bbox: 0.0580, loss: 0.2491, grad_norm: 1.9925\r\n",
      "2025-09-16 20:19:16,005 - mmrotate - INFO - Epoch [7][700/1855]\tlr: 2.500e-03, eta: 2:51:30, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0516, loss_rpn_bbox: 0.0779, loss_cls: 0.0848, acc: 97.0098, loss_bbox: 0.0566, loss: 0.2710, grad_norm: 2.0996\r\n",
      "2025-09-16 20:21:52,996 - mmrotate - INFO - Epoch [7][800/1855]\tlr: 2.500e-03, eta: 2:48:59, time: 1.570, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.0650, loss_cls: 0.0864, acc: 96.8818, loss_bbox: 0.0606, loss: 0.2540, grad_norm: 1.8800\r\n",
      "2025-09-16 20:24:30,158 - mmrotate - INFO - Epoch [7][900/1855]\tlr: 2.500e-03, eta: 2:46:28, time: 1.572, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0471, loss_rpn_bbox: 0.0618, loss_cls: 0.0899, acc: 96.9297, loss_bbox: 0.0585, loss: 0.2573, grad_norm: 1.9746\r\n",
      "2025-09-16 20:27:07,530 - mmrotate - INFO - Epoch [7][1000/1855]\tlr: 2.500e-03, eta: 2:43:57, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0446, loss_rpn_bbox: 0.0745, loss_cls: 0.0790, acc: 97.1758, loss_bbox: 0.0539, loss: 0.2519, grad_norm: 2.0142\r\n",
      "2025-09-16 20:29:44,654 - mmrotate - INFO - Epoch [7][1100/1855]\tlr: 2.500e-03, eta: 2:41:26, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0483, loss_rpn_bbox: 0.0740, loss_cls: 0.0835, acc: 97.1328, loss_bbox: 0.0552, loss: 0.2610, grad_norm: 1.9775\r\n",
      "2025-09-16 20:32:21,827 - mmrotate - INFO - Epoch [7][1200/1855]\tlr: 2.500e-03, eta: 2:38:54, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0509, loss_rpn_bbox: 0.0720, loss_cls: 0.0827, acc: 97.1035, loss_bbox: 0.0528, loss: 0.2584, grad_norm: 1.9793\r\n",
      "2025-09-16 20:34:58,916 - mmrotate - INFO - Epoch [7][1300/1855]\tlr: 2.500e-03, eta: 2:36:23, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0408, loss_rpn_bbox: 0.0590, loss_cls: 0.0782, acc: 97.2910, loss_bbox: 0.0504, loss: 0.2284, grad_norm: 1.8624\r\n",
      "2025-09-16 20:37:36,280 - mmrotate - INFO - Epoch [7][1400/1855]\tlr: 2.500e-03, eta: 2:33:52, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0533, loss_rpn_bbox: 0.0641, loss_cls: 0.0869, acc: 96.9004, loss_bbox: 0.0582, loss: 0.2625, grad_norm: 2.0240\r\n",
      "2025-09-16 20:40:13,774 - mmrotate - INFO - Epoch [7][1500/1855]\tlr: 2.500e-03, eta: 2:31:20, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0453, loss_rpn_bbox: 0.0648, loss_cls: 0.0950, acc: 96.6826, loss_bbox: 0.0649, loss: 0.2699, grad_norm: 1.9145\r\n",
      "2025-09-16 20:42:51,044 - mmrotate - INFO - Epoch [7][1600/1855]\tlr: 2.500e-03, eta: 2:28:49, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0348, loss_rpn_bbox: 0.0509, loss_cls: 0.0731, acc: 97.4023, loss_bbox: 0.0502, loss: 0.2090, grad_norm: 1.6613\r\n",
      "2025-09-16 20:45:28,629 - mmrotate - INFO - Epoch [7][1700/1855]\tlr: 2.500e-03, eta: 2:26:17, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0575, loss_rpn_bbox: 0.0804, loss_cls: 0.0961, acc: 96.6094, loss_bbox: 0.0659, loss: 0.2999, grad_norm: 2.1790\r\n",
      "2025-09-16 20:48:06,054 - mmrotate - INFO - Epoch [7][1800/1855]\tlr: 2.500e-03, eta: 2:23:45, time: 1.574, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0540, loss_rpn_bbox: 0.0677, loss_cls: 0.0820, acc: 97.2344, loss_bbox: 0.0519, loss: 0.2556, grad_norm: 1.9182\r\n",
      "2025-09-16 20:49:32,609 - mmrotate - INFO - Saving checkpoint at 7 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 20:51:06,807 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5243 | 0.530  | 0.401 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.401 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 20:51:06,932 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_5.pth was removed\r\n",
      "2025-09-16 20:51:07,717 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_7.pth.\r\n",
      "2025-09-16 20:51:07,718 - mmrotate - INFO - Best mAP is 0.4010 at 7 epoch.\r\n",
      "2025-09-16 20:51:07,719 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 20:51:07,719 - mmrotate - INFO - Epoch(val) [7][464]\tmAP: 0.4010\r\n",
      "2025-09-16 20:53:47,634 - mmrotate - INFO - Epoch [8][100/1855]\tlr: 2.500e-03, eta: 2:19:15, time: 1.599, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0372, loss_rpn_bbox: 0.0695, loss_cls: 0.0818, acc: 96.9727, loss_bbox: 0.0571, loss: 0.2456, grad_norm: 1.9691\r\n",
      "2025-09-16 20:56:24,909 - mmrotate - INFO - Epoch [8][200/1855]\tlr: 2.500e-03, eta: 2:16:44, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0477, loss_rpn_bbox: 0.0619, loss_cls: 0.0913, acc: 96.7168, loss_bbox: 0.0653, loss: 0.2662, grad_norm: 2.0245\r\n",
      "2025-09-16 20:59:02,273 - mmrotate - INFO - Epoch [8][300/1855]\tlr: 2.500e-03, eta: 2:14:13, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0435, loss_rpn_bbox: 0.0664, loss_cls: 0.0829, acc: 97.0215, loss_bbox: 0.0548, loss: 0.2476, grad_norm: 1.9637\r\n",
      "2025-09-16 21:01:39,317 - mmrotate - INFO - Epoch [8][400/1855]\tlr: 2.500e-03, eta: 2:11:41, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0401, loss_rpn_bbox: 0.0553, loss_cls: 0.0774, acc: 97.1953, loss_bbox: 0.0539, loss: 0.2268, grad_norm: 1.8558\r\n",
      "2025-09-16 21:04:16,615 - mmrotate - INFO - Epoch [8][500/1855]\tlr: 2.500e-03, eta: 2:09:10, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0445, loss_rpn_bbox: 0.0666, loss_cls: 0.0752, acc: 97.3555, loss_bbox: 0.0506, loss: 0.2369, grad_norm: 1.9463\r\n",
      "2025-09-16 21:06:54,084 - mmrotate - INFO - Epoch [8][600/1855]\tlr: 2.500e-03, eta: 2:06:38, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0423, loss_rpn_bbox: 0.0597, loss_cls: 0.0783, acc: 97.1943, loss_bbox: 0.0534, loss: 0.2337, grad_norm: 1.8859\r\n",
      "2025-09-16 21:09:31,182 - mmrotate - INFO - Epoch [8][700/1855]\tlr: 2.500e-03, eta: 2:04:07, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0396, loss_rpn_bbox: 0.0709, loss_cls: 0.0792, acc: 97.1123, loss_bbox: 0.0541, loss: 0.2438, grad_norm: 1.9904\r\n",
      "2025-09-16 21:12:08,410 - mmrotate - INFO - Epoch [8][800/1855]\tlr: 2.500e-03, eta: 2:01:35, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0428, loss_rpn_bbox: 0.0618, loss_cls: 0.0875, acc: 96.9141, loss_bbox: 0.0603, loss: 0.2523, grad_norm: 1.8653\r\n",
      "2025-09-16 21:14:45,184 - mmrotate - INFO - Epoch [8][900/1855]\tlr: 2.500e-03, eta: 1:59:03, time: 1.568, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0396, loss_rpn_bbox: 0.0570, loss_cls: 0.0810, acc: 97.0342, loss_bbox: 0.0560, loss: 0.2337, grad_norm: 1.9739\r\n",
      "2025-09-16 21:17:22,401 - mmrotate - INFO - Epoch [8][1000/1855]\tlr: 2.500e-03, eta: 1:56:31, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0376, loss_rpn_bbox: 0.0625, loss_cls: 0.0768, acc: 97.1885, loss_bbox: 0.0541, loss: 0.2310, grad_norm: 1.9459\r\n",
      "2025-09-16 21:19:59,612 - mmrotate - INFO - Epoch [8][1100/1855]\tlr: 2.500e-03, eta: 1:54:00, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0502, loss_rpn_bbox: 0.0614, loss_cls: 0.0864, acc: 96.8955, loss_bbox: 0.0572, loss: 0.2551, grad_norm: 2.0126\r\n",
      "2025-09-16 21:22:36,696 - mmrotate - INFO - Epoch [8][1200/1855]\tlr: 2.500e-03, eta: 1:51:28, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0409, loss_rpn_bbox: 0.0654, loss_cls: 0.0886, acc: 96.7812, loss_bbox: 0.0637, loss: 0.2587, grad_norm: 2.0462\r\n",
      "2025-09-16 21:25:13,878 - mmrotate - INFO - Epoch [8][1300/1855]\tlr: 2.500e-03, eta: 1:48:56, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0537, loss_rpn_bbox: 0.0578, loss_cls: 0.0833, acc: 97.0645, loss_bbox: 0.0587, loss: 0.2534, grad_norm: 1.9860\r\n",
      "2025-09-16 21:27:51,257 - mmrotate - INFO - Epoch [8][1400/1855]\tlr: 2.500e-03, eta: 1:46:23, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0373, loss_rpn_bbox: 0.0594, loss_cls: 0.0847, acc: 96.8359, loss_bbox: 0.0583, loss: 0.2397, grad_norm: 1.9502\r\n",
      "2025-09-16 21:30:28,351 - mmrotate - INFO - Epoch [8][1500/1855]\tlr: 2.500e-03, eta: 1:43:51, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0543, loss_rpn_bbox: 0.0623, loss_cls: 0.0851, acc: 97.0537, loss_bbox: 0.0539, loss: 0.2556, grad_norm: 2.0953\r\n",
      "2025-09-16 21:33:05,494 - mmrotate - INFO - Epoch [8][1600/1855]\tlr: 2.500e-03, eta: 1:41:19, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0403, loss_rpn_bbox: 0.0624, loss_cls: 0.0873, acc: 96.7686, loss_bbox: 0.0602, loss: 0.2502, grad_norm: 1.9807\r\n",
      "2025-09-16 21:35:42,442 - mmrotate - INFO - Epoch [8][1700/1855]\tlr: 2.500e-03, eta: 1:38:47, time: 1.569, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0401, loss_rpn_bbox: 0.0692, loss_cls: 0.0859, acc: 96.8838, loss_bbox: 0.0615, loss: 0.2567, grad_norm: 2.0454\r\n",
      "2025-09-16 21:38:20,004 - mmrotate - INFO - Epoch [8][1800/1855]\tlr: 2.500e-03, eta: 1:36:14, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0494, loss_rpn_bbox: 0.0806, loss_cls: 0.0934, acc: 96.5537, loss_bbox: 0.0673, loss: 0.2907, grad_norm: 2.1113\r\n",
      "2025-09-16 21:39:46,700 - mmrotate - INFO - Saving checkpoint at 8 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 21:41:21,443 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 7872 | 0.599  | 0.432 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.432 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 21:41:21,568 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_7.pth was removed\r\n",
      "2025-09-16 21:41:22,366 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_8.pth.\r\n",
      "2025-09-16 21:41:22,367 - mmrotate - INFO - Best mAP is 0.4323 at 8 epoch.\r\n",
      "2025-09-16 21:41:22,368 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 21:41:22,368 - mmrotate - INFO - Epoch(val) [8][464]\tmAP: 0.4323\r\n",
      "2025-09-16 21:44:02,312 - mmrotate - INFO - Epoch [9][100/1855]\tlr: 2.500e-04, eta: 1:31:58, time: 1.599, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0443, loss_rpn_bbox: 0.0766, loss_cls: 0.0983, acc: 96.4170, loss_bbox: 0.0754, loss: 0.2947, grad_norm: 2.1945\r\n",
      "2025-09-16 21:46:39,405 - mmrotate - INFO - Epoch [9][200/1855]\tlr: 2.500e-04, eta: 1:29:26, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0399, loss_rpn_bbox: 0.0642, loss_cls: 0.0842, acc: 96.8643, loss_bbox: 0.0612, loss: 0.2495, grad_norm: 1.8933\r\n",
      "2025-09-16 21:49:16,669 - mmrotate - INFO - Epoch [9][300/1855]\tlr: 2.500e-04, eta: 1:26:54, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0382, loss_rpn_bbox: 0.0552, loss_cls: 0.0858, acc: 96.8867, loss_bbox: 0.0634, loss: 0.2427, grad_norm: 1.9037\r\n",
      "2025-09-16 21:51:53,772 - mmrotate - INFO - Epoch [9][400/1855]\tlr: 2.500e-04, eta: 1:24:22, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0392, loss_rpn_bbox: 0.0596, loss_cls: 0.0759, acc: 97.2227, loss_bbox: 0.0597, loss: 0.2345, grad_norm: 1.8972\r\n",
      "2025-09-16 21:54:30,803 - mmrotate - INFO - Epoch [9][500/1855]\tlr: 2.500e-04, eta: 1:21:50, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0335, loss_rpn_bbox: 0.0447, loss_cls: 0.0804, acc: 97.0947, loss_bbox: 0.0598, loss: 0.2184, grad_norm: 1.8522\r\n",
      "2025-09-16 21:57:07,826 - mmrotate - INFO - Epoch [9][600/1855]\tlr: 2.500e-04, eta: 1:19:18, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0369, loss_rpn_bbox: 0.0512, loss_cls: 0.0831, acc: 96.9043, loss_bbox: 0.0624, loss: 0.2336, grad_norm: 1.9511\r\n",
      "2025-09-16 21:59:44,786 - mmrotate - INFO - Epoch [9][700/1855]\tlr: 2.500e-04, eta: 1:16:46, time: 1.570, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0316, loss_rpn_bbox: 0.0593, loss_cls: 0.0805, acc: 96.9980, loss_bbox: 0.0581, loss: 0.2294, grad_norm: 1.9296\r\n",
      "2025-09-16 22:02:22,061 - mmrotate - INFO - Epoch [9][800/1855]\tlr: 2.500e-04, eta: 1:14:13, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0318, loss_rpn_bbox: 0.0455, loss_cls: 0.0755, acc: 97.2217, loss_bbox: 0.0552, loss: 0.2079, grad_norm: 1.8643\r\n",
      "2025-09-16 22:04:59,318 - mmrotate - INFO - Epoch [9][900/1855]\tlr: 2.500e-04, eta: 1:11:41, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0367, loss_rpn_bbox: 0.0635, loss_cls: 0.0889, acc: 96.6826, loss_bbox: 0.0673, loss: 0.2564, grad_norm: 2.0662\r\n",
      "2025-09-16 22:07:36,348 - mmrotate - INFO - Epoch [9][1000/1855]\tlr: 2.500e-04, eta: 1:09:09, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0353, loss_rpn_bbox: 0.0515, loss_cls: 0.0914, acc: 96.5674, loss_bbox: 0.0695, loss: 0.2477, grad_norm: 2.0144\r\n",
      "2025-09-16 22:10:13,372 - mmrotate - INFO - Epoch [9][1100/1855]\tlr: 2.500e-04, eta: 1:06:36, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0358, loss_rpn_bbox: 0.0584, loss_cls: 0.0889, acc: 96.7617, loss_bbox: 0.0649, loss: 0.2479, grad_norm: 2.0986\r\n",
      "2025-09-16 22:12:50,647 - mmrotate - INFO - Epoch [9][1200/1855]\tlr: 2.500e-04, eta: 1:04:04, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0378, loss_rpn_bbox: 0.0517, loss_cls: 0.0769, acc: 97.1914, loss_bbox: 0.0560, loss: 0.2224, grad_norm: 1.8623\r\n",
      "2025-09-16 22:15:27,638 - mmrotate - INFO - Epoch [9][1300/1855]\tlr: 2.500e-04, eta: 1:01:31, time: 1.570, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0327, loss_rpn_bbox: 0.0472, loss_cls: 0.0791, acc: 97.1689, loss_bbox: 0.0553, loss: 0.2143, grad_norm: 1.9896\r\n",
      "2025-09-16 22:18:04,954 - mmrotate - INFO - Epoch [9][1400/1855]\tlr: 2.500e-04, eta: 0:58:58, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0370, loss_rpn_bbox: 0.0600, loss_cls: 0.0913, acc: 96.6172, loss_bbox: 0.0688, loss: 0.2570, grad_norm: 2.1685\r\n",
      "2025-09-16 22:20:42,006 - mmrotate - INFO - Epoch [9][1500/1855]\tlr: 2.500e-04, eta: 0:56:26, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0332, loss_rpn_bbox: 0.0479, loss_cls: 0.0850, acc: 96.8457, loss_bbox: 0.0642, loss: 0.2304, grad_norm: 1.9900\r\n",
      "2025-09-16 22:23:19,150 - mmrotate - INFO - Epoch [9][1600/1855]\tlr: 2.500e-04, eta: 0:53:53, time: 1.571, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.0649, loss_cls: 0.0829, acc: 97.0088, loss_bbox: 0.0592, loss: 0.2490, grad_norm: 2.1368\r\n",
      "2025-09-16 22:25:56,237 - mmrotate - INFO - Epoch [9][1700/1855]\tlr: 2.500e-04, eta: 0:51:20, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0352, loss_rpn_bbox: 0.0521, loss_cls: 0.0822, acc: 96.9414, loss_bbox: 0.0623, loss: 0.2318, grad_norm: 1.9250\r\n",
      "2025-09-16 22:28:33,324 - mmrotate - INFO - Epoch [9][1800/1855]\tlr: 2.500e-04, eta: 0:48:47, time: 1.571, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0397, loss_rpn_bbox: 0.0517, loss_cls: 0.0915, acc: 96.6260, loss_bbox: 0.0720, loss: 0.2549, grad_norm: 2.1130\r\n",
      "2025-09-16 22:29:59,968 - mmrotate - INFO - Saving checkpoint at 9 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 22:31:33,963 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 5839 | 0.601  | 0.465 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.465 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 22:31:34,092 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_8.pth was removed\r\n",
      "2025-09-16 22:31:34,879 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_9.pth.\r\n",
      "2025-09-16 22:31:34,880 - mmrotate - INFO - Best mAP is 0.4650 at 9 epoch.\r\n",
      "2025-09-16 22:31:34,881 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 22:31:34,881 - mmrotate - INFO - Epoch(val) [9][464]\tmAP: 0.4650\r\n",
      "2025-09-16 22:34:14,457 - mmrotate - INFO - Epoch [10][100/1855]\tlr: 2.500e-04, eta: 0:44:42, time: 1.596, data_time: 0.034, memory: 9386, loss_rpn_cls: 0.0327, loss_rpn_bbox: 0.0515, loss_cls: 0.0883, acc: 96.7305, loss_bbox: 0.0670, loss: 0.2395, grad_norm: 2.0390\r\n",
      "2025-09-16 22:36:51,958 - mmrotate - INFO - Epoch [10][200/1855]\tlr: 2.500e-04, eta: 0:42:09, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0376, loss_rpn_bbox: 0.0553, loss_cls: 0.0851, acc: 96.7617, loss_bbox: 0.0617, loss: 0.2396, grad_norm: 1.9952\r\n",
      "2025-09-16 22:39:29,451 - mmrotate - INFO - Epoch [10][300/1855]\tlr: 2.500e-04, eta: 0:39:37, time: 1.575, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0376, loss_rpn_bbox: 0.0550, loss_cls: 0.0858, acc: 96.7686, loss_bbox: 0.0642, loss: 0.2427, grad_norm: 2.0587\r\n",
      "2025-09-16 22:42:06,495 - mmrotate - INFO - Epoch [10][400/1855]\tlr: 2.500e-04, eta: 0:37:04, time: 1.570, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0329, loss_rpn_bbox: 0.0544, loss_cls: 0.0794, acc: 97.0518, loss_bbox: 0.0607, loss: 0.2275, grad_norm: 2.0623\r\n",
      "2025-09-16 22:44:43,971 - mmrotate - INFO - Epoch [10][500/1855]\tlr: 2.500e-04, eta: 0:34:32, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0331, loss_rpn_bbox: 0.0447, loss_cls: 0.0742, acc: 97.3652, loss_bbox: 0.0545, loss: 0.2064, grad_norm: 1.9224\r\n",
      "2025-09-16 22:47:21,277 - mmrotate - INFO - Epoch [10][600/1855]\tlr: 2.500e-04, eta: 0:31:59, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.0629, loss_cls: 0.0884, acc: 96.6660, loss_bbox: 0.0648, loss: 0.2511, grad_norm: 2.1992\r\n",
      "2025-09-16 22:49:59,135 - mmrotate - INFO - Epoch [10][700/1855]\tlr: 2.500e-04, eta: 0:29:27, time: 1.579, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0288, loss_rpn_bbox: 0.0486, loss_cls: 0.0756, acc: 97.2158, loss_bbox: 0.0574, loss: 0.2105, grad_norm: 1.8646\r\n",
      "2025-09-16 22:52:36,751 - mmrotate - INFO - Epoch [10][800/1855]\tlr: 2.500e-04, eta: 0:26:54, time: 1.576, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0376, loss_rpn_bbox: 0.0582, loss_cls: 0.0887, acc: 96.6934, loss_bbox: 0.0663, loss: 0.2508, grad_norm: 2.1719\r\n",
      "2025-09-16 22:55:14,224 - mmrotate - INFO - Epoch [10][900/1855]\tlr: 2.500e-04, eta: 0:24:21, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0369, loss_rpn_bbox: 0.0643, loss_cls: 0.0876, acc: 96.7197, loss_bbox: 0.0687, loss: 0.2575, grad_norm: 2.1298\r\n",
      "2025-09-16 22:57:51,395 - mmrotate - INFO - Epoch [10][1000/1855]\tlr: 2.500e-04, eta: 0:21:48, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0352, loss_rpn_bbox: 0.0449, loss_cls: 0.0821, acc: 96.9141, loss_bbox: 0.0654, loss: 0.2276, grad_norm: 2.1095\r\n",
      "2025-09-16 23:00:28,730 - mmrotate - INFO - Epoch [10][1100/1855]\tlr: 2.500e-04, eta: 0:19:15, time: 1.573, data_time: 0.010, memory: 9386, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.0438, loss_cls: 0.0832, acc: 96.8076, loss_bbox: 0.0667, loss: 0.2288, grad_norm: 1.9634\r\n",
      "2025-09-16 23:03:06,140 - mmrotate - INFO - Epoch [10][1200/1855]\tlr: 2.500e-04, eta: 0:16:42, time: 1.574, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0378, loss_rpn_bbox: 0.0472, loss_cls: 0.0841, acc: 96.7861, loss_bbox: 0.0640, loss: 0.2331, grad_norm: 2.0226\r\n",
      "2025-09-16 23:05:43,859 - mmrotate - INFO - Epoch [10][1300/1855]\tlr: 2.500e-04, eta: 0:14:09, time: 1.577, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.0512, loss_cls: 0.0859, acc: 96.8291, loss_bbox: 0.0674, loss: 0.2395, grad_norm: 2.0625\r\n",
      "2025-09-16 23:08:21,075 - mmrotate - INFO - Epoch [10][1400/1855]\tlr: 2.500e-04, eta: 0:11:36, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0337, loss_rpn_bbox: 0.0524, loss_cls: 0.0791, acc: 97.0635, loss_bbox: 0.0602, loss: 0.2254, grad_norm: 2.0341\r\n",
      "2025-09-16 23:10:58,388 - mmrotate - INFO - Epoch [10][1500/1855]\tlr: 2.500e-04, eta: 0:09:03, time: 1.573, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0354, loss_rpn_bbox: 0.0655, loss_cls: 0.0894, acc: 96.6777, loss_bbox: 0.0704, loss: 0.2607, grad_norm: 2.1559\r\n",
      "2025-09-16 23:13:36,078 - mmrotate - INFO - Epoch [10][1600/1855]\tlr: 2.500e-04, eta: 0:06:30, time: 1.577, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0355, loss_rpn_bbox: 0.0498, loss_cls: 0.0894, acc: 96.6514, loss_bbox: 0.0642, loss: 0.2389, grad_norm: 2.0999\r\n",
      "2025-09-16 23:16:13,252 - mmrotate - INFO - Epoch [10][1700/1855]\tlr: 2.500e-04, eta: 0:03:57, time: 1.572, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0360, loss_rpn_bbox: 0.0549, loss_cls: 0.0780, acc: 97.1182, loss_bbox: 0.0537, loss: 0.2225, grad_norm: 2.0289\r\n",
      "2025-09-16 23:18:50,761 - mmrotate - INFO - Epoch [10][1800/1855]\tlr: 2.500e-04, eta: 0:01:24, time: 1.575, data_time: 0.011, memory: 9386, loss_rpn_cls: 0.0405, loss_rpn_bbox: 0.0606, loss_cls: 0.0836, acc: 96.9336, loss_bbox: 0.0669, loss: 0.2516, grad_norm: 2.1520\r\n",
      "2025-09-16 23:20:17,204 - mmrotate - INFO - Saving checkpoint at 10 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 5.5 task/s, elapsed: 84s, ETA:     0s/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "2025-09-16 23:21:51,533 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 1744 | 6652 | 0.653  | 0.506 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.506 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-09-16 23:21:51,664 - mmrotate - INFO - The previous best checkpoint /kaggle/working/runs/FIRNet_train/best_mAP_epoch_9.pth was removed\r\n",
      "2025-09-16 23:21:52,448 - mmrotate - INFO - Now best checkpoint is saved as best_mAP_epoch_10.pth.\r\n",
      "2025-09-16 23:21:52,450 - mmrotate - INFO - Best mAP is 0.5055 at 10 epoch.\r\n",
      "2025-09-16 23:21:52,450 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-09-16 23:21:52,451 - mmrotate - INFO - Epoch(val) [10][464]\tmAP: 0.5055\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact artifacts (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m 20250916_145842.log 68.9KB/68.9KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m firnet_r50_fpn_1x_sccos.py 8.5KB/8.5KB (0.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 55.5KB/55.5KB (0.8s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: + 1 more task(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact artifacts (2.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m 20250916_145842.log.json 58.1KB/58.1KB (1.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact artifacts (3.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact artifacts (3.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact artifacts (3.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact artifacts (3.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact artifacts (3.0s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       learning_rate ▅▆▇████████████████████████████████▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            momentum ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/acc ██▇▆▇▅▅▅▅▅▃▂▄▂▂▃▃▃▃▄▃▃▂▁▂▂▁▃▁▃▃▃▂▂▃▁▁▂▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm ██▇▄▃▂▂▂▂▁▁▂▂▂▁▁▁▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▃▂▃▂▂\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss ▆▇▄▅▂▅▂▅▆▃▄▇▇▆▆▂▆▄█▆▃▆▃▄▃▄▄▄▁▃▃▃▄▄▃▄▂▄▄▃\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/loss_bbox ▂▂▁▂▃▅▅▄▄▅▆▆▆▅▆▆▇▆▅▇▅▆▆▇▆▇▆█▆▆▇▇▆█▇▇████\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/loss_cls ▃▁▁▁▂▇▇▇▆▆█▆▆▇▆▅█▇▅▆▅▇▆▇▇█▇▇▅▆▆▆▆▇█▇▆▆▆▇\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss_rpn_bbox ▆▅▇█▄▅▄▅▄▄▃▄▃▅▂▄▄▂▄▅▃▄▅▃▃▃▃▄▃▃▂▂▃▃▂▂▂▁▂▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/loss_rpn_cls ██▅▇▃▄▃▃▄▂▃▃▃▂▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             val/mAP ▁▂▃▄▅▅▆▇▇█\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       learning_rate 0.00025\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            momentum 0.9\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/acc 96.93359\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm 2.15204\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss 0.25157\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/loss_bbox 0.06685\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/loss_cls 0.08363\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss_rpn_bbox 0.06056\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train/loss_rpn_cls 0.04053\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             val/mAP 0.50551\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mFREANet_PKI\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/FREANet_training/runs/dalqxg2u\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/tanish1403/FREANet_training\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250916_145907-dalqxg2u/logs\u001b[0m\r\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the Model\n",
    "%cd /kaggle/working/mmrotate\n",
    "!mkdir -p /kaggle/working/runs/FIRNet_train\n",
    "\n",
    "\n",
    "!python tools/train.py \\\n",
    "    configs/firnet/firnet_r50_fpn_1x_sccos.py \\\n",
    "    --work-dir /kaggle/working/runs/FIRNet_train \\\n",
    "    --gpus 1 \\\n",
    "\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70055692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T23:22:00.133143Z",
     "iopub.status.busy": "2025-09-16T23:22:00.132310Z",
     "iopub.status.idle": "2025-09-16T23:25:24.238604Z",
     "shell.execute_reply": "2025-09-16T23:25:24.237736Z"
    },
    "papermill": {
     "duration": 204.367963,
     "end_time": "2025-09-16T23:25:24.239805",
     "exception": false,
     "start_time": "2025-09-16T23:21:59.871842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "Found best checkpoint: /kaggle/working/runs/FIRNet_train/best_mAP_epoch_10.pth\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "load checkpoint from local path: /kaggle/working/runs/FIRNet_train/best_mAP_epoch_10.pth\r\n",
      "[                                                  ] 0/464, elapsed: 0s, ETA:/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "[                                 ] 1/464, 0.6 task/s, elapsed: 2s, ETA:   718s/usr/local/lib/python3.11/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 2.5 task/s, elapsed: 182s, ETA:     0s\r\n",
      "writing results to /kaggle/working/runs/firnet_test/results.pkl\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\r\n",
      "\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 2140 | 6906 | 0.585  | 0.457 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.457 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "{'mAP': 0.45703810453414917}\r\n",
      "FIRNet testing completed. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Test FIRNet (uncomment to run)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%cd /kaggle/working/mmrotate\n",
    "\n",
    "# Step 1: Find the best checkpoint file automatically\n",
    "checkpoint_dir = '/kaggle/working/runs/FIRNet_train'\n",
    "best_checkpoint_path = None\n",
    "# Search for the best checkpoint file\n",
    "for filename in glob.glob(os.path.join(checkpoint_dir, 'best_mAP_*.pth')):\n",
    "    best_checkpoint_path = filename\n",
    "    break  # Take the first one found\n",
    "\n",
    "if best_checkpoint_path:\n",
    "    print(f\"Found best checkpoint: {best_checkpoint_path}\")\n",
    "    \n",
    "    # Step 2: Run the test command with the found checkpoint\n",
    "    !mkdir -p /kaggle/working/runs/FIRNet_test\n",
    "    !python tools/test.py \\\n",
    "        configs/firnet/firnet_r50_fpn_1x_sccos.py \\\n",
    "        {best_checkpoint_path} \\\n",
    "        --eval mAP \\\n",
    "        --out /kaggle/working/runs/firnet_test/results.pkl \\\n",
    "        --show-dir /kaggle/working/runs/firnet_test/vis\n",
    "    \n",
    "    print(\"FIRNet testing completed. Results saved.\")\n",
    "else:\n",
    "    print(f\"Error: No best checkpoint found in {checkpoint_dir}. Please ensure training was successful.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8134003,
     "sourceId": 12859844,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30633.757205,
   "end_time": "2025-09-16T23:25:25.073023",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-16T14:54:51.315818",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
